{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting\n",
    "\n",
    "This notebook demonstrates the new modular architecture for time series forecasting experiments.\n",
    "\n",
    "## Features:\n",
    "- üîß Configuration-driven experiments\n",
    "- üìä Unified logging and metrics\n",
    "- üé® Interactive visualizations\n",
    "- üîÑ Rolling window validation\n",
    "- ‚ö° Parallel model execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Cell 1: Import Libraries and Setup Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries and training function imported\n",
      "üöÄ Available CPU cores: 14\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries and Setup Training Function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import gc\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "# Setup paths and import training function\n",
    "current_dir = Path.cwd()\n",
    "if \"ENEXIS\" in str(current_dir):\n",
    "    while current_dir.name != \"ENEXIS\" and current_dir.parent != current_dir:\n",
    "        current_dir = current_dir.parent\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "from utils.build_training_set import build_training_set\n",
    "\n",
    "# Performance optimizations\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)  # Suppress INFO/DEBUG logs\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "plt.ioff()\n",
    "\n",
    "print(f\"‚úÖ Libraries and training function imported\")\n",
    "print(f\"üöÄ Available CPU cores: {multiprocessing.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Random Seeds and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Target: Price\n",
      "üìä Features: 19\n",
      "üé≤ Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Key configuration\n",
    "TARGET = 'Price'\n",
    "FEATURES = [\n",
    "    'Load', 'shortwave_radiation', 'temperature_2m', \n",
    "    'direct_normal_irradiance', 'diffuse_radiation', \n",
    "    'Flow_NO', 'yearday_cos', 'Flow_GB', 'month', 'is_dst', \n",
    "    'yearday_sin', 'wind_speed_10m', 'is_non_working_day', \n",
    "    'hour_cos', 'is_weekend', 'cloud_cover', 'weekday_sin', \n",
    "    'hour_sin', 'weekday_cos'\n",
    "]\n",
    "\n",
    "# SARIMAX parameters (optimized for speed)\n",
    "ORDER = (1, 1, 1)\n",
    "SEASONAL_ORDER = (1, 1, 1, 24)\n",
    "\n",
    "# Rolling window setup\n",
    "BASE_START = \"2025-01-01 00:00:00\"\n",
    "BASE_END = \"2025-03-14 23:00:00\"\n",
    "BASE_RUN = \"2025-03-15 00:00:00\"\n",
    "\n",
    "print(f\"üéØ Target: {TARGET}\")\n",
    "print(f\"üìä Features: {len(FEATURES)}\")\n",
    "print(f\"üé≤ Random seed: 42\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Core Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def prep_data(df, target_col, feature_cols=None):\n",
    "    \"\"\"Fast data preparation for SARIMAX models.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['target_datetime'] = pd.to_datetime(df['target_datetime']).dt.tz_localize(None)\n",
    "    df = df.set_index('target_datetime').sort_index()\n",
    "    \n",
    "    y = df[target_col].astype(float)\n",
    "    exog = df[feature_cols].astype(float) if feature_cols else None\n",
    "    \n",
    "    return y, exog\n",
    "\n",
    "def fit_fast_sarimax(y_train, exog_train=None):\n",
    "    \"\"\"Fit SARIMAX with speed optimizations.\"\"\"\n",
    "    model = SARIMAX(\n",
    "        y_train, \n",
    "        exog=exog_train,\n",
    "        order=ORDER, \n",
    "        seasonal_order=SEASONAL_ORDER,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False,\n",
    "        concentrate_scale=True  # Speed boost\n",
    "    )\n",
    "    return model.fit(disp=False, maxiter=50, method='lbfgs')\n",
    "\n",
    "def calc_rmse_by_day(y_true, y_pred, max_days=7):\n",
    "    \"\"\"Calculate RMSE for each forecast day (1-7).\"\"\"\n",
    "    rmse_dict = {'overall': np.sqrt(mean_squared_error(y_true, y_pred))}\n",
    "    \n",
    "    for day in range(1, min(len(y_true)//24, max_days) + 1):\n",
    "        start, end = (day-1)*24, day*24\n",
    "        if end <= len(y_true):\n",
    "            rmse_dict[f'day_{day}'] = np.sqrt(mean_squared_error(\n",
    "                y_true.iloc[start:end], y_pred[start:end]\n",
    "            ))\n",
    "    \n",
    "    return rmse_dict\n",
    "\n",
    "print(\"‚úÖ Helper functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Cell 4: SARIMA Model (Univariate - Price Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç SARIMA Results (144 predictions):\n",
      "  overall: 0.0527\n",
      "  day_1: 0.0571\n",
      "  day_2: 0.0364\n",
      "  day_3: 0.0488\n",
      "  day_4: 0.0463\n",
      "  day_5: 0.0470\n",
      "  day_6: 0.0730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: SARIMA Model (Univariate - Price Only)\n",
    "def test_sarima():\n",
    "    \"\"\"Test SARIMA model on single time window.\"\"\"\n",
    "    df = build_training_set(BASE_START, BASE_END, BASE_RUN)\n",
    "    df['target_datetime'] = pd.to_datetime(df['target_datetime'], utc=True)\n",
    "    \n",
    "    run_date_utc = pd.Timestamp(BASE_RUN).tz_localize(\"UTC\")\n",
    "    train_data = df[df['target_datetime'] <= run_date_utc]\n",
    "    test_data = df[df['target_datetime'] > run_date_utc]\n",
    "    \n",
    "    # Skip first 24h as per requirement\n",
    "    test_data = test_data.iloc[24:] if len(test_data) > 24 else test_data\n",
    "    \n",
    "    # Prepare data (univariate - no features)\n",
    "    y_train, _ = prep_data(train_data, TARGET)\n",
    "    y_test, _ = prep_data(test_data, TARGET)\n",
    "    \n",
    "    # Fit and forecast\n",
    "    model_fit = fit_fast_sarimax(y_train)\n",
    "    y_pred = model_fit.forecast(len(y_test)).values\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse_results = calc_rmse_by_day(y_test, y_pred)\n",
    "    \n",
    "    return rmse_results, len(y_test)\n",
    "\n",
    "# Run test\n",
    "sarima_rmse, n_pred = test_sarima()\n",
    "print(f\"üîç SARIMA Results ({n_pred} predictions):\")\n",
    "for k, v in sarima_rmse.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "gc.collect()  # Clean memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5: SARIMAX Model (19 Observation Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Training: 2025-01-01 00:00:00+00:00 ‚Üí 2025-03-15 00:00:00+00:00\n",
      "üîÆ Oracle Forecast: 2025-03-15 01:00:00+00:00 ‚Üí 2025-03-22 00:00:00+00:00\n",
      "üéØ Oracle mode: Using OBSERVED exogenous features (perfect forecasts)\n",
      "üîç Debug - Oracle using OBSERVED values for all 19 exogenous features\n",
      "üîç SARIMAX Perfect Results (312 predictions):\n",
      "  overall: 0.0517\n",
      "  day_1: 0.0219\n",
      "  day_2: 0.0281\n",
      "  day_3: 0.0295\n",
      "  day_4: 0.0414\n",
      "  day_5: 0.0399\n",
      "  day_6: 0.0486\n",
      "  day_7: 0.0756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: SARIMAX with Perfect Exogenous Features (Oracle Upper Bound)\n",
    "def test_sarimax_perfect():\n",
    "    \"\"\"Oracle scenario: SARIMAX with perfect exogenous features in forecast window.\"\"\"\n",
    "    df = build_training_set(BASE_START, BASE_END, BASE_RUN)\n",
    "    df['target_datetime'] = pd.to_datetime(df['target_datetime'], utc=True)\n",
    "    \n",
    "    run_date_utc = pd.Timestamp(BASE_RUN).tz_localize(\"UTC\")\n",
    "    train_data = df[df['target_datetime'] <= run_date_utc]\n",
    "    test_data = df[df['target_datetime'] > run_date_utc]\n",
    "    \n",
    "    print(f\"üìÖ Training: {train_data['target_datetime'].min()} ‚Üí {train_data['target_datetime'].max()}\")\n",
    "    print(f\"üîÆ Oracle Forecast: {test_data['target_datetime'].min()} ‚Üí {test_data['target_datetime'].max()}\")\n",
    "    print(f\"üéØ Oracle mode: Using OBSERVED exogenous features (perfect forecasts)\")\n",
    "    \n",
    "    # Skip first 24h as per requirement  \n",
    "    test_data = test_data.iloc[24:] if len(test_data) > 24 else test_data\n",
    "    \n",
    "    # For oracle scenario, we need to get the ACTUAL observed values for exogenous features\n",
    "    # in the forecast window. This simulates having perfect weather forecasts, etc.\n",
    "    \n",
    "    # Get additional observed data for the forecast window from master_warp\n",
    "    try:\n",
    "        df_oracle = build_training_set(\n",
    "            BASE_START, \n",
    "            (pd.Timestamp(BASE_RUN) + pd.Timedelta(hours=168)).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            (pd.Timestamp(BASE_RUN) + pd.Timedelta(hours=168)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        )\n",
    "        df_oracle['target_datetime'] = pd.to_datetime(df_oracle['target_datetime'], utc=True)\n",
    "        \n",
    "        # Use observed values for ALL features in forecast window\n",
    "        oracle_train = df_oracle[df_oracle['target_datetime'] <= run_date_utc]\n",
    "        oracle_test = df_oracle[df_oracle['target_datetime'] > run_date_utc]\n",
    "        oracle_test = oracle_test.iloc[24:] if len(oracle_test) > 24 else oracle_test\n",
    "        \n",
    "        print(f\"üîç Debug - Oracle using OBSERVED values for all {len(FEATURES)} exogenous features\")\n",
    "        \n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Cannot access future observed values - using available data\")\n",
    "        oracle_train = train_data\n",
    "        oracle_test = test_data\n",
    "    \n",
    "    # Drop NaN and prepare data\n",
    "    oracle_train = oracle_train.dropna(subset=[TARGET] + FEATURES)\n",
    "    oracle_test = oracle_test.dropna(subset=[TARGET] + FEATURES)\n",
    "    \n",
    "    if oracle_test.empty:\n",
    "        print(\"‚ùå No oracle test data available\")\n",
    "        return {}, 0\n",
    "    \n",
    "    # Prepare data with ALL features (using observed values)\n",
    "    y_train, exog_train = prep_data(oracle_train, TARGET, FEATURES)\n",
    "    y_test, exog_test = prep_data(oracle_test, TARGET, FEATURES)\n",
    "    \n",
    "    # Fit SARIMAX with exogenous features\n",
    "    model_fit = fit_fast_sarimax(y_train, exog_train)\n",
    "    \n",
    "    # Forecast WITH perfect exogenous features\n",
    "    y_pred = model_fit.forecast(len(y_test), exog=exog_test).values\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse_results = calc_rmse_by_day(y_test, y_pred)\n",
    "    \n",
    "    return rmse_results, len(y_test)\n",
    "\n",
    "# Run oracle test\n",
    "sarimax_perfect_rmse, n_pred = test_sarimax_perfect()\n",
    "print(f\"üîç SARIMAX Perfect Results ({n_pred} predictions):\")\n",
    "for k, v in sarimax_perfect_rmse.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: SARIMAX Model (19 Obs + Predictive Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: SARIMAX Realistic (Predicted/Lagged Exogenous Features)\n",
    "def analyze_forecast_features(df, run_date_utc, features):\n",
    "    \"\"\"Analyze which features are predicted vs lagged in forecast window.\"\"\"\n",
    "    forecast_data = df[df['target_datetime'] > run_date_utc]\n",
    "    train_data = df[df['target_datetime'] <= run_date_utc]\n",
    "    \n",
    "    if forecast_data.empty:\n",
    "        return {}\n",
    "    \n",
    "    feature_sources = {}\n",
    "    first_forecast_time = forecast_data['target_datetime'].iloc[0]\n",
    "    lag_time = first_forecast_time - pd.Timedelta(hours=168)\n",
    "    \n",
    "    print(f\"üîç Debug - Feature sources for forecast (first hour: {first_forecast_time}):\")\n",
    "    \n",
    "    for feature in features[:6]:  # Show first 6 features to avoid clutter\n",
    "        if feature in forecast_data.columns:\n",
    "            forecast_val = forecast_data[feature].iloc[0]\n",
    "            \n",
    "            # Find what the 168h lagged value would be\n",
    "            lag_match = train_data[train_data['target_datetime'] == lag_time]\n",
    "            lag_val = lag_match[feature].iloc[0] if not lag_match.empty else None\n",
    "            \n",
    "            # Determine if this looks like a prediction or lag\n",
    "            if lag_val is not None and abs(forecast_val - lag_val) < 0.001:\n",
    "                source = \"168h LAG\"\n",
    "                feature_sources[feature] = \"lagged\"\n",
    "            else:\n",
    "                source = \"PREDICTION\"\n",
    "                feature_sources[feature] = \"predicted\"\n",
    "            \n",
    "            print(f\"  {feature}: {source} (val={forecast_val:.3f})\")\n",
    "    \n",
    "    pred_count = sum(1 for v in feature_sources.values() if v == \"predicted\")\n",
    "    lag_count = sum(1 for v in feature_sources.values() if v == \"lagged\")\n",
    "    print(f\"  Summary: {pred_count} predicted, {lag_count} lagged features\")\n",
    "    \n",
    "    return feature_sources\n",
    "\n",
    "def test_sarimax_realistic():\n",
    "    \"\"\"Realistic scenario: SARIMAX with predicted/lagged exogenous features.\"\"\"\n",
    "    df = build_training_set(BASE_START, BASE_END, BASE_RUN)\n",
    "    df['target_datetime'] = pd.to_datetime(df['target_datetime'], utc=True)\n",
    "    \n",
    "    run_date_utc = pd.Timestamp(BASE_RUN).tz_localize(\"UTC\")\n",
    "    train_data = df[df['target_datetime'] <= run_date_utc]\n",
    "    test_data = df[df['target_datetime'] > run_date_utc]\n",
    "    \n",
    "    print(f\"üìÖ Training: {train_data['target_datetime'].min()} ‚Üí {train_data['target_datetime'].max()}\")\n",
    "    print(f\"üîÆ Realistic Forecast: {test_data['target_datetime'].min()} ‚Üí {test_data['target_datetime'].max()}\")\n",
    "    print(f\"üéØ Realistic mode: Using predicted/lagged exogenous features\")\n",
    "    \n",
    "    # Analyze feature sources in forecast window\n",
    "    feature_sources = analyze_forecast_features(df, run_date_utc, FEATURES)\n",
    "    \n",
    "    # Skip first 24h as per requirement\n",
    "    test_data = test_data.iloc[24:] if len(test_data) > 24 else test_data\n",
    "    \n",
    "    # Drop NaN for features in both periods\n",
    "    train_data = train_data.dropna(subset=[TARGET] + FEATURES)\n",
    "    test_data = test_data.dropna(subset=[TARGET] + FEATURES)\n",
    "    \n",
    "    # Prepare data WITH features (realistic scenario uses available predictions/lags)\n",
    "    y_train, exog_train = prep_data(train_data, TARGET, FEATURES)\n",
    "    y_test, exog_test = prep_data(test_data, TARGET, FEATURES)\n",
    "    \n",
    "    # Fit SARIMAX with exogenous features\n",
    "    model_fit = fit_fast_sarimax(y_train, exog_train)\n",
    "    \n",
    "    # Forecast WITH exogenous features (realistic scenario)\n",
    "    y_pred = model_fit.forecast(len(y_test), exog=exog_test).values\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse_results = calc_rmse_by_day(y_test, y_pred)\n",
    "    \n",
    "    return rmse_results, len(y_test)\n",
    "\n",
    "# Run realistic test\n",
    "sarimax_realistic_rmse, n_pred = test_sarimax_realistic()\n",
    "print(f\"üîç SARIMAX Realistic Results ({n_pred} predictions):\")\n",
    "for k, v in sarimax_realistic_rmse.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
