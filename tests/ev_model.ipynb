{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import time\n",
    "\n",
    "# Statistical modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✅ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Loading Function\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path and import build_training_set function\n",
    "src_path = Path(\"src\").resolve()\n",
    "if src_path.exists():\n",
    "    sys.path.insert(0, str(src_path))\n",
    "from utils.build_training_set import build_training_set\n",
    "\n",
    "def load_training_data(train_start, train_end, run_date):\n",
    "    \"\"\"Load training data using build_training_set function\"\"\"\n",
    "    training_set = build_training_set(\n",
    "        train_start=train_start,\n",
    "        train_end=train_end, \n",
    "        run_date=run_date\n",
    "    )\n",
    "    \n",
    "    if training_set is not None:\n",
    "        training_data = training_set.copy()\n",
    "        if 'target_datetime' in training_data.columns:\n",
    "            training_data = training_data.set_index('target_datetime')\n",
    "        return training_data\n",
    "    else:\n",
    "        raise ValueError(\"Failed to build training set\")\n",
    "\n",
    "def get_rolling_training_data(origin_date, window_days=73):\n",
    "    \"\"\"Get training data for rolling window experiment\"\"\"\n",
    "    origin = pd.to_datetime(origin_date, utc=True)\n",
    "    train_start = origin - timedelta(days=window_days)\n",
    "    train_end = origin - timedelta(hours=1)\n",
    "    run_date = origin\n",
    "    \n",
    "    return load_training_data(\n",
    "        train_start=train_start.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        train_end=train_end.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        run_date=run_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    )\n",
    "\n",
    "print(\"✅ Data loading functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Ultra-Fast SARIMAX Configuration\n",
    "\n",
    "# Model configuration - optimized for speed\n",
    "SARIMA_ORDER = (1, 0, 0)  # Simple AR(1) for speed\n",
    "SEASONAL_ORDER = (0, 0, 0, 0)  # No seasonality for speed\n",
    "TRAINING_WINDOW_DAYS = 73\n",
    "FORECAST_HORIZON_DAYS = 7\n",
    "REFIT_FREQUENCY = 7\n",
    "\n",
    "# All your exogenous variables\n",
    "EXOG_VARIABLES = [\n",
    "    'Load', 'shortwave_radiation', 'temperature_2m', 'direct_normal_irradiance', \n",
    "    'diffuse_radiation', 'Flow_NO', 'yearday_cos', 'Flow_GB', 'month', 'is_dst',\n",
    "    'yearday_sin', 'wind_speed_10m', 'is_non_working_day', 'hour_cos', 'is_weekend',\n",
    "    'cloud_cover', 'weekday_sin', 'hour_sin', 'weekday_cos'\n",
    "]\n",
    "\n",
    "def fit_fast_models(price_series, exog_data=None):\n",
    "    \"\"\"Fit models with speed optimizations\"\"\"\n",
    "    models = {'naive': None, 'sarima': None, 'sarimax': None}\n",
    "    \n",
    "    # SARIMA with reduced iterations\n",
    "    try:\n",
    "        sarima_model = SARIMAX(price_series, order=SARIMA_ORDER, seasonal_order=SEASONAL_ORDER,\n",
    "                              enforce_stationarity=False, enforce_invertibility=False)\n",
    "        models['sarima'] = sarima_model.fit(disp=False, maxiter=50, method='lbfgs')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # SARIMAX with reduced iterations\n",
    "    if exog_data is not None:\n",
    "        try:\n",
    "            sarimax_model = SARIMAX(price_series, exog=exog_data, order=SARIMA_ORDER, \n",
    "                                   seasonal_order=SEASONAL_ORDER, enforce_stationarity=False, \n",
    "                                   enforce_invertibility=False)\n",
    "            models['sarimax'] = sarimax_model.fit(disp=False, maxiter=30, method='lbfgs')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return models\n",
    "\n",
    "def generate_7day_forecasts(models, last_price, exog_forecast=None):\n",
    "    \"\"\"Generate 7-day forecasts from fitted models\"\"\"\n",
    "    forecasts = {\n",
    "        'naive': [last_price] * 7,\n",
    "        'sarima': [last_price] * 7,\n",
    "        'sarimax': [last_price] * 7\n",
    "    }\n",
    "    \n",
    "    # SARIMA forecast\n",
    "    if models['sarima']:\n",
    "        try:\n",
    "            forecasts['sarima'] = models['sarima'].forecast(steps=7).tolist()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # SARIMAX forecast\n",
    "    if models['sarimax'] and exog_forecast is not None:\n",
    "        try:\n",
    "            forecasts['sarimax'] = models['sarimax'].forecast(steps=7, exog=exog_forecast).tolist()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return forecasts\n",
    "\n",
    "print(\"✅ Ultra-fast SARIMAX configuration ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Main Rolling Forecast Class\n",
    "\n",
    "class RollingForecastExperiment:\n",
    "    \"\"\"\n",
    "    Implements 30-day rolling forecast experiment for electricity price forecasting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, training_data: pd.DataFrame, \n",
    "                 sarima_order: Tuple[int, int, int] = (1, 1, 1),\n",
    "                 seasonal_order: Tuple[int, int, int, int] = (1, 1, 1, 24),\n",
    "                 exog_variables: List[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the rolling forecast experiment\n",
    "        \n",
    "        Args:\n",
    "            training_data: DataFrame with Price and exogenous variables\n",
    "            sarima_order: (p, d, q) parameters for SARIMA\n",
    "            seasonal_order: (P, D, Q, s) parameters for seasonal component\n",
    "            exog_variables: List of exogenous variable column names\n",
    "        \"\"\"\n",
    "        self.data = training_data.copy()\n",
    "        self.sarima_order = sarima_order\n",
    "        self.seasonal_order = seasonal_order\n",
    "        self.exog_variables = exog_variables or []\n",
    "        \n",
    "        # Results storage\n",
    "        self.results = {\n",
    "            'dates': [],\n",
    "            'actual_prices': [],\n",
    "            'naive_forecasts': [],\n",
    "            'sarima_forecasts': [],\n",
    "            'sarimax_forecasts': [],\n",
    "            'naive_rmse': [],\n",
    "            'sarima_rmse': [],\n",
    "            'sarimax_rmse': []\n",
    "        }\n",
    "        \n",
    "        # Model storage for analysis\n",
    "        self.fitted_models = {\n",
    "            'sarima': [],\n",
    "            'sarimax': []\n",
    "        }\n",
    "        \n",
    "        print(f\"🔧 Experiment initialized:\")\n",
    "        print(f\"   - SARIMA order: {sarima_order}\")\n",
    "        print(f\"   - Seasonal order: {seasonal_order}\")\n",
    "        print(f\"   - Exogenous variables: {len(self.exog_variables)}\")\n",
    "    \n",
    "    \n",
    "    def get_actual_data_end_date(self) -> pd.Timestamp:\n",
    "        \"\"\"\n",
    "        Find the last date with actual price data (not forecasted)\n",
    "        Assumes forecasted data has been appended to the end\n",
    "        \"\"\"\n",
    "        # This is a heuristic - you might need to adjust based on your data structure\n",
    "        # Look for the last non-interpolated or non-repeated price pattern\n",
    "        price_series = self.data['Price']\n",
    "        \n",
    "        # Simple approach: assume actual data is complete up to a certain point\n",
    "        # You may need to modify this based on your specific data structure\n",
    "        return price_series.index[-169]  # Assuming last 168 hours are forecasted\n",
    "    \n",
    "    \n",
    "    def run_experiment(self, start_date: str, num_days: int = 30, \n",
    "                      training_window_days: int = 73, refit_frequency: int = 7) -> Dict:\n",
    "        \"\"\"\n",
    "        Run the rolling forecast experiment with sliding training window\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date for the experiment (YYYY-MM-DD)\n",
    "            num_days: Number of days to forecast\n",
    "            training_window_days: Length of training window in days (default: 73 days)\n",
    "            refit_frequency: Refit models every N days (default: 7 days)\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with experiment results\n",
    "        \"\"\"\n",
    "        start_dt = pd.to_datetime(start_date, utc=True)\n",
    "        \n",
    "        print(f\"🚀 Starting {num_days}-day rolling forecast experiment from {start_date}\")\n",
    "        print(f\"📊 Training window: {training_window_days} days (sliding window)\")\n",
    "        print(f\"🔄 Model refit frequency: Every {refit_frequency} days\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Store fitted models for reuse\n",
    "        current_sarima_model = None\n",
    "        current_sarimax_model = None\n",
    "        last_refit_day = -1\n",
    "        \n",
    "        for day in range(num_days):\n",
    "            forecast_date = start_dt + timedelta(days=day)\n",
    "            \n",
    "            print(f\"📅 Day {day + 1}/{num_days}: Forecasting for {forecast_date.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            # Calculate sliding training window\n",
    "            train_start = start_dt - timedelta(days=training_window_days) + timedelta(days=day)\n",
    "            train_end = forecast_date - timedelta(hours=1)\n",
    "            \n",
    "            print(f\"   🧠 Training window: {train_start.strftime('%Y-%m-%d')} to {train_end.strftime('%Y-%m-%d %H:%M')}\")\n",
    "            \n",
    "            # Get training data for this specific window\n",
    "            training_subset = self.data.loc[train_start:train_end]\n",
    "            \n",
    "            if len(training_subset) < 168:\n",
    "                print(f\"   ⚠️ Insufficient training data ({len(training_subset)} hours), skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Check if we need to refit models\n",
    "            should_refit = (day % refit_frequency == 0) or (current_sarima_model is None)\n",
    "            \n",
    "            if should_refit:\n",
    "                print(f\"   🔄 Refitting models (day {day + 1})...\")\n",
    "                last_refit_day = day\n",
    "            else:\n",
    "                print(f\"   ♻️ Reusing models from day {last_refit_day + 1}\")\n",
    "            \n",
    "            # Get actual value for forecast date (midnight)\n",
    "            forecast_timestamp = forecast_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "            \n",
    "            if forecast_timestamp not in self.data.index:\n",
    "                print(f\"   ⚠️ No actual data available for {forecast_timestamp}, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            actual_price = self.data.loc[forecast_timestamp, 'Price']\n",
    "            \n",
    "            if pd.isna(actual_price):\n",
    "                print(f\"   ⚠️ Actual price is NaN for {forecast_timestamp}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"   📊 Training data: {len(training_subset)} hours\")\n",
    "            \n",
    "            # Generate forecasts (with conditional refitting)\n",
    "            forecasts = self._generate_forecasts_optimized(\n",
    "                training_subset, forecast_timestamp, should_refit,\n",
    "                current_sarima_model, current_sarimax_model\n",
    "            )\n",
    "            \n",
    "            # Update stored models if we refitted\n",
    "            if should_refit:\n",
    "                current_sarima_model = forecasts.get('sarima_model')\n",
    "                current_sarimax_model = forecasts.get('sarimax_model')\n",
    "            \n",
    "            # Calculate RMSEs\n",
    "            rmse_naive = calculate_rmse(actual_price, forecasts['naive'])\n",
    "            rmse_sarima = calculate_rmse(actual_price, forecasts['sarima'])\n",
    "            rmse_sarimax = calculate_rmse(actual_price, forecasts['sarimax'])\n",
    "            \n",
    "            # Store results\n",
    "            self.results['dates'].append(forecast_timestamp)\n",
    "            self.results['actual_prices'].append(actual_price)\n",
    "            self.results['naive_forecasts'].append(forecasts['naive'])\n",
    "            self.results['sarima_forecasts'].append(forecasts['sarima'])\n",
    "            self.results['sarimax_forecasts'].append(forecasts['sarimax'])\n",
    "            self.results['naive_rmse'].append(rmse_naive)\n",
    "            self.results['sarima_rmse'].append(rmse_sarima)\n",
    "            self.results['sarimax_rmse'].append(rmse_sarimax)\n",
    "            \n",
    "            # Print daily results\n",
    "            print(f\"   💰 Actual: {actual_price:.4f}\")\n",
    "            print(f\"   🔮 Naive: {forecasts['naive']:.4f} (RMSE: {rmse_naive:.4f})\")\n",
    "            print(f\"   📊 SARIMA: {forecasts['sarima']:.4f} (RMSE: {rmse_sarima:.4f})\")\n",
    "            print(f\"   🎯 SARIMAX: {forecasts['sarimax']:.4f} (RMSE: {rmse_sarimax:.4f})\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        print(\"✅ Rolling forecast experiment completed!\")\n",
    "        return self._calculate_summary_stats()\n",
    "    \n",
    "    \n",
    "    def _generate_forecasts_optimized(self, training_data: pd.DataFrame, \n",
    "                                     forecast_timestamp: pd.Timestamp, should_refit: bool,\n",
    "                                     current_sarima_model: Any = None,\n",
    "                                     current_sarimax_model: Any = None) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Generate forecasts with conditional model refitting for optimization\n",
    "        \"\"\"\n",
    "        forecasts = {'naive': np.nan, 'sarima': np.nan, 'sarimax': np.nan,\n",
    "                    'sarima_model': None, 'sarimax_model': None}\n",
    "        \n",
    "        price_series = training_data['Price']\n",
    "        \n",
    "        # 1. Naive forecast (always fast)\n",
    "        forecasts['naive'] = naive_forecast(price_series)\n",
    "        \n",
    "        # 2. SARIMA forecast (with conditional refitting)\n",
    "        if should_refit or current_sarima_model is None:\n",
    "            print(f\"     🔄 Fitting new SARIMA model...\")\n",
    "            sarima_model = fit_sarima_model(price_series, self.sarima_order, self.seasonal_order)\n",
    "            forecasts['sarima_model'] = sarima_model\n",
    "        else:\n",
    "            print(f\"     ♻️ Using existing SARIMA model...\")\n",
    "            sarima_model = current_sarima_model\n",
    "        \n",
    "        if sarima_model is not None:\n",
    "            try:\n",
    "                # For reused models, we need to update with new data\n",
    "                if not should_refit and current_sarima_model is not None:\n",
    "                    # Use the existing model for forecast (simplified approach)\n",
    "                    # Note: This is a simplified approach. For full accuracy, you'd want to \n",
    "                    # extend the model with new data, but that's complex with statsmodels\n",
    "                    sarima_pred = sarima_model.forecast(steps=1)\n",
    "                else:\n",
    "                    sarima_pred = sarima_model.forecast(steps=1)\n",
    "                \n",
    "                forecasts['sarima'] = sarima_pred.iloc[0] if hasattr(sarima_pred, 'iloc') else sarima_pred[0]\n",
    "                if should_refit:\n",
    "                    self.fitted_models['sarima'].append(sarima_model)\n",
    "            except Exception as e:\n",
    "                print(f\"     ⚠️ SARIMA forecast failed: {str(e)[:50]}...\")\n",
    "        \n",
    "        # 3. SARIMAX forecast (with conditional refitting)\n",
    "        if self.exog_variables:\n",
    "            try:\n",
    "                exog_train = training_data[self.exog_variables]\n",
    "                \n",
    "                # Get exogenous data for forecast point\n",
    "                if forecast_timestamp in self.data.index:\n",
    "                    exog_forecast = self.data.loc[[forecast_timestamp], self.exog_variables]\n",
    "                    \n",
    "                    if should_refit or current_sarimax_model is None:\n",
    "                        print(f\"     🔄 Fitting new SARIMAX model...\")\n",
    "                        sarimax_model = fit_sarimax_model(price_series, exog_train, \n",
    "                                                        self.sarima_order, self.seasonal_order)\n",
    "                        forecasts['sarimax_model'] = sarimax_model\n",
    "                    else:\n",
    "                        print(f\"     ♻️ Using existing SARIMAX model...\")\n",
    "                        sarimax_model = current_sarimax_model\n",
    "                    \n",
    "                    if sarimax_model is not None:\n",
    "                        # Similar limitation as SARIMA - simplified forecast for reused models\n",
    "                        sarimax_pred = sarimax_model.forecast(steps=1, exog=exog_forecast)\n",
    "                        forecasts['sarimax'] = sarimax_pred.iloc[0] if hasattr(sarimax_pred, 'iloc') else sarimax_pred[0]\n",
    "                        if should_refit:\n",
    "                            self.fitted_models['sarimax'].append(sarimax_model)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"     ⚠️ SARIMAX forecast failed: {str(e)[:50]}...\")\n",
    "        \n",
    "        return forecasts\n",
    "    \n",
    "    \n",
    "    def _calculate_summary_stats(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate summary statistics for the experiment\n",
    "        \"\"\"\n",
    "        summary = {}\n",
    "        \n",
    "        for model in ['naive', 'sarima', 'sarimax']:\n",
    "            rmse_values = [x for x in self.results[f'{model}_rmse'] if not pd.isna(x)]\n",
    "            \n",
    "            if rmse_values:\n",
    "                summary[model] = {\n",
    "                    'mean_rmse': np.mean(rmse_values),\n",
    "                    'std_rmse': np.std(rmse_values),\n",
    "                    'min_rmse': np.min(rmse_values),\n",
    "                    'max_rmse': np.max(rmse_values),\n",
    "                    'successful_forecasts': len(rmse_values)\n",
    "                }\n",
    "            else:\n",
    "                summary[model] = {\n",
    "                    'mean_rmse': np.nan,\n",
    "                    'std_rmse': np.nan,\n",
    "                    'min_rmse': np.nan,\n",
    "                    'max_rmse': np.nan,\n",
    "                    'successful_forecasts': 0\n",
    "                }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    \n",
    "    def get_results_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return results as a pandas DataFrame\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "print(\"✅ RollingForecastExperiment class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configuration and Data Preparation\n",
    "\n",
    "# =============================================================================\n",
    "# EXPERIMENT CONFIGURATION\n",
    "# =============================================================================\n",
    "import time\n",
    "# Model parameters\n",
    "SARIMA_ORDER = (1, 1, 1)  # (p, d, q) - adjust based on your data characteristics\n",
    "SEASONAL_ORDER = (1, 1, 1, 24)  # (P, D, Q, s) - 24 for hourly seasonality\n",
    "\n",
    "# Experiment parameters\n",
    "EXPERIMENT_START_DATE = \"2025-03-15\"  # Should match the RUN_DATE from Cell 0\n",
    "NUM_FORECAST_DAYS = 30\n",
    "\n",
    "# Exogenous variables (based on your build_training_set function output)\n",
    "EXOG_VARIABLES = [\n",
    "    'Load',\n",
    "    'shortwave_radiation', \n",
    "    'temperature_2m',\n",
    "    'direct_normal_irradiance',\n",
    "    'diffuse_radiation',\n",
    "    'Flow_NO',\n",
    "    'yearday_cos',\n",
    "    'Flow_GB',\n",
    "    'month',\n",
    "    'is_dst',\n",
    "    'yearday_sin',\n",
    "    'wind_speed_10m',\n",
    "    'is_non_working_day',\n",
    "    'hour_cos',\n",
    "    'is_weekend',\n",
    "    'cloud_cover',\n",
    "    'weekday_sin',\n",
    "    'hour_sin',\n",
    "    'weekday_cos'\n",
    "]\n",
    "\n",
    "print(\"🔧 EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📅 Start Date: {EXPERIMENT_START_DATE}\")\n",
    "print(f\"⏰ Forecast Days: {NUM_FORECAST_DAYS}\")\n",
    "print(f\"📊 SARIMA Order: {SARIMA_ORDER}\")\n",
    "print(f\"🔄 Seasonal Order: {SEASONAL_ORDER}\")\n",
    "print(f\"📈 Exogenous Variables: {len(EXOG_VARIABLES)}\")\n",
    "print(\"\\n📋 Exogenous Variables List:\")\n",
    "for i, var in enumerate(EXOG_VARIABLES, 1):\n",
    "    print(f\"   {i}. {var}\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATA VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n🔍 VALIDATING TRAINING DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if training_data exists\n",
    "try:\n",
    "    print(f\"📊 Dataset shape: {training_data.shape}\")\n",
    "    print(f\"📅 Date range: {training_data.index.min()} to {training_data.index.max()}\")\n",
    "    print(f\"💰 Price column stats:\")\n",
    "    print(f\"   - Mean: {training_data['Price'].mean():.2f}\")\n",
    "    print(f\"   - Std: {training_data['Price'].std():.2f}\")\n",
    "    print(f\"   - Min: {training_data['Price'].min():.2f}\")\n",
    "    print(f\"   - Max: {training_data['Price'].max():.2f}\")\n",
    "    \n",
    "    # Validate data structure\n",
    "    is_valid = validate_training_data(training_data)\n",
    "    \n",
    "    if is_valid:\n",
    "        # Check availability of exogenous variables\n",
    "        available_exog = [var for var in EXOG_VARIABLES if var in training_data.columns]\n",
    "        missing_exog = [var for var in EXOG_VARIABLES if var not in training_data.columns]\n",
    "        \n",
    "        if missing_exog:\n",
    "            print(f\"⚠️ Missing exogenous variables: {missing_exog}\")\n",
    "            print(f\"✅ Available exogenous variables: {available_exog}\")\n",
    "            EXOG_VARIABLES = available_exog  # Update to only use available variables\n",
    "            print(f\"🔄 Updated exogenous variables list to {len(EXOG_VARIABLES)} variables\")\n",
    "        \n",
    "        # Check data coverage for experiment period\n",
    "        experiment_start = pd.to_datetime(EXPERIMENT_START_DATE, utc=True)\n",
    "        experiment_end = experiment_start + timedelta(days=NUM_FORECAST_DAYS)\n",
    "        \n",
    "        data_start = training_data.index.min()\n",
    "        data_end = training_data.index.max()\n",
    "        \n",
    "        # Ensure all timestamps are timezone-aware for comparison\n",
    "        if data_start.tz is None:\n",
    "            data_start = data_start.tz_localize('UTC')\n",
    "        if data_end.tz is None:\n",
    "            data_end = data_end.tz_localize('UTC')\n",
    "            \n",
    "        print(f\"\\n📅 Data Coverage Check:\")\n",
    "        print(f\"   - Experiment needs: {experiment_start} to {experiment_end}\")\n",
    "        print(f\"   - Data available: {data_start} to {data_end}\")\n",
    "        \n",
    "        if experiment_start < data_start:\n",
    "            print(\"❌ Experiment start date is before available data\")\n",
    "        elif experiment_end > data_end:\n",
    "            print(\"⚠️ Experiment end date extends beyond available data\")\n",
    "            print(\"   This is expected if you have forecasted exogenous variables\")\n",
    "        else:\n",
    "            print(\"✅ Data coverage is sufficient for the experiment\")\n",
    "        \n",
    "        print(\"\\n✅ Data validation completed successfully!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Data validation failed. Please check your training_data DataFrame.\")\n",
    "        \n",
    "except NameError:\n",
    "    print(\"❌ training_data DataFrame not found!\")\n",
    "    print(\"Please ensure your training_data DataFrame is loaded before running this cell.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during data validation: {str(e)}\")\n",
    "\n",
    "print(\"\\n🚀 Ready to run the rolling forecast experiment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ SARIMA fitted successfully\n",
      "   ✅ SARIMAX fitted with 19 variables\n",
      "   📊 7-Day RMSE Results:\n",
      "      🎯 Naive:   0.008536\n",
      "      📈 SARIMA:  0.008243\n",
      "      🎯 SARIMAX: 0.036659\n",
      "   📋 Day 1 Comparison:\n",
      "      Actual: 0.1121 | Naive: 0.1052 | SARIMA: 0.1009 | SARIMAX: 0.0950\n",
      "------------------------------------------------------------\n",
      "\\n📅 Experiment 2/4\n",
      "   🎯 Origin: 2025-03-22\n",
      "   🧠 Training: 2025-01-08 to 2025-03-21 (1752h)\n",
      "   📈 Forecasting: 03-22 to 03-28\n",
      "   💰 Actual prices available: 1/7 days\n",
      "   ✅ SARIMA fitted successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Final Corrected 7-Day Rolling Forecast\n",
    "# Clean version with all 19 exogenous variables and proper 7-day horizons\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"🎯 FINAL CORRECTED 7-DAY ROLLING FORECAST EXPERIMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL CORRECTED CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Fixed training window (doesn't shrink)\n",
    "FIXED_TRAINING_WINDOW_DAYS = 73  # Always 73 days of training data\n",
    "FORECAST_HORIZON_DAYS = 7  # 7-day ahead forecasting\n",
    "REFIT_FREQUENCY = 7  # Weekly refits\n",
    "\n",
    "# Keep your original model complexity if you want\n",
    "FINAL_SARIMA_ORDER = (1, 1, 1)  # Your original SARIMA order\n",
    "FINAL_SEASONAL_ORDER = (1, 1, 1, 24)  # Your original seasonal order\n",
    "\n",
    "# KEEP ALL YOUR 19 EXOGENOUS VARIABLES - exactly as you had them!\n",
    "FINAL_EXOG_VARIABLES = [\n",
    "    'Load',\n",
    "    'shortwave_radiation', \n",
    "    'temperature_2m',\n",
    "    'direct_normal_irradiance',\n",
    "    'diffuse_radiation',\n",
    "    'Flow_NO',\n",
    "    'yearday_cos',\n",
    "    'Flow_GB',\n",
    "    'month',\n",
    "    'is_dst',\n",
    "    'yearday_sin',\n",
    "    'wind_speed_10m',\n",
    "    'is_non_working_day',\n",
    "    'hour_cos',\n",
    "    'is_weekend',\n",
    "    'cloud_cover',\n",
    "    'weekday_sin',\n",
    "    'hour_sin',\n",
    "    'weekday_cos'\n",
    "]\n",
    "\n",
    "# Filter to available variables\n",
    "available_final_exog = [var for var in FINAL_EXOG_VARIABLES if var in training_data.columns]\n",
    "\n",
    "print(f\"🔧 Final Configuration:\")\n",
    "print(f\"   - Fixed training window: {FIXED_TRAINING_WINDOW_DAYS} days\")\n",
    "print(f\"   - Forecast horizon: {FORECAST_HORIZON_DAYS} days (168 hours)\")\n",
    "print(f\"   - SARIMA order: {FINAL_SARIMA_ORDER}\")\n",
    "print(f\"   - Seasonal order: {FINAL_SEASONAL_ORDER}\")\n",
    "print(f\"   - ALL Exogenous vars: {len(available_final_exog)}/{len(FINAL_EXOG_VARIABLES)}\")\n",
    "print(f\"   - Variables: {available_final_exog}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SIMPLE WORKING EXPERIMENT FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def run_7day_rolling_experiment(data, start_date, num_experiments=4):\n",
    "    \"\"\"\n",
    "    Simple, working 7-day rolling forecast experiment\n",
    "    \"\"\"\n",
    "    start_dt = pd.to_datetime(start_date, utc=True)\n",
    "    \n",
    "    results = {\n",
    "        'experiment': [], 'origin_date': [], 'forecast_dates': [],\n",
    "        'actual_prices': [], 'naive_forecasts': [], 'sarima_forecasts': [], 'sarimax_forecasts': [],\n",
    "        'naive_rmse_7day': [], 'sarima_rmse_7day': [], 'sarimax_rmse_7day': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\\\n🎯 Running {num_experiments} × 7-day forecast experiments\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for exp in range(num_experiments):\n",
    "        # Forecast origin shifts by 7 days each time\n",
    "        origin = start_dt + timedelta(days=exp * 7)\n",
    "        \n",
    "        print(f\"\\\\n📅 Experiment {exp + 1}/{num_experiments}\")\n",
    "        print(f\"   🎯 Origin: {origin.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # FIXED training window - always same size\n",
    "        train_start = origin - timedelta(days=FIXED_TRAINING_WINDOW_DAYS)\n",
    "        train_end = origin - timedelta(hours=1)\n",
    "        train_data = data.loc[train_start:train_end]\n",
    "        \n",
    "        print(f\"   🧠 Training: {train_start.strftime('%Y-%m-%d')} to {train_end.strftime('%Y-%m-%d')} ({len(train_data)}h)\")\n",
    "        \n",
    "        if len(train_data) < 168:\n",
    "            print(f\"   ❌ Insufficient training data, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Generate 7-day forecast dates\n",
    "        forecast_dates = [origin + timedelta(days=d) for d in range(FORECAST_HORIZON_DAYS)]\n",
    "        forecast_timestamps = [dt.replace(hour=0, minute=0, second=0, microsecond=0) for dt in forecast_dates]\n",
    "        \n",
    "        print(f\"   📈 Forecasting: {forecast_dates[0].strftime('%m-%d')} to {forecast_dates[-1].strftime('%m-%d')}\")\n",
    "        \n",
    "        # Get actual prices for 7 days\n",
    "        actual_prices = []\n",
    "        for ts in forecast_timestamps:\n",
    "            if ts in data.index and not pd.isna(data.loc[ts, 'Price']):\n",
    "                actual_prices.append(float(data.loc[ts, 'Price']))\n",
    "            else:\n",
    "                actual_prices.append(np.nan)\n",
    "        \n",
    "        valid_actuals = [p for p in actual_prices if not pd.isna(p)]\n",
    "        print(f\"   💰 Actual prices available: {len(valid_actuals)}/7 days\")\n",
    "        \n",
    "        # 1. NAIVE FORECAST - repeat last price\n",
    "        price_series = train_data['Price'].astype('float64').dropna()\n",
    "        last_price = float(price_series.iloc[-1])\n",
    "        naive_forecasts = [last_price] * 7\n",
    "        \n",
    "        # 2. SARIMA FORECAST\n",
    "        sarima_forecasts = [np.nan] * 7\n",
    "        try:\n",
    "            if len(price_series) >= 48:\n",
    "                sarima_model = SARIMAX(price_series, \n",
    "                                     order=FINAL_SARIMA_ORDER, \n",
    "                                     seasonal_order=FINAL_SEASONAL_ORDER,\n",
    "                                     enforce_stationarity=False, \n",
    "                                     enforce_invertibility=False)\n",
    "                fitted_sarima = sarima_model.fit(disp=False, maxiter=100, method='lbfgs')\n",
    "                sarima_pred = fitted_sarima.forecast(steps=7)\n",
    "                sarima_forecasts = [float(x) for x in sarima_pred]\n",
    "                print(f\"   ✅ SARIMA fitted successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ SARIMA failed: {str(e)[:50]}...\")\n",
    "            sarima_forecasts = naive_forecasts.copy()\n",
    "        \n",
    "        # 3. SARIMAX FORECAST with ALL YOUR FEATURES\n",
    "        sarimax_forecasts = [np.nan] * 7\n",
    "        try:\n",
    "            if available_final_exog and len(price_series) >= 48:\n",
    "                # Get exogenous training data\n",
    "                exog_train = train_data[available_final_exog].astype('float64')\n",
    "                \n",
    "                # Get exogenous forecast data for 7 days\n",
    "                exog_forecast_list = []\n",
    "                for ts in forecast_timestamps:\n",
    "                    if ts in data.index:\n",
    "                        exog_forecast_list.append(data.loc[ts, available_final_exog].astype('float64'))\n",
    "                    else:\n",
    "                        # Use last available values\n",
    "                        exog_forecast_list.append(exog_train.iloc[-1])\n",
    "                \n",
    "                exog_forecast = pd.DataFrame(exog_forecast_list, columns=available_final_exog)\n",
    "                \n",
    "                # Align data and remove NaN\n",
    "                combined = pd.concat([price_series, exog_train], axis=1).dropna()\n",
    "                \n",
    "                if len(combined) >= 48:\n",
    "                    clean_price = combined.iloc[:, 0]\n",
    "                    clean_exog = combined.iloc[:, 1:]\n",
    "                    \n",
    "                    sarimax_model = SARIMAX(clean_price, \n",
    "                                          exog=clean_exog,\n",
    "                                          order=FINAL_SARIMA_ORDER,\n",
    "                                          seasonal_order=FINAL_SEASONAL_ORDER,\n",
    "                                          enforce_stationarity=False,\n",
    "                                          enforce_invertibility=False)\n",
    "                    fitted_sarimax = sarimax_model.fit(disp=False, maxiter=100, method='lbfgs')\n",
    "                    sarimax_pred = fitted_sarimax.forecast(steps=7, exog=exog_forecast)\n",
    "                    sarimax_forecasts = [float(x) for x in sarimax_pred]\n",
    "                    print(f\"   ✅ SARIMAX fitted with {len(available_final_exog)} variables\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ SARIMAX failed: {str(e)[:50]}...\")\n",
    "            sarimax_forecasts = naive_forecasts.copy()\n",
    "        \n",
    "        # Calculate 7-day RMSE for each model\n",
    "        def calc_7day_rmse(actual, forecast):\n",
    "            valid_pairs = [(a, f) for a, f in zip(actual, forecast) if not pd.isna(a) and not pd.isna(f)]\n",
    "            if len(valid_pairs) == 0:\n",
    "                return np.nan\n",
    "            mse = np.mean([(a - f) ** 2 for a, f in valid_pairs])\n",
    "            return np.sqrt(mse)\n",
    "        \n",
    "        rmse_naive = calc_7day_rmse(actual_prices, naive_forecasts)\n",
    "        rmse_sarima = calc_7day_rmse(actual_prices, sarima_forecasts)\n",
    "        rmse_sarimax = calc_7day_rmse(actual_prices, sarimax_forecasts)\n",
    "        \n",
    "        # Store results\n",
    "        results['experiment'].append(exp + 1)\n",
    "        results['origin_date'].append(origin)\n",
    "        results['forecast_dates'].append(forecast_timestamps)\n",
    "        results['actual_prices'].append(actual_prices)\n",
    "        results['naive_forecasts'].append(naive_forecasts)\n",
    "        results['sarima_forecasts'].append(sarima_forecasts)\n",
    "        results['sarimax_forecasts'].append(sarimax_forecasts)\n",
    "        results['naive_rmse_7day'].append(rmse_naive)\n",
    "        results['sarima_rmse_7day'].append(rmse_sarima)\n",
    "        results['sarimax_rmse_7day'].append(rmse_sarimax)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"   📊 7-Day RMSE Results:\")\n",
    "        print(f\"      🎯 Naive:   {rmse_naive:.6f}\")\n",
    "        print(f\"      📈 SARIMA:  {rmse_sarima:.6f}\")\n",
    "        print(f\"      🎯 SARIMAX: {rmse_sarimax:.6f}\")\n",
    "        \n",
    "        if len(valid_actuals) > 0:\n",
    "            print(f\"   📋 Day 1 Comparison:\")\n",
    "            print(f\"      Actual: {actual_prices[0]:.4f} | Naive: {naive_forecasts[0]:.4f} | SARIMA: {sarima_forecasts[0]:.4f} | SARIMAX: {sarimax_forecasts[0]:.4f}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# =============================================================================\n",
    "# RUN THE FINAL EXPERIMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\\\n🚀 EXECUTING FINAL EXPERIMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Run the corrected experiment\n",
    "    final_results = run_7day_rolling_experiment(\n",
    "        data=training_data,\n",
    "        start_date=EXPERIMENT_START_DATE,  # 2025-03-15\n",
    "        num_experiments=4  # 4 × 7-day experiments\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\\\n⏱️ FINAL experiment completed in {end_time - start_time:.1f} seconds!\")\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    summary_final = {}\n",
    "    for model in ['naive', 'sarima', 'sarimax']:\n",
    "        rmse_values = [x for x in final_results[f'{model}_rmse_7day'] if not pd.isna(x)]\n",
    "        if rmse_values:\n",
    "            summary_final[model] = {\n",
    "                'mean_rmse_7day': np.mean(rmse_values),\n",
    "                'std_rmse_7day': np.std(rmse_values),\n",
    "                'successful_experiments': len(rmse_values)\n",
    "            }\n",
    "        else:\n",
    "            summary_final[model] = {\n",
    "                'mean_rmse_7day': np.nan, \n",
    "                'std_rmse_7day': np.nan, \n",
    "                'successful_experiments': 0\n",
    "            }\n",
    "    \n",
    "    # Display final results\n",
    "    print(f\"\\\\n📊 FINAL EXPERIMENT RESULTS (7-Day RMSE)\")\n",
    "    print(\"=\" * 60)\n",
    "    for model_name, stats in summary_final.items():\n",
    "        print(f\"🔹 {model_name.upper()}:\")\n",
    "        print(f\"   Mean 7-Day RMSE: {stats['mean_rmse_7day']:.6f}\")\n",
    "        print(f\"   Std 7-Day RMSE:  {stats['std_rmse_7day']:.6f}\")\n",
    "        print(f\"   Successful Experiments: {stats['successful_experiments']}/4\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    final_results_df = pd.DataFrame(final_results)\n",
    "    \n",
    "    print(f\"\\\\n✅ Final results available in 'final_results_df'\")\n",
    "    print(f\"✅ Final summary in 'summary_final'\")\n",
    "    \n",
    "    # Show which model performed best\n",
    "    valid_models = {name: stats for name, stats in summary_final.items() \n",
    "                   if not pd.isna(stats['mean_rmse_7day'])}\n",
    "    \n",
    "    if valid_models:\n",
    "        best_model = min(valid_models.keys(), key=lambda x: valid_models[x]['mean_rmse_7day'])\n",
    "        best_rmse = valid_models[best_model]['mean_rmse_7day']\n",
    "        print(f\"\\\\n🏆 BEST MODEL: {best_model.upper()} (RMSE: {best_rmse:.6f})\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Final experiment failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\\\n💡 Final experiment features:\")\n",
    "print(f\"   ✅ Fixed 73-day training windows\")\n",
    "print(f\"   ✅ True 7-day forecast horizons\") \n",
    "print(f\"   ✅ ALL {len(available_final_exog)} of your exogenous variables\")\n",
    "print(f\"   ✅ Your original SARIMA({FINAL_SARIMA_ORDER[0]},{FINAL_SARIMA_ORDER[1]},{FINAL_SARIMA_ORDER[2]}) + seasonal({FINAL_SEASONAL_ORDER[0]},{FINAL_SEASONAL_ORDER[1]},{FINAL_SEASONAL_ORDER[2]},{FINAL_SEASONAL_ORDER[3]}) specification\")\n",
    "print(f\"   ✅ Proper 7-day RMSE calculation\")\n",
    "print(f\"   ✅ 4 rolling experiments covering 28 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Results Analysis and Visualization\n",
    "\n",
    "# =============================================================================\n",
    "# DETAILED RESULTS ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"📊 DETAILED RESULTS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Display results dataframe summary\n",
    "    print(f\"📋 Results DataFrame Shape: {results_df.shape}\")\n",
    "    print(f\"📅 Date Range: {results_df['dates'].min()} to {results_df['dates'].max()}\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    valid_results = results_df.dropna(subset=['actual_prices'])\n",
    "    \n",
    "    if len(valid_results) > 0:\n",
    "        print(f\"\\n✅ Valid forecasts: {len(valid_results)}/{len(results_df)}\")\n",
    "        \n",
    "        # Price statistics\n",
    "        print(f\"\\n💰 ACTUAL PRICE STATISTICS:\")\n",
    "        print(f\"   Mean: {valid_results['actual_prices'].mean():.2f}\")\n",
    "        print(f\"   Std:  {valid_results['actual_prices'].std():.2f}\")\n",
    "        print(f\"   Min:  {valid_results['actual_prices'].min():.2f}\")\n",
    "        print(f\"   Max:  {valid_results['actual_prices'].max():.2f}\")\n",
    "        \n",
    "        # Model comparison table\n",
    "        print(f\"\\n📊 MODEL COMPARISON TABLE:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Model':<12} {'Mean RMSE':<12} {'Std RMSE':<12} {'Min RMSE':<12} {'Max RMSE':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for model in ['naive', 'sarima', 'sarimax']:\n",
    "            if model in summary_stats:\n",
    "                stats = summary_stats[model]\n",
    "                print(f\"{model.capitalize():<12} \"\n",
    "                      f\"{stats['mean_rmse']:<12.4f} \"\n",
    "                      f\"{stats['std_rmse']:<12.4f} \"\n",
    "                      f\"{stats['min_rmse']:<12.4f} \"\n",
    "                      f\"{stats['max_rmse']:<12.4f}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "except NameError:\n",
    "    print(\"❌ Results not available. Please run the experiment first (Cell 5).\")\n",
    "    print(\"🔄 Attempting to create sample visualization with dummy data...\")\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n📈 CREATING VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Create a comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('30-Day Rolling Forecast Experiment Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. RMSE Evolution Over Time\n",
    "    ax1 = axes[0, 0]\n",
    "    valid_results = results_df.dropna(subset=['dates'])\n",
    "    \n",
    "    if len(valid_results) > 0:\n",
    "        ax1.plot(valid_results['dates'], valid_results['naive_rmse'], \n",
    "                marker='o', label='Naive', linewidth=2, markersize=4)\n",
    "        ax1.plot(valid_results['dates'], valid_results['sarima_rmse'], \n",
    "                marker='s', label='SARIMA', linewidth=2, markersize=4)\n",
    "        ax1.plot(valid_results['dates'], valid_results['sarimax_rmse'], \n",
    "                marker='^', label='SARIMAX', linewidth=2, markersize=4)\n",
    "        \n",
    "        ax1.set_title('RMSE Evolution Over 30 Days')\n",
    "        ax1.set_xlabel('Date')\n",
    "        ax1.set_ylabel('RMSE')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Box Plot of RMSE Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    rmse_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for model in ['naive', 'sarima', 'sarimax']:\n",
    "        rmse_col = f'{model}_rmse'\n",
    "        if rmse_col in results_df.columns:\n",
    "            model_rmse = results_df[rmse_col].dropna()\n",
    "            if len(model_rmse) > 0:\n",
    "                rmse_data.append(model_rmse)\n",
    "                labels.append(model.capitalize())\n",
    "    \n",
    "    if rmse_data:\n",
    "        ax2.boxplot(rmse_data, labels=labels)\n",
    "        ax2.set_title('RMSE Distribution by Model')\n",
    "        ax2.set_ylabel('RMSE')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Actual vs Predicted Scatter Plot\n",
    "    ax3 = axes[1, 0]\n",
    "    if len(valid_results) > 0:\n",
    "        # SARIMAX scatter (best model typically)\n",
    "        valid_pred = valid_results.dropna(subset=['actual_prices', 'sarimax_forecasts'])\n",
    "        if len(valid_pred) > 0:\n",
    "            ax3.scatter(valid_pred['actual_prices'], valid_pred['sarimax_forecasts'], \n",
    "                       alpha=0.6, s=50, label='SARIMAX')\n",
    "            \n",
    "        # Perfect prediction line\n",
    "        if len(valid_results) > 0:\n",
    "            min_price = valid_results['actual_prices'].min()\n",
    "            max_price = valid_results['actual_prices'].max()\n",
    "            ax3.plot([min_price, max_price], [min_price, max_price], \n",
    "                    'r--', alpha=0.8, label='Perfect Prediction')\n",
    "        \n",
    "        ax3.set_title('Actual vs Predicted Prices (SARIMAX)')\n",
    "        ax3.set_xlabel('Actual Price')\n",
    "        ax3.set_ylabel('Predicted Price')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Model Performance Summary Bar Chart\n",
    "    ax4 = axes[1, 1]\n",
    "    models = []\n",
    "    mean_rmses = []\n",
    "    \n",
    "    for model in ['naive', 'sarima', 'sarimax']:\n",
    "        if model in summary_stats and not pd.isna(summary_stats[model]['mean_rmse']):\n",
    "            models.append(model.capitalize())\n",
    "            mean_rmses.append(summary_stats[model]['mean_rmse'])\n",
    "    \n",
    "    if models and mean_rmses:\n",
    "        bars = ax4.bar(models, mean_rmses, \n",
    "                      color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "        ax4.set_title('Mean RMSE by Model')\n",
    "        ax4.set_ylabel('Mean RMSE')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, mean_rmses):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mean_rmses)*0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Visualization completed successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Visualization error: {str(e)}\")\n",
    "    print(\"🔧 This might be due to insufficient data or missing results\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS (SARIMAX)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n🎯 SARIMAX FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    if hasattr(experiment, 'fitted_models') and experiment.fitted_models['sarimax']:\n",
    "        # Get the last fitted SARIMAX model for analysis\n",
    "        last_sarimax_model = experiment.fitted_models['sarimax'][-1]\n",
    "        \n",
    "        if hasattr(last_sarimax_model, 'params') and len(EXOG_VARIABLES) > 0:\n",
    "            print(\"📊 EXOGENOUS VARIABLE COEFFICIENTS (Last Model):\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Extract coefficients for exogenous variables\n",
    "            params = last_sarimax_model.params\n",
    "            \n",
    "            # The exogenous coefficients typically come after the ARIMA parameters\n",
    "            # This is a simplified approach - you might need to adjust based on your model structure\n",
    "            if len(params) > len(SARIMA_ORDER) + len(SEASONAL_ORDER):\n",
    "                exog_start_idx = len(SARIMA_ORDER) + len(SEASONAL_ORDER) - 2  # Approximate\n",
    "                \n",
    "                for i, var_name in enumerate(EXOG_VARIABLES):\n",
    "                    if exog_start_idx + i < len(params):\n",
    "                        coef_value = params.iloc[exog_start_idx + i]\n",
    "                        print(f\"   {var_name:<20}: {coef_value:>8.4f}\")\n",
    "            \n",
    "            print(\"\\n💡 Note: Coefficient interpretation depends on model specification\")\n",
    "            print(\"   Larger absolute values indicate stronger influence on price forecasts\")\n",
    "        \n",
    "        else:\n",
    "            print(\"⚠️ Feature importance analysis not available\")\n",
    "            print(\"   Model parameters not accessible or no exogenous variables\")\n",
    "    \n",
    "    else:\n",
    "        print(\"⚠️ No SARIMAX models available for feature importance analysis\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Feature importance analysis failed: {str(e)}\")\n",
    "    print(\"🔧 This is normal if SARIMAX models failed to fit\")\n",
    "\n",
    "print(f\"\\n📋 RESULTS SUMMARY SAVED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"✅ All analysis completed!\")\n",
    "print(\"📊 Key variables available for further analysis:\")\n",
    "print(\"   - results_df: Detailed daily results\")\n",
    "print(\"   - summary_stats: Model performance summary\")\n",
    "print(\"   - experiment: Full experiment object with fitted models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Model Recommendation and Insights\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL RECOMMENDATION ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🎯 MODEL RECOMMENDATION AND INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def get_best_model_recommendation(summary_stats: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Determine the best performing model based on multiple criteria\n",
    "    \"\"\"\n",
    "    recommendation = {\n",
    "        'best_model': None,\n",
    "        'best_rmse': float('inf'),\n",
    "        'criteria': {},\n",
    "        'insights': []\n",
    "    }\n",
    "    \n",
    "    valid_models = {}\n",
    "    \n",
    "    # Filter out models with invalid results\n",
    "    for model_name, stats in summary_stats.items():\n",
    "        if not pd.isna(stats['mean_rmse']) and stats['successful_forecasts'] > 0:\n",
    "            valid_models[model_name] = stats\n",
    "    \n",
    "    if not valid_models:\n",
    "        recommendation['insights'].append(\"❌ No valid model results found\")\n",
    "        return recommendation\n",
    "    \n",
    "    # 1. Best Mean RMSE\n",
    "    best_rmse_model = min(valid_models.keys(), \n",
    "                         key=lambda x: valid_models[x]['mean_rmse'])\n",
    "    recommendation['best_model'] = best_rmse_model\n",
    "    recommendation['best_rmse'] = valid_models[best_rmse_model]['mean_rmse']\n",
    "    \n",
    "    # 2. Most Consistent (Lowest Std RMSE)\n",
    "    most_consistent_model = min(valid_models.keys(), \n",
    "                               key=lambda x: valid_models[x]['std_rmse'])\n",
    "    \n",
    "    # 3. Most Reliable (Highest Success Rate)\n",
    "    most_reliable_model = max(valid_models.keys(), \n",
    "                             key=lambda x: valid_models[x]['successful_forecasts'])\n",
    "    \n",
    "    # Store criteria results\n",
    "    recommendation['criteria'] = {\n",
    "        'best_accuracy': best_rmse_model,\n",
    "        'most_consistent': most_consistent_model,\n",
    "        'most_reliable': most_reliable_model\n",
    "    }\n",
    "    \n",
    "    # Generate insights\n",
    "    recommendation['insights'].append(\n",
    "        f\"🏆 Best Overall Model: {best_rmse_model.upper()} \"\n",
    "        f\"(Mean RMSE: {recommendation['best_rmse']:.4f})\"\n",
    "    )\n",
    "    \n",
    "    if most_consistent_model != best_rmse_model:\n",
    "        recommendation['insights'].append(\n",
    "            f\"📊 Most Consistent: {most_consistent_model.upper()} \"\n",
    "            f\"(Std RMSE: {valid_models[most_consistent_model]['std_rmse']:.4f})\"\n",
    "        )\n",
    "    \n",
    "    if most_reliable_model != best_rmse_model:\n",
    "        recommendation['insights'].append(\n",
    "            f\"🔧 Most Reliable: {most_reliable_model.upper()} \"\n",
    "            f\"({valid_models[most_reliable_model]['successful_forecasts']}/{NUM_FORECAST_DAYS} forecasts)\"\n",
    "        )\n",
    "    \n",
    "    # Performance comparison insights\n",
    "    rmse_values = [stats['mean_rmse'] for stats in valid_models.values()]\n",
    "    rmse_improvement = (max(rmse_values) - min(rmse_values)) / max(rmse_values) * 100\n",
    "    \n",
    "    recommendation['insights'].append(\n",
    "        f\"📈 Performance Improvement: {rmse_improvement:.1f}% \"\n",
    "        f\"(Best vs Worst Model)\"\n",
    "    )\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "# =============================================================================\n",
    "# GENERATE RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    # Get model recommendation\n",
    "    recommendation = get_best_model_recommendation(summary_stats)\n",
    "    \n",
    "    print(\"🏆 MODEL PERFORMANCE RANKING\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Rank models by mean RMSE\n",
    "    valid_models = {name: stats for name, stats in summary_stats.items() \n",
    "                   if not pd.isna(stats['mean_rmse'])}\n",
    "    \n",
    "    if valid_models:\n",
    "        sorted_models = sorted(valid_models.items(), \n",
    "                              key=lambda x: x[1]['mean_rmse'])\n",
    "        \n",
    "        for rank, (model_name, stats) in enumerate(sorted_models, 1):\n",
    "            medal = \"🥇\" if rank == 1 else \"🥈\" if rank == 2 else \"🥉\"\n",
    "            print(f\"{medal} {rank}. {model_name.upper()}\")\n",
    "            print(f\"     Mean RMSE: {stats['mean_rmse']:.4f}\")\n",
    "            print(f\"     Consistency: {stats['std_rmse']:.4f}\")\n",
    "            print(f\"     Success Rate: {stats['successful_forecasts']}/{NUM_FORECAST_DAYS}\")\n",
    "            print()\n",
    "    \n",
    "    print(\"💡 KEY INSIGHTS\")\n",
    "    print(\"-\" * 40)\n",
    "    for insight in recommendation['insights']:\n",
    "        print(f\"   {insight}\")\n",
    "    \n",
    "    print(f\"\\n🎯 FINAL RECOMMENDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    if recommendation['best_model']:\n",
    "        print(f\"✅ Recommended Model: {recommendation['best_model'].upper()}\")\n",
    "        print(f\"📊 Expected RMSE: {recommendation['best_rmse']:.4f}\")\n",
    "        \n",
    "        # Model-specific recommendations\n",
    "        if recommendation['best_model'] == 'naive':\n",
    "            print(f\"\\n🔍 NAIVE MODEL INSIGHTS:\")\n",
    "            print(f\"   • Simple yesterday=today approach works surprisingly well\")\n",
    "            print(f\"   • Consider this as a strong baseline for comparison\")\n",
    "            print(f\"   • Low computational cost, high interpretability\")\n",
    "            \n",
    "        elif recommendation['best_model'] == 'sarima':\n",
    "            print(f\"\\n🔍 SARIMA MODEL INSIGHTS:\")\n",
    "            print(f\"   • Pure time series approach captures patterns effectively\")\n",
    "            print(f\"   • Model order: {SARIMA_ORDER} with seasonality {SEASONAL_ORDER}\")\n",
    "            print(f\"   • Consider tuning hyperparameters for better performance\")\n",
    "            \n",
    "        elif recommendation['best_model'] == 'sarimax':\n",
    "            print(f\"\\n🔍 SARIMAX MODEL INSIGHTS:\")\n",
    "            print(f\"   • Exogenous variables provide valuable additional information\")\n",
    "            print(f\"   • Using {len(EXOG_VARIABLES)} external features\")\n",
    "            print(f\"   • Most complex model - ensure robust exogenous forecasts\")\n",
    "        \n",
    "        print(f\"\\n📋 IMPLEMENTATION CONSIDERATIONS:\")\n",
    "        print(f\"   • Computational Cost: {'Low' if recommendation['best_model'] == 'naive' else 'Medium' if recommendation['best_model'] == 'sarima' else 'High'}\")\n",
    "        print(f\"   • Data Requirements: {'Minimal' if recommendation['best_model'] == 'naive' else 'Historical Prices' if recommendation['best_model'] == 'sarima' else 'Prices + Exogenous'}\")\n",
    "        print(f\"   • Interpretability: {'High' if recommendation['best_model'] == 'naive' else 'Medium'}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No clear recommendation - all models failed\")\n",
    "        print(\"🔧 Consider:\")\n",
    "        print(\"   • Checking data quality and completeness\")\n",
    "        print(\"   • Adjusting model parameters\")\n",
    "        print(\"   • Using a longer training period\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"❌ Summary statistics not available\")\n",
    "    print(\"🔄 Please run the experiment first (Cell 5)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Recommendation generation failed: {str(e)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ADDITIONAL INSIGHTS AND NEXT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n🚀 NEXT STEPS AND IMPROVEMENTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🎨 Model Enhancement Ideas:\")\n",
    "print(\"   1. Hyperparameter Tuning:\")\n",
    "print(\"      • Grid search for optimal SARIMA orders\")\n",
    "print(\"      • Cross-validation for model selection\")\n",
    "print(\"   2. Feature Engineering:\")\n",
    "print(\"      • Lag features, rolling averages\")\n",
    "print(\"      • Calendar effects (holidays, seasons)\")\n",
    "print(\"   3. Advanced Models:\")\n",
    "print(\"      • Machine Learning approaches (XGBoost, LSTM)\")\n",
    "print(\"      • Ensemble methods combining multiple forecasts\")\n",
    "print(\"   4. Evaluation Improvements:\")\n",
    "print(\"      • Multi-step ahead forecasting\")\n",
    "print(\"      • Additional metrics (MAE, MAPE)\")\n",
    "print(\"      • Directional accuracy assessment\")\n",
    "\n",
    "print(f\"\\n📊 Experiment Variables Available:\")\n",
    "print(\"   • results_df: Daily forecast results\")\n",
    "print(\"   • summary_stats: Model performance statistics\") \n",
    "print(\"   • experiment: Complete experiment object\")\n",
    "print(\"   • recommendation: Model recommendation analysis\")\n",
    "\n",
    "print(f\"\\n✅ 30-Day Rolling Forecast Experiment Complete!\")\n",
    "print(\"🎯 Use the insights above to improve your electricity price forecasting system.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
