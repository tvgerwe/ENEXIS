{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 12:04:59,979 - build_training_set - INFO - üöÄ Start build van trainingset\n",
      "2025-05-30 12:04:59,986 - build_training_set - INFO - üß† Actuals van 2025-01-01 00:00:00+00:00 t/m 2025-03-14 23:00:00+00:00\n",
      "2025-05-30 12:05:00,011 - build_training_set - INFO - üìÖ Forecast van run_date 2025-03-15 12:00:00+00:00, target range: 2025-03-15 12:00:00+00:00 ‚Üí 2025-03-22 11:00:00+00:00\n",
      "2025-05-30 12:05:00,012 - build_training_set - INFO - üì• Loading actuals with selected columns only...\n",
      "2025-05-30 12:05:00,014 - build_training_set - INFO - üìã Requested columns found: 20/20\n",
      "2025-05-30 12:05:00,015 - build_training_set - INFO - üìã Using columns: ['Price', 'target_datetime', 'Load', 'shortwave_radiation', 'temperature_2m', 'direct_normal_irradiance', 'diffuse_radiation', 'Flow_NO', 'yearday_cos', 'Flow_GB', 'month', 'is_dst', 'yearday_sin', 'is_non_working_day', 'hour_cos', 'is_weekend', 'cloud_cover', 'weekday_sin', 'hour_sin', 'weekday_cos']\n",
      "2025-05-30 12:05:00,031 - build_training_set - INFO - ‚úÖ Actuals loaded: 1752 rows with 20 selected columns\n",
      "2025-05-30 12:05:00,032 - build_training_set - INFO - üîç Checking for forecast data...\n",
      "2025-05-30 12:05:00,036 - build_training_set - INFO - üìä Forecast rows available: 0\n",
      "2025-05-30 12:05:00,038 - build_training_set - INFO - üì¶ Final table: 1752 rows, 20 columns\n",
      "2025-05-30 12:05:00,038 - build_training_set - INFO - üßæ Final columns: ['Price', 'target_datetime', 'Load', 'shortwave_radiation', 'temperature_2m', 'direct_normal_irradiance', 'diffuse_radiation', 'Flow_NO', 'yearday_cos', 'Flow_GB', 'month', 'is_dst', 'yearday_sin', 'is_non_working_day', 'hour_cos', 'is_weekend', 'cloud_cover', 'weekday_sin', 'hour_sin', 'weekday_cos']\n",
      "2025-05-30 12:05:00,039 - build_training_set - INFO - üí∞ Price NaN count: 0/1752 (0.0%)\n",
      "2025-05-30 12:05:00,041 - build_training_set - INFO - ‚úÖ All columns have good data quality (<20% NaN)\n",
      "2025-05-30 12:05:00,048 - build_training_set - INFO - ‚úÖ Saved as training_set in WARP.db\n",
      "2025-05-30 12:05:00,049 - build_training_set - INFO - üîí Connection closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 1752 rows, ends 2025-03-14\n",
      "Validation: 2025-03-15 to 2025-04-14 (30 days)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - Imports & Dynamic Validation Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import sqlite3\n",
    "import json\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "current_dir = Path.cwd()\n",
    "if \"ENEXIS\" in str(current_dir):\n",
    "    while current_dir.name != \"ENEXIS\" and current_dir.parent != current_dir:\n",
    "        current_dir = current_dir.parent\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "from utils.build_training_set import build_training_set\n",
    "\n",
    "# Load training data\n",
    "training_data = build_training_set(\n",
    "    train_start=\"2025-01-01 00:00:00\",\n",
    "    train_end=\"2025-03-14 23:00:00\",\n",
    "    run_date=\"2025-03-15 12:00:00\"\n",
    ").set_index('target_datetime')\n",
    "training_data.index = pd.to_datetime(training_data.index, utc=True)\n",
    "\n",
    "def load_validation_data(start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Load actual price data from master_warp table\"\"\"\n",
    "    db_path = project_root / \"src\" / \"data\" / \"WARP.db\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    query = \"SELECT target_datetime, Price FROM master_warp WHERE target_datetime >= ? AND target_datetime <= ? ORDER BY target_datetime\"\n",
    "    validation_data = pd.read_sql_query(query, conn, params=[start_date, end_date], parse_dates=['target_datetime'])\n",
    "    conn.close()\n",
    "    \n",
    "    if len(validation_data) > 0:\n",
    "        validation_data = validation_data.set_index('target_datetime')\n",
    "        validation_data.index = pd.to_datetime(validation_data.index, utc=True)\n",
    "        return validation_data\n",
    "    return None\n",
    "\n",
    "# Calculate validation periods\n",
    "train_end = training_data.index.max()\n",
    "validation_start = train_end + timedelta(hours=1)\n",
    "validation_end = validation_start + timedelta(days=30)\n",
    "\n",
    "print(f\"Training: {training_data.shape[0]} rows, ends {train_end.date()}\")\n",
    "print(f\"Validation: {validation_start.date()} to {validation_end.date()} (30 days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimized: order=(2, 0, 0), seasonal=(1, 1, 0, 24)\n",
      "Exog variables: 18/18\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Model Configuration\n",
    "\n",
    "EXOG_VARS = [\n",
    "    'Load', 'shortwave_radiation', 'temperature_2m', 'direct_normal_irradiance', \n",
    "    'diffuse_radiation', 'Flow_NO', 'yearday_cos', 'Flow_GB', 'month', 'is_dst', \n",
    "    'yearday_sin', 'is_non_working_day', 'hour_cos', 'is_weekend', 'cloud_cover', \n",
    "    'weekday_sin', 'hour_sin', 'weekday_cos'\n",
    "]\n",
    "\n",
    "available_exog = [col for col in EXOG_VARS if col in training_data.columns]\n",
    "\n",
    "# Load your optimized SARIMAX parameters\n",
    "config_file = project_root / \"src\" / \"config\" / \"best_sarimax_params.json\"\n",
    "if config_file.exists():\n",
    "    with open(config_file, 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    current_order = tuple(best_params['order'])\n",
    "    current_seasonal = tuple(best_params['seasonal_order'])\n",
    "    print(f\"Using optimized: order={current_order}, seasonal={current_seasonal}\")\n",
    "else:\n",
    "    # Fallback defaults\n",
    "    current_order = (1, 0, 1)\n",
    "    current_seasonal = (1, 1, 1, 24)\n",
    "    print(f\"Using defaults: order={current_order}, seasonal={current_seasonal}\")\n",
    "\n",
    "print(f\"Exog variables: {len(available_exog)}/{len(EXOG_VARS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 30-day rolling window validation...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - 30 Day Rolling Window Validation (Notebook, Threaded)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def validate_single_day(day, training_data, exog_vars, forecast_days, current_order, current_seasonal):\n",
    "    \"\"\"\n",
    "    Voert een rolling window forecast uit voor 1 dag.\n",
    "    \"\"\"\n",
    "    train_end = training_data.index.max()\n",
    "    forecast_start = train_end + timedelta(days=day, hours=1)\n",
    "    forecast_end = forecast_start + timedelta(days=forecast_days-1, hours=23)\n",
    "    try:\n",
    "        # Haal validatie data op\n",
    "        validation_data = load_validation_data(\n",
    "            forecast_start.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            forecast_end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        )\n",
    "        if validation_data is None or len(validation_data) == 0:\n",
    "            return {'Day': day+1, 'Date': forecast_start.date(), 'Naive': np.nan, 'SARIMA': np.nan, 'SARIMAX': np.nan, 'Status': 'NO_DATA'}\n",
    "        # Training window tot aan de voorspeldatum\n",
    "        train_cutoff = forecast_start - timedelta(hours=1)\n",
    "        train_data = training_data[training_data.index <= train_cutoff]\n",
    "        if len(train_data) < 168:\n",
    "            return {'Day': day+1, 'Date': forecast_start.date(), 'Naive': np.nan, 'SARIMA': np.nan, 'SARIMAX': np.nan, 'Status': 'INSUFFICIENT_TRAIN'}\n",
    "        y_actual = validation_data['Price']\n",
    "        forecast_hours = len(y_actual)\n",
    "        result = {'Day': day+1, 'Date': forecast_start.date(), 'Status': 'SUCCESS'}\n",
    "        # NAIVE\n",
    "        try:\n",
    "            y_train = train_data['Price']\n",
    "            naive_forecast = [y_train.iloc[-(168 - h % 168)] if len(y_train) >= 168 else y_train.iloc[-1] for h in range(forecast_hours)]\n",
    "            result['Naive'] = np.sqrt(mean_squared_error(y_actual, naive_forecast))\n",
    "        except Exception:\n",
    "            result['Naive'] = np.nan\n",
    "        # SARIMA\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                sarima_model = SARIMAX(\n",
    "                    train_data['Price'],\n",
    "                    order=current_order,\n",
    "                    seasonal_order=current_seasonal,\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False\n",
    "                )\n",
    "                fitted_sarima = sarima_model.fit(method='lbfgs', maxiter=15, disp=False)\n",
    "                sarima_forecast = fitted_sarima.forecast(steps=forecast_hours)\n",
    "                result['SARIMA'] = np.sqrt(mean_squared_error(y_actual, sarima_forecast))\n",
    "        except Exception:\n",
    "            result['SARIMA'] = np.nan\n",
    "        # SARIMAX\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                # Exog voor validatie (herhaal laatste week features)\n",
    "                future_exog = pd.DataFrame(index=validation_data.index, columns=exog_vars)\n",
    "                recent_exog = train_data[exog_vars].iloc[-168:]\n",
    "                for i in range(forecast_hours):\n",
    "                    future_exog.iloc[i] = recent_exog.iloc[i % len(recent_exog)]\n",
    "                sarimax_model = SARIMAX(\n",
    "                    train_data['Price'],\n",
    "                    exog=train_data[exog_vars],\n",
    "                    order=current_order,\n",
    "                    seasonal_order=current_seasonal,\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False\n",
    "                )\n",
    "                fitted_sarimax = sarimax_model.fit(method='lbfgs', maxiter=15, disp=False)\n",
    "                sarimax_forecast = fitted_sarimax.forecast(steps=forecast_hours, exog=future_exog)\n",
    "                result['SARIMAX'] = np.sqrt(mean_squared_error(y_actual, sarimax_forecast))\n",
    "        except Exception:\n",
    "            result['SARIMAX'] = np.nan\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {'Day': day+1, 'Date': forecast_start.date(), 'Naive': np.nan, 'SARIMA': np.nan, 'SARIMAX': np.nan, 'Status': f'ERROR: {str(e)[:50]}'}\n",
    "\n",
    "# -------- Rolling Validation --------\n",
    "\n",
    "n_days = 30\n",
    "forecast_days = 7\n",
    "max_workers = 4  # Pas aan op je laptop/VM (4-6 optimaal)\n",
    "\n",
    "print(\"Running 30-day rolling window validation...\")\n",
    "start_time = time.time()\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_to_day = {\n",
    "        executor.submit(\n",
    "            validate_single_day, day, training_data, available_exog, forecast_days, current_order, current_seasonal\n",
    "        ): day for day in range(n_days)\n",
    "    }\n",
    "    for future in as_completed(future_to_day):\n",
    "        day = future_to_day[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            naive_str = f\"N:{result['Naive']:.4f}\" if not pd.isna(result['Naive']) else \"N:FAIL\"\n",
    "            sarima_str = f\"S:{result['SARIMA']:.4f}\" if not pd.isna(result['SARIMA']) else \"S:FAIL\"\n",
    "            sarimax_str = f\"X:{result['SARIMAX']:.4f}\" if not pd.isna(result['SARIMAX']) else \"X:FAIL\"\n",
    "            print(f\"Day {result['Day']:2d}: {result['Date']} | {naive_str} | {sarima_str} | {sarimax_str}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Day {day+1:2d}: FAILED ({str(e)[:30]})\")\n",
    "            results.append({'Day': day+1, 'Status': 'FAILED'})\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "# DataFrame sorteren en samenvatten\n",
    "results_df = pd.DataFrame(results).sort_values('Day').reset_index(drop=True)\n",
    "print(f\"\\nValidation completed in {elapsed_time:.1f} seconds\")\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
