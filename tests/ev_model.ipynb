{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "üìä Pandas version: 2.2.3\n",
      "üìà Matplotlib version: 3.7.5\n",
      "üöÄ Ready to start rolling forecast experiment!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "# Statistical modeling\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üìà Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(\"üöÄ Ready to start rolling forecast experiment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "def naive_forecast(historical_data: pd.Series, steps_ahead: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Naive benchmark: yesterday's price = today's prediction\n",
    "    \n",
    "    Args:\n",
    "        historical_data: Time series of historical prices\n",
    "        steps_ahead: Number of steps to forecast (default=1 for next hour)\n",
    "    \n",
    "    Returns:\n",
    "        Forecasted value (last observed value)\n",
    "    \"\"\"\n",
    "    if len(historical_data) == 0:\n",
    "        return np.nan\n",
    "    return historical_data.iloc[-1]\n",
    "\n",
    "\n",
    "def fit_sarima_model(data: pd.Series, order: Tuple[int, int, int], \n",
    "                     seasonal_order: Tuple[int, int, int, int]) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Fit SARIMA model with error handling\n",
    "    \n",
    "    Args:\n",
    "        data: Time series data\n",
    "        order: (p, d, q) parameters\n",
    "        seasonal_order: (P, D, Q, s) parameters\n",
    "    \n",
    "    Returns:\n",
    "        Fitted SARIMAX model or None if fitting fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SARIMAX(data, \n",
    "                       order=order, \n",
    "                       seasonal_order=seasonal_order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "        \n",
    "        fitted_model = model.fit(disp=False, maxiter=100)\n",
    "        return fitted_model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è SARIMA fitting failed: {str(e)[:100]}...\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fit_sarimax_model(endog: pd.Series, exog: pd.DataFrame, \n",
    "                      order: Tuple[int, int, int], \n",
    "                      seasonal_order: Tuple[int, int, int, int]) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Fit SARIMAX model with exogenous variables\n",
    "    \n",
    "    Args:\n",
    "        endog: Target time series\n",
    "        exog: Exogenous variables DataFrame\n",
    "        order: (p, d, q) parameters\n",
    "        seasonal_order: (P, D, Q, s) parameters\n",
    "    \n",
    "    Returns:\n",
    "        Fitted SARIMAX model or None if fitting fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SARIMAX(endog, \n",
    "                       exog=exog,\n",
    "                       order=order, \n",
    "                       seasonal_order=seasonal_order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "        \n",
    "        fitted_model = model.fit(disp=False, maxiter=100)\n",
    "        return fitted_model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è SARIMAX fitting failed: {str(e)[:100]}...\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_rmse(actual: float, predicted: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Root Mean Square Error for single point\n",
    "    \n",
    "    Args:\n",
    "        actual: Actual observed value\n",
    "        predicted: Predicted value\n",
    "    \n",
    "    Returns:\n",
    "        RMSE value\n",
    "    \"\"\"\n",
    "    if pd.isna(actual) or pd.isna(predicted):\n",
    "        return np.nan\n",
    "    return np.sqrt((actual - predicted) ** 2)\n",
    "\n",
    "\n",
    "def validate_training_data(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    Validate the structure of training_data DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: Training data DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        True if validation passes, False otherwise\n",
    "    \"\"\"\n",
    "    required_cols = ['Price']\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"‚ùå Missing required columns: {missing_cols}\")\n",
    "        return False\n",
    "    \n",
    "    # Check if index is datetime\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        print(\"‚ùå Index must be DatetimeIndex\")\n",
    "        return False\n",
    "    \n",
    "    # Check for missing values in Price column\n",
    "    if df['Price'].isna().any():\n",
    "        print(\"‚ùå Price column contains NaN values\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úÖ Training data validation passed!\")\n",
    "    return True\n",
    "\n",
    "print(\"‚úÖ Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RollingForecastExperiment class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Main Rolling Forecast Class\n",
    "\n",
    "class RollingForecastExperiment:\n",
    "    \"\"\"\n",
    "    Implements 30-day rolling forecast experiment for electricity price forecasting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, training_data: pd.DataFrame, \n",
    "                 sarima_order: Tuple[int, int, int] = (1, 1, 1),\n",
    "                 seasonal_order: Tuple[int, int, int, int] = (1, 1, 1, 24),\n",
    "                 exog_variables: List[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the rolling forecast experiment\n",
    "        \n",
    "        Args:\n",
    "            training_data: DataFrame with Price and exogenous variables\n",
    "            sarima_order: (p, d, q) parameters for SARIMA\n",
    "            seasonal_order: (P, D, Q, s) parameters for seasonal component\n",
    "            exog_variables: List of exogenous variable column names\n",
    "        \"\"\"\n",
    "        self.data = training_data.copy()\n",
    "        self.sarima_order = sarima_order\n",
    "        self.seasonal_order = seasonal_order\n",
    "        self.exog_variables = exog_variables or []\n",
    "        \n",
    "        # Results storage\n",
    "        self.results = {\n",
    "            'dates': [],\n",
    "            'actual_prices': [],\n",
    "            'naive_forecasts': [],\n",
    "            'sarima_forecasts': [],\n",
    "            'sarimax_forecasts': [],\n",
    "            'naive_rmse': [],\n",
    "            'sarima_rmse': [],\n",
    "            'sarimax_rmse': []\n",
    "        }\n",
    "        \n",
    "        # Model storage for analysis\n",
    "        self.fitted_models = {\n",
    "            'sarima': [],\n",
    "            'sarimax': []\n",
    "        }\n",
    "        \n",
    "        print(f\"üîß Experiment initialized:\")\n",
    "        print(f\"   - SARIMA order: {sarima_order}\")\n",
    "        print(f\"   - Seasonal order: {seasonal_order}\")\n",
    "        print(f\"   - Exogenous variables: {len(self.exog_variables)}\")\n",
    "    \n",
    "    \n",
    "    def get_actual_data_end_date(self) -> pd.Timestamp:\n",
    "        \"\"\"\n",
    "        Find the last date with actual price data (not forecasted)\n",
    "        Assumes forecasted data has been appended to the end\n",
    "        \"\"\"\n",
    "        # This is a heuristic - you might need to adjust based on your data structure\n",
    "        # Look for the last non-interpolated or non-repeated price pattern\n",
    "        price_series = self.data['Price']\n",
    "        \n",
    "        # Simple approach: assume actual data is complete up to a certain point\n",
    "        # You may need to modify this based on your specific data structure\n",
    "        return price_series.index[-169]  # Assuming last 168 hours are forecasted\n",
    "    \n",
    "    \n",
    "    def run_experiment(self, start_date: str, num_days: int = 30) -> Dict:\n",
    "        \"\"\"\n",
    "        Run the rolling forecast experiment\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date for the experiment (YYYY-MM-DD)\n",
    "            num_days: Number of days to forecast\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with experiment results\n",
    "        \"\"\"\n",
    "        start_dt = pd.to_datetime(start_date)\n",
    "        \n",
    "        print(f\"üöÄ Starting {num_days}-day rolling forecast experiment from {start_date}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for day in range(num_days):\n",
    "            forecast_date = start_dt + timedelta(days=day)\n",
    "            \n",
    "            print(f\"üìÖ Day {day + 1}/{num_days}: Forecasting for {forecast_date.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            # Get training data up to (but not including) forecast date\n",
    "            train_end = forecast_date - timedelta(hours=1)\n",
    "            training_subset = self.data.loc[:train_end]\n",
    "            \n",
    "            if len(training_subset) < 168:  # Need at least 1 week of data\n",
    "                print(f\"   ‚ö†Ô∏è Insufficient training data, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Get actual value for forecast date (first hour of the day)\n",
    "            forecast_timestamp = forecast_date.replace(hour=0, minute=0, second=0)\n",
    "            \n",
    "            if forecast_timestamp not in self.data.index:\n",
    "                print(f\"   ‚ö†Ô∏è No actual data available for {forecast_timestamp}, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            actual_price = self.data.loc[forecast_timestamp, 'Price']\n",
    "            \n",
    "            # Generate forecasts from each model\n",
    "            forecasts = self._generate_forecasts(training_subset, forecast_timestamp)\n",
    "            \n",
    "            # Calculate RMSEs\n",
    "            rmse_naive = calculate_rmse(actual_price, forecasts['naive'])\n",
    "            rmse_sarima = calculate_rmse(actual_price, forecasts['sarima'])\n",
    "            rmse_sarimax = calculate_rmse(actual_price, forecasts['sarimax'])\n",
    "            \n",
    "            # Store results\n",
    "            self.results['dates'].append(forecast_timestamp)\n",
    "            self.results['actual_prices'].append(actual_price)\n",
    "            self.results['naive_forecasts'].append(forecasts['naive'])\n",
    "            self.results['sarima_forecasts'].append(forecasts['sarima'])\n",
    "            self.results['sarimax_forecasts'].append(forecasts['sarimax'])\n",
    "            self.results['naive_rmse'].append(rmse_naive)\n",
    "            self.results['sarima_rmse'].append(rmse_sarima)\n",
    "            self.results['sarimax_rmse'].append(rmse_sarimax)\n",
    "            \n",
    "            # Print daily results\n",
    "            print(f\"   üí∞ Actual: {actual_price:.2f}\")\n",
    "            print(f\"   üîÆ Naive: {forecasts['naive']:.2f} (RMSE: {rmse_naive:.2f})\")\n",
    "            print(f\"   üìä SARIMA: {forecasts['sarima']:.2f} (RMSE: {rmse_sarima:.2f})\")\n",
    "            print(f\"   üéØ SARIMAX: {forecasts['sarimax']:.2f} (RMSE: {rmse_sarimax:.2f})\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        print(\"‚úÖ Rolling forecast experiment completed!\")\n",
    "        return self._calculate_summary_stats()\n",
    "    \n",
    "    \n",
    "    def _generate_forecasts(self, training_data: pd.DataFrame, \n",
    "                          forecast_timestamp: pd.Timestamp) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Generate forecasts from all three models\n",
    "        \"\"\"\n",
    "        forecasts = {'naive': np.nan, 'sarima': np.nan, 'sarimax': np.nan}\n",
    "        \n",
    "        price_series = training_data['Price']\n",
    "        \n",
    "        # 1. Naive forecast\n",
    "        forecasts['naive'] = naive_forecast(price_series)\n",
    "        \n",
    "        # 2. SARIMA forecast\n",
    "        sarima_model = fit_sarima_model(price_series, self.sarima_order, self.seasonal_order)\n",
    "        if sarima_model is not None:\n",
    "            try:\n",
    "                sarima_pred = sarima_model.forecast(steps=1)\n",
    "                forecasts['sarima'] = sarima_pred.iloc[0] if hasattr(sarima_pred, 'iloc') else sarima_pred[0]\n",
    "                self.fitted_models['sarima'].append(sarima_model)\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è SARIMA forecast failed: {str(e)[:50]}...\")\n",
    "        \n",
    "        # 3. SARIMAX forecast\n",
    "        if self.exog_variables:\n",
    "            try:\n",
    "                exog_train = training_data[self.exog_variables]\n",
    "                \n",
    "                # Get exogenous data for forecast point\n",
    "                if forecast_timestamp in self.data.index:\n",
    "                    exog_forecast = self.data.loc[[forecast_timestamp], self.exog_variables]\n",
    "                    \n",
    "                    sarimax_model = fit_sarimax_model(price_series, exog_train, \n",
    "                                                    self.sarima_order, self.seasonal_order)\n",
    "                    if sarimax_model is not None:\n",
    "                        sarimax_pred = sarimax_model.forecast(steps=1, exog=exog_forecast)\n",
    "                        forecasts['sarimax'] = sarimax_pred.iloc[0] if hasattr(sarimax_pred, 'iloc') else sarimax_pred[0]\n",
    "                        self.fitted_models['sarimax'].append(sarimax_model)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è SARIMAX forecast failed: {str(e)[:50]}...\")\n",
    "        \n",
    "        return forecasts\n",
    "    \n",
    "    \n",
    "    def _calculate_summary_stats(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate summary statistics for the experiment\n",
    "        \"\"\"\n",
    "        summary = {}\n",
    "        \n",
    "        for model in ['naive', 'sarima', 'sarimax']:\n",
    "            rmse_values = [x for x in self.results[f'{model}_rmse'] if not pd.isna(x)]\n",
    "            \n",
    "            if rmse_values:\n",
    "                summary[model] = {\n",
    "                    'mean_rmse': np.mean(rmse_values),\n",
    "                    'std_rmse': np.std(rmse_values),\n",
    "                    'min_rmse': np.min(rmse_values),\n",
    "                    'max_rmse': np.max(rmse_values),\n",
    "                    'successful_forecasts': len(rmse_values)\n",
    "                }\n",
    "            else:\n",
    "                summary[model] = {\n",
    "                    'mean_rmse': np.nan,\n",
    "                    'std_rmse': np.nan,\n",
    "                    'min_rmse': np.nan,\n",
    "                    'max_rmse': np.nan,\n",
    "                    'successful_forecasts': 0\n",
    "                }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    \n",
    "    def get_results_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Return results as a pandas DataFrame\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(self.results)\n",
    "\n",
    "print(\"‚úÖ RollingForecastExperiment class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß EXPERIMENT CONFIGURATION\n",
      "==================================================\n",
      "üìÖ Start Date: 2024-03-15\n",
      "‚è∞ Forecast Days: 30\n",
      "üìä SARIMA Order: (1, 1, 1)\n",
      "üîÑ Seasonal Order: (1, 1, 1, 24)\n",
      "üìà Exogenous Variables: 18\n",
      "\n",
      "üìã Exogenous Variables List:\n",
      "   1. Load\n",
      "   2. shortwave_radiation\n",
      "   3. temperature_2m\n",
      "   4. direct_normal_irradiance\n",
      "   5. diffuse_radiation\n",
      "   6. Flow_NO\n",
      "   7. yearday_cos\n",
      "   8. Flow_GB\n",
      "   9. month\n",
      "   10. is_dst\n",
      "   11. yearday_sin\n",
      "   12. is_non_working_day\n",
      "   13. hour_cos\n",
      "   14. is_weekend\n",
      "   15. cloud_cover\n",
      "   16. weekday_sin\n",
      "   17. hour_sin\n",
      "   18. weekday_cos\n",
      "\n",
      "üîç VALIDATING TRAINING DATA\n",
      "==================================================\n",
      "‚ùå training_data DataFrame not found!\n",
      "Please ensure your training_data DataFrame is loaded before running this cell.\n",
      "\n",
      "üöÄ Ready to run the rolling forecast experiment!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Configuration and Data Preparation\n",
    "\n",
    "# =============================================================================\n",
    "# EXPERIMENT CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Model parameters\n",
    "SARIMA_ORDER = (1, 1, 1)  # (p, d, q) - adjust based on your data characteristics\n",
    "SEASONAL_ORDER = (1, 1, 1, 24)  # (P, D, Q, s) - 24 for hourly seasonality\n",
    "\n",
    "# Experiment parameters\n",
    "EXPERIMENT_START_DATE = \"2024-03-15\"  # Adjust to your preferred start date\n",
    "NUM_FORECAST_DAYS = 30\n",
    "\n",
    "# Exogenous variables (adjust based on your available columns)\n",
    "EXOG_VARIABLES = [\n",
    "'Load', 'shortwave_radiation', 'temperature_2m', 'direct_normal_irradiance', \n",
    "    'diffuse_radiation', 'Flow_NO', 'yearday_cos', 'Flow_GB', 'month', 'is_dst', \n",
    "    'yearday_sin', 'is_non_working_day', 'hour_cos', 'is_weekend', 'cloud_cover', \n",
    "    'weekday_sin', 'hour_sin', 'weekday_cos'\n",
    "]\n",
    "\n",
    "print(\"üîß EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìÖ Start Date: {EXPERIMENT_START_DATE}\")\n",
    "print(f\"‚è∞ Forecast Days: {NUM_FORECAST_DAYS}\")\n",
    "print(f\"üìä SARIMA Order: {SARIMA_ORDER}\")\n",
    "print(f\"üîÑ Seasonal Order: {SEASONAL_ORDER}\")\n",
    "print(f\"üìà Exogenous Variables: {len(EXOG_VARIABLES)}\")\n",
    "print(\"\\nüìã Exogenous Variables List:\")\n",
    "for i, var in enumerate(EXOG_VARIABLES, 1):\n",
    "    print(f\"   {i}. {var}\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATA VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüîç VALIDATING TRAINING DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if training_data exists\n",
    "try:\n",
    "    print(f\"üìä Dataset shape: {training_data.shape}\")\n",
    "    print(f\"üìÖ Date range: {training_data.index.min()} to {training_data.index.max()}\")\n",
    "    print(f\"üí∞ Price column stats:\")\n",
    "    print(f\"   - Mean: {training_data['Price'].mean():.2f}\")\n",
    "    print(f\"   - Std: {training_data['Price'].std():.2f}\")\n",
    "    print(f\"   - Min: {training_data['Price'].min():.2f}\")\n",
    "    print(f\"   - Max: {training_data['Price'].max():.2f}\")\n",
    "    \n",
    "    # Validate data structure\n",
    "    is_valid = validate_training_data(training_data)\n",
    "    \n",
    "    if is_valid:\n",
    "        # Check availability of exogenous variables\n",
    "        available_exog = [var for var in EXOG_VARIABLES if var in training_data.columns]\n",
    "        missing_exog = [var for var in EXOG_VARIABLES if var not in training_data.columns]\n",
    "        \n",
    "        if missing_exog:\n",
    "            print(f\"‚ö†Ô∏è Missing exogenous variables: {missing_exog}\")\n",
    "            print(f\"‚úÖ Available exogenous variables: {available_exog}\")\n",
    "            EXOG_VARIABLES = available_exog  # Update to only use available variables\n",
    "            print(f\"üîÑ Updated exogenous variables list to {len(EXOG_VARIABLES)} variables\")\n",
    "        \n",
    "        # Check data coverage for experiment period\n",
    "        experiment_start = pd.to_datetime(EXPERIMENT_START_DATE)\n",
    "        experiment_end = experiment_start + timedelta(days=NUM_FORECAST_DAYS)\n",
    "        \n",
    "        data_start = training_data.index.min()\n",
    "        data_end = training_data.index.max()\n",
    "        \n",
    "        print(f\"\\nüìÖ Data Coverage Check:\")\n",
    "        print(f\"   - Experiment needs: {experiment_start} to {experiment_end}\")\n",
    "        print(f\"   - Data available: {data_start} to {data_end}\")\n",
    "        \n",
    "        if experiment_start < data_start:\n",
    "            print(\"‚ùå Experiment start date is before available data\")\n",
    "        elif experiment_end > data_end:\n",
    "            print(\"‚ö†Ô∏è Experiment end date extends beyond available data\")\n",
    "            print(\"   This is expected if you have forecasted exogenous variables\")\n",
    "        else:\n",
    "            print(\"‚úÖ Data coverage is sufficient for the experiment\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Data validation completed successfully!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Data validation failed. Please check your training_data DataFrame.\")\n",
    "        \n",
    "except NameError:\n",
    "    print(\"‚ùå training_data DataFrame not found!\")\n",
    "    print(\"Please ensure your training_data DataFrame is loaded before running this cell.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during data validation: {str(e)}\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to run the rolling forecast experiment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING ROLLING FORECAST EXPERIMENT\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create the experiment instance\u001b[39;00m\n\u001b[1;32m     11\u001b[0m experiment \u001b[38;5;241m=\u001b[39m RollingForecastExperiment(\n\u001b[0;32m---> 12\u001b[0m     training_data\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_data\u001b[49m,\n\u001b[1;32m     13\u001b[0m     sarima_order\u001b[38;5;241m=\u001b[39mSARIMA_ORDER,\n\u001b[1;32m     14\u001b[0m     seasonal_order\u001b[38;5;241m=\u001b[39mSEASONAL_ORDER,\n\u001b[1;32m     15\u001b[0m     exog_variables\u001b[38;5;241m=\u001b[39mEXOG_VARIABLES\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚è≥ Running experiment... This may take several minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müí° Tip: Model fitting can be time-consuming, especially for SARIMAX models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 5: Execute Rolling Forecast Experiment\n",
    "\n",
    "# =============================================================================\n",
    "# INITIALIZE AND RUN EXPERIMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üöÄ INITIALIZING ROLLING FORECAST EXPERIMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create the experiment instance\n",
    "experiment = RollingForecastExperiment(\n",
    "    training_data=training_data,\n",
    "    sarima_order=SARIMA_ORDER,\n",
    "    seasonal_order=SEASONAL_ORDER,\n",
    "    exog_variables=EXOG_VARIABLES\n",
    ")\n",
    "\n",
    "print(\"\\n‚è≥ Running experiment... This may take several minutes.\")\n",
    "print(\"üí° Tip: Model fitting can be time-consuming, especially for SARIMAX models\")\n",
    "\n",
    "# Record start time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run the experiment\n",
    "try:\n",
    "    summary_stats = experiment.run_experiment(\n",
    "        start_date=EXPERIMENT_START_DATE,\n",
    "        num_days=NUM_FORECAST_DAYS\n",
    "    )\n",
    "    \n",
    "    # Record end time\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è Experiment completed in {execution_time:.1f} seconds ({execution_time/60:.1f} minutes)\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nüìä EXPERIMENT SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for model_name, stats in summary_stats.items():\n",
    "        print(f\"\\nüîπ {model_name.upper()} MODEL:\")\n",
    "        print(f\"   Mean RMSE: {stats['mean_rmse']:.4f}\")\n",
    "        print(f\"   Std RMSE:  {stats['std_rmse']:.4f}\")\n",
    "        print(f\"   Min RMSE:  {stats['min_rmse']:.4f}\")\n",
    "        print(f\"   Max RMSE:  {stats['max_rmse']:.4f}\")\n",
    "        print(f\"   Success Rate: {stats['successful_forecasts']}/{NUM_FORECAST_DAYS}\")\n",
    "    \n",
    "    # Store results for further analysis\n",
    "    results_df = experiment.get_results_dataframe()\n",
    "    \n",
    "    print(\"\\n‚úÖ Experimental results stored in 'results_df' DataFrame\")\n",
    "    print(\"‚úÖ Summary statistics stored in 'summary_stats' dictionary\")\n",
    "    print(\"‚úÖ Experiment object stored in 'experiment' variable\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Experiment failed with error: {str(e)}\")\n",
    "    print(\"üîß This might be due to:\")\n",
    "    print(\"   - Insufficient historical data\")\n",
    "    print(\"   - Model convergence issues\")\n",
    "    print(\"   - Missing exogenous variables\")\n",
    "    print(\"   - Date range issues\")\n",
    "    \n",
    "    # Still try to get partial results\n",
    "    try:\n",
    "        results_df = experiment.get_results_dataframe()\n",
    "        if len(results_df) > 0:\n",
    "            print(f\"\\nüìä Partial results available: {len(results_df)} forecasts completed\")\n",
    "        else:\n",
    "            print(\"\\nüìä No results available\")\n",
    "    except:\n",
    "        print(\"\\nüìä No results could be retrieved\")\n",
    "\n",
    "print(\"\\nüéØ Ready for results analysis and visualization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Results Analysis and Visualization\n",
    "\n",
    "# =============================================================================\n",
    "# DETAILED RESULTS ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä DETAILED RESULTS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Display results dataframe summary\n",
    "    print(f\"üìã Results DataFrame Shape: {results_df.shape}\")\n",
    "    print(f\"üìÖ Date Range: {results_df['dates'].min()} to {results_df['dates'].max()}\")\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    valid_results = results_df.dropna(subset=['actual_prices'])\n",
    "    \n",
    "    if len(valid_results) > 0:\n",
    "        print(f\"\\n‚úÖ Valid forecasts: {len(valid_results)}/{len(results_df)}\")\n",
    "        \n",
    "        # Price statistics\n",
    "        print(f\"\\nüí∞ ACTUAL PRICE STATISTICS:\")\n",
    "        print(f\"   Mean: {valid_results['actual_prices'].mean():.2f}\")\n",
    "        print(f\"   Std:  {valid_results['actual_prices'].std():.2f}\")\n",
    "        print(f\"   Min:  {valid_results['actual_prices'].min():.2f}\")\n",
    "        print(f\"   Max:  {valid_results['actual_prices'].max():.2f}\")\n",
    "        \n",
    "        # Model comparison table\n",
    "        print(f\"\\nüìä MODEL COMPARISON TABLE:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Model':<12} {'Mean RMSE':<12} {'Std RMSE':<12} {'Min RMSE':<12} {'Max RMSE':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for model in ['naive', 'sarima', 'sarimax']:\n",
    "            if model in summary_stats:\n",
    "                stats = summary_stats[model]\n",
    "                print(f\"{model.capitalize():<12} \"\n",
    "                      f\"{stats['mean_rmse']:<12.4f} \"\n",
    "                      f\"{stats['std_rmse']:<12.4f} \"\n",
    "                      f\"{stats['min_rmse']:<12.4f} \"\n",
    "                      f\"{stats['max_rmse']:<12.4f}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "except NameError:\n",
    "    print(\"‚ùå Results not available. Please run the experiment first (Cell 5).\")\n",
    "    print(\"üîÑ Attempting to create sample visualization with dummy data...\")\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìà CREATING VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Create a comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('30-Day Rolling Forecast Experiment Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. RMSE Evolution Over Time\n",
    "    ax1 = axes[0, 0]\n",
    "    valid_results = results_df.dropna(subset=['dates'])\n",
    "    \n",
    "    if len(valid_results) > 0:\n",
    "        ax1.plot(valid_results['dates'], valid_results['naive_rmse'], \n",
    "                marker='o', label='Naive', linewidth=2, markersize=4)\n",
    "        ax1.plot(valid_results['dates'], valid_results['sarima_rmse'], \n",
    "                marker='s', label='SARIMA', linewidth=2, markersize=4)\n",
    "        ax1.plot(valid_results['dates'], valid_results['sarimax_rmse'], \n",
    "                marker='^', label='SARIMAX', linewidth=2, markersize=4)\n",
    "        \n",
    "        ax1.set_title('RMSE Evolution Over 30 Days')\n",
    "        ax1.set_xlabel('Date')\n",
    "        ax1.set_ylabel('RMSE')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Box Plot of RMSE Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    rmse_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for model in ['naive', 'sarima', 'sarimax']:\n",
    "        rmse_col = f'{model}_rmse'\n",
    "        if rmse_col in results_df.columns:\n",
    "            model_rmse = results_df[rmse_col].dropna()\n",
    "            if len(model_rmse) > 0:\n",
    "                rmse_data.append(model_rmse)\n",
    "                labels.append(model.capitalize())\n",
    "    \n",
    "    if rmse_data:\n",
    "        ax2.boxplot(rmse_data, labels=labels)\n",
    "        ax2.set_title('RMSE Distribution by Model')\n",
    "        ax2.set_ylabel('RMSE')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Actual vs Predicted Scatter Plot\n",
    "    ax3 = axes[1, 0]\n",
    "    if len(valid_results) > 0:\n",
    "        # SARIMAX scatter (best model typically)\n",
    "        valid_pred = valid_results.dropna(subset=['actual_prices', 'sarimax_forecasts'])\n",
    "        if len(valid_pred) > 0:\n",
    "            ax3.scatter(valid_pred['actual_prices'], valid_pred['sarimax_forecasts'], \n",
    "                       alpha=0.6, s=50, label='SARIMAX')\n",
    "            \n",
    "        # Perfect prediction line\n",
    "        if len(valid_results) > 0:\n",
    "            min_price = valid_results['actual_prices'].min()\n",
    "            max_price = valid_results['actual_prices'].max()\n",
    "            ax3.plot([min_price, max_price], [min_price, max_price], \n",
    "                    'r--', alpha=0.8, label='Perfect Prediction')\n",
    "        \n",
    "        ax3.set_title('Actual vs Predicted Prices (SARIMAX)')\n",
    "        ax3.set_xlabel('Actual Price')\n",
    "        ax3.set_ylabel('Predicted Price')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Model Performance Summary Bar Chart\n",
    "    ax4 = axes[1, 1]\n",
    "    models = []\n",
    "    mean_rmses = []\n",
    "    \n",
    "    for model in ['naive', 'sarima', 'sarimax']:\n",
    "        if model in summary_stats and not pd.isna(summary_stats[model]['mean_rmse']):\n",
    "            models.append(model.capitalize())\n",
    "            mean_rmses.append(summary_stats[model]['mean_rmse'])\n",
    "    \n",
    "    if models and mean_rmses:\n",
    "        bars = ax4.bar(models, mean_rmses, \n",
    "                      color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "        ax4.set_title('Mean RMSE by Model')\n",
    "        ax4.set_ylabel('Mean RMSE')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, mean_rmses):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(mean_rmses)*0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualization completed successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Visualization error: {str(e)}\")\n",
    "    print(\"üîß This might be due to insufficient data or missing results\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE ANALYSIS (SARIMAX)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüéØ SARIMAX FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    if hasattr(experiment, 'fitted_models') and experiment.fitted_models['sarimax']:\n",
    "        # Get the last fitted SARIMAX model for analysis\n",
    "        last_sarimax_model = experiment.fitted_models['sarimax'][-1]\n",
    "        \n",
    "        if hasattr(last_sarimax_model, 'params') and len(EXOG_VARIABLES) > 0:\n",
    "            print(\"üìä EXOGENOUS VARIABLE COEFFICIENTS (Last Model):\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Extract coefficients for exogenous variables\n",
    "            params = last_sarimax_model.params\n",
    "            \n",
    "            # The exogenous coefficients typically come after the ARIMA parameters\n",
    "            # This is a simplified approach - you might need to adjust based on your model structure\n",
    "            if len(params) > len(SARIMA_ORDER) + len(SEASONAL_ORDER):\n",
    "                exog_start_idx = len(SARIMA_ORDER) + len(SEASONAL_ORDER) - 2  # Approximate\n",
    "                \n",
    "                for i, var_name in enumerate(EXOG_VARIABLES):\n",
    "                    if exog_start_idx + i < len(params):\n",
    "                        coef_value = params.iloc[exog_start_idx + i]\n",
    "                        print(f\"   {var_name:<20}: {coef_value:>8.4f}\")\n",
    "            \n",
    "            print(\"\\nüí° Note: Coefficient interpretation depends on model specification\")\n",
    "            print(\"   Larger absolute values indicate stronger influence on price forecasts\")\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Feature importance analysis not available\")\n",
    "            print(\"   Model parameters not accessible or no exogenous variables\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No SARIMAX models available for feature importance analysis\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Feature importance analysis failed: {str(e)}\")\n",
    "    print(\"üîß This is normal if SARIMAX models failed to fit\")\n",
    "\n",
    "print(f\"\\nüìã RESULTS SUMMARY SAVED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ All analysis completed!\")\n",
    "print(\"üìä Key variables available for further analysis:\")\n",
    "print(\"   - results_df: Detailed daily results\")\n",
    "print(\"   - summary_stats: Model performance summary\")\n",
    "print(\"   - experiment: Full experiment object with fitted models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Model Recommendation and Insights\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL RECOMMENDATION ENGINE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üéØ MODEL RECOMMENDATION AND INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def get_best_model_recommendation(summary_stats: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Determine the best performing model based on multiple criteria\n",
    "    \"\"\"\n",
    "    recommendation = {\n",
    "        'best_model': None,\n",
    "        'best_rmse': float('inf'),\n",
    "        'criteria': {},\n",
    "        'insights': []\n",
    "    }\n",
    "    \n",
    "    valid_models = {}\n",
    "    \n",
    "    # Filter out models with invalid results\n",
    "    for model_name, stats in summary_stats.items():\n",
    "        if not pd.isna(stats['mean_rmse']) and stats['successful_forecasts'] > 0:\n",
    "            valid_models[model_name] = stats\n",
    "    \n",
    "    if not valid_models:\n",
    "        recommendation['insights'].append(\"‚ùå No valid model results found\")\n",
    "        return recommendation\n",
    "    \n",
    "    # 1. Best Mean RMSE\n",
    "    best_rmse_model = min(valid_models.keys(), \n",
    "                         key=lambda x: valid_models[x]['mean_rmse'])\n",
    "    recommendation['best_model'] = best_rmse_model\n",
    "    recommendation['best_rmse'] = valid_models[best_rmse_model]['mean_rmse']\n",
    "    \n",
    "    # 2. Most Consistent (Lowest Std RMSE)\n",
    "    most_consistent_model = min(valid_models.keys(), \n",
    "                               key=lambda x: valid_models[x]['std_rmse'])\n",
    "    \n",
    "    # 3. Most Reliable (Highest Success Rate)\n",
    "    most_reliable_model = max(valid_models.keys(), \n",
    "                             key=lambda x: valid_models[x]['successful_forecasts'])\n",
    "    \n",
    "    # Store criteria results\n",
    "    recommendation['criteria'] = {\n",
    "        'best_accuracy': best_rmse_model,\n",
    "        'most_consistent': most_consistent_model,\n",
    "        'most_reliable': most_reliable_model\n",
    "    }\n",
    "    \n",
    "    # Generate insights\n",
    "    recommendation['insights'].append(\n",
    "        f\"üèÜ Best Overall Model: {best_rmse_model.upper()} \"\n",
    "        f\"(Mean RMSE: {recommendation['best_rmse']:.4f})\"\n",
    "    )\n",
    "    \n",
    "    if most_consistent_model != best_rmse_model:\n",
    "        recommendation['insights'].append(\n",
    "            f\"üìä Most Consistent: {most_consistent_model.upper()} \"\n",
    "            f\"(Std RMSE: {valid_models[most_consistent_model]['std_rmse']:.4f})\"\n",
    "        )\n",
    "    \n",
    "    if most_reliable_model != best_rmse_model:\n",
    "        recommendation['insights'].append(\n",
    "            f\"üîß Most Reliable: {most_reliable_model.upper()} \"\n",
    "            f\"({valid_models[most_reliable_model]['successful_forecasts']}/{NUM_FORECAST_DAYS} forecasts)\"\n",
    "        )\n",
    "    \n",
    "    # Performance comparison insights\n",
    "    rmse_values = [stats['mean_rmse'] for stats in valid_models.values()]\n",
    "    rmse_improvement = (max(rmse_values) - min(rmse_values)) / max(rmse_values) * 100\n",
    "    \n",
    "    recommendation['insights'].append(\n",
    "        f\"üìà Performance Improvement: {rmse_improvement:.1f}% \"\n",
    "        f\"(Best vs Worst Model)\"\n",
    "    )\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "# =============================================================================\n",
    "# GENERATE RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    # Get model recommendation\n",
    "    recommendation = get_best_model_recommendation(summary_stats)\n",
    "    \n",
    "    print(\"üèÜ MODEL PERFORMANCE RANKING\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Rank models by mean RMSE\n",
    "    valid_models = {name: stats for name, stats in summary_stats.items() \n",
    "                   if not pd.isna(stats['mean_rmse'])}\n",
    "    \n",
    "    if valid_models:\n",
    "        sorted_models = sorted(valid_models.items(), \n",
    "                              key=lambda x: x[1]['mean_rmse'])\n",
    "        \n",
    "        for rank, (model_name, stats) in enumerate(sorted_models, 1):\n",
    "            medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\"\n",
    "            print(f\"{medal} {rank}. {model_name.upper()}\")\n",
    "            print(f\"     Mean RMSE: {stats['mean_rmse']:.4f}\")\n",
    "            print(f\"     Consistency: {stats['std_rmse']:.4f}\")\n",
    "            print(f\"     Success Rate: {stats['successful_forecasts']}/{NUM_FORECAST_DAYS}\")\n",
    "            print()\n",
    "    \n",
    "    print(\"üí° KEY INSIGHTS\")\n",
    "    print(\"-\" * 40)\n",
    "    for insight in recommendation['insights']:\n",
    "        print(f\"   {insight}\")\n",
    "    \n",
    "    print(f\"\\nüéØ FINAL RECOMMENDATION\")\n",
    "    print(\"-\" * 40)\n",
    "    if recommendation['best_model']:\n",
    "        print(f\"‚úÖ Recommended Model: {recommendation['best_model'].upper()}\")\n",
    "        print(f\"üìä Expected RMSE: {recommendation['best_rmse']:.4f}\")\n",
    "        \n",
    "        # Model-specific recommendations\n",
    "        if recommendation['best_model'] == 'naive':\n",
    "            print(f\"\\nüîç NAIVE MODEL INSIGHTS:\")\n",
    "            print(f\"   ‚Ä¢ Simple yesterday=today approach works surprisingly well\")\n",
    "            print(f\"   ‚Ä¢ Consider this as a strong baseline for comparison\")\n",
    "            print(f\"   ‚Ä¢ Low computational cost, high interpretability\")\n",
    "            \n",
    "        elif recommendation['best_model'] == 'sarima':\n",
    "            print(f\"\\nüîç SARIMA MODEL INSIGHTS:\")\n",
    "            print(f\"   ‚Ä¢ Pure time series approach captures patterns effectively\")\n",
    "            print(f\"   ‚Ä¢ Model order: {SARIMA_ORDER} with seasonality {SEASONAL_ORDER}\")\n",
    "            print(f\"   ‚Ä¢ Consider tuning hyperparameters for better performance\")\n",
    "            \n",
    "        elif recommendation['best_model'] == 'sarimax':\n",
    "            print(f\"\\nüîç SARIMAX MODEL INSIGHTS:\")\n",
    "            print(f\"   ‚Ä¢ Exogenous variables provide valuable additional information\")\n",
    "            print(f\"   ‚Ä¢ Using {len(EXOG_VARIABLES)} external features\")\n",
    "            print(f\"   ‚Ä¢ Most complex model - ensure robust exogenous forecasts\")\n",
    "        \n",
    "        print(f\"\\nüìã IMPLEMENTATION CONSIDERATIONS:\")\n",
    "        print(f\"   ‚Ä¢ Computational Cost: {'Low' if recommendation['best_model'] == 'naive' else 'Medium' if recommendation['best_model'] == 'sarima' else 'High'}\")\n",
    "        print(f\"   ‚Ä¢ Data Requirements: {'Minimal' if recommendation['best_model'] == 'naive' else 'Historical Prices' if recommendation['best_model'] == 'sarima' else 'Prices + Exogenous'}\")\n",
    "        print(f\"   ‚Ä¢ Interpretability: {'High' if recommendation['best_model'] == 'naive' else 'Medium'}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No clear recommendation - all models failed\")\n",
    "        print(\"üîß Consider:\")\n",
    "        print(\"   ‚Ä¢ Checking data quality and completeness\")\n",
    "        print(\"   ‚Ä¢ Adjusting model parameters\")\n",
    "        print(\"   ‚Ä¢ Using a longer training period\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Summary statistics not available\")\n",
    "    print(\"üîÑ Please run the experiment first (Cell 5)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Recommendation generation failed: {str(e)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ADDITIONAL INSIGHTS AND NEXT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS AND IMPROVEMENTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üé® Model Enhancement Ideas:\")\n",
    "print(\"   1. Hyperparameter Tuning:\")\n",
    "print(\"      ‚Ä¢ Grid search for optimal SARIMA orders\")\n",
    "print(\"      ‚Ä¢ Cross-validation for model selection\")\n",
    "print(\"   2. Feature Engineering:\")\n",
    "print(\"      ‚Ä¢ Lag features, rolling averages\")\n",
    "print(\"      ‚Ä¢ Calendar effects (holidays, seasons)\")\n",
    "print(\"   3. Advanced Models:\")\n",
    "print(\"      ‚Ä¢ Machine Learning approaches (XGBoost, LSTM)\")\n",
    "print(\"      ‚Ä¢ Ensemble methods combining multiple forecasts\")\n",
    "print(\"   4. Evaluation Improvements:\")\n",
    "print(\"      ‚Ä¢ Multi-step ahead forecasting\")\n",
    "print(\"      ‚Ä¢ Additional metrics (MAE, MAPE)\")\n",
    "print(\"      ‚Ä¢ Directional accuracy assessment\")\n",
    "\n",
    "print(f\"\\nüìä Experiment Variables Available:\")\n",
    "print(\"   ‚Ä¢ results_df: Daily forecast results\")\n",
    "print(\"   ‚Ä¢ summary_stats: Model performance statistics\") \n",
    "print(\"   ‚Ä¢ experiment: Complete experiment object\")\n",
    "print(\"   ‚Ä¢ recommendation: Model recommendation analysis\")\n",
    "\n",
    "print(f\"\\n‚úÖ 30-Day Rolling Forecast Experiment Complete!\")\n",
    "print(\"üéØ Use the insights above to improve your electricity price forecasting system.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
