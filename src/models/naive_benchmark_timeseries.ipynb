{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a1d77c",
   "metadata": {},
   "source": [
    "# Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Plotly setup for notebooks\n",
    "pio.renderers.default = \"notebook\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d66b9b",
   "metadata": {},
   "source": [
    "# Step 2: Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a508e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and preprocess dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "FILE_PATH = \"https://raw.githubusercontent.com/tvgerwe/ENEXIS/refs/heads/main/workspaces/sharell/df_filtered.csv\"\n",
    "print(f\"üìÇ Loading: {FILE_PATH}\")\n",
    "\n",
    "# Load and prepare\n",
    "df = pd.read_csv(FILE_PATH, index_col=0, parse_dates=True)\n",
    "df.index = df.index.tz_localize(None)  # Remove timezone if present\n",
    "df = df.asfreq(\"h\").ffill()\n",
    "\n",
    "# Select only necessary columns\n",
    "required_cols = [\"Price\", \"Load\", \"production_fossilhardcoal\"]\n",
    "missing = [col for col in required_cols if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"‚ùå Missing required columns: {missing}\")\n",
    "\n",
    "df = df[required_cols]\n",
    "df[\"Price\"] = df[\"Price\"] / 1000  # Convert to EUR/kWh\n",
    "\n",
    "# Preview\n",
    "print(f\"‚úÖ Data shape: {df.shape}\")\n",
    "print(f\"üìÖ Date range: {df.index.min()} ‚Üí {df.index.max()}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b167b5",
   "metadata": {},
   "source": [
    "# Step 3: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train-Test Split\n",
    "\n",
    "train_start = \"2025-02-24\"\n",
    "train_end   = \"2025-03-24 00:00:00\"\n",
    "test_start  = \"2025-03-24 00:00:01\"\n",
    "test_end    = \"2025-03-31\"\n",
    "\n",
    "train = df.loc[train_start:train_end]\n",
    "test  = df.loc[test_start:test_end]\n",
    "\n",
    "# Simple leakage check\n",
    "assert train.index.max() < test.index.min(), \"‚ùå Data leakage: train ends after test begins!\"\n",
    "\n",
    "# Overview\n",
    "print(f\"‚úÖ Train: {train.index.min()} ‚Üí {train.index.max()} | {len(train)} records\")\n",
    "print(f\"‚úÖ Test : {test.index.min()} ‚Üí {test.index.max()} | {len(test)} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c8395",
   "metadata": {},
   "source": [
    "# Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Feature Engineering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define target and features\n",
    "target_col = \"Price\"\n",
    "feature_cols = [\"Load\", \"production_fossilhardcoal\"]\n",
    "\n",
    "# Extract features and target\n",
    "X_train, y_train = train[feature_cols], train[target_col]\n",
    "X_test, y_test   = test[feature_cols], test[target_col]\n",
    "\n",
    "# Ensure index alignment\n",
    "X_train = X_train.loc[y_train.index]\n",
    "X_test = X_test.loc[y_test.index]\n",
    "\n",
    "# Scale features (important for SARIMAX stability)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "X_test_scaled  = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "# R-values (pre-scaling, on original features)\n",
    "print(\"üìà R-values (correlation with Price):\")\n",
    "r_values = X_train.corrwith(y_train).sort_values(ascending=False)\n",
    "for feature, r in r_values.items():\n",
    "    print(f\"  {feature:30s} ‚Üí R = {r:.4f}\")\n",
    "\n",
    "# Shape check\n",
    "print(f\"\\n‚úÖ X_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
    "print(f\"‚úÖ X_test : {X_test.shape}  | y_test : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f54f82",
   "metadata": {},
   "source": [
    "# Step 5: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Training (manual vs auto_arima, evaluated on RMSE)\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pmdarima import auto_arima\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Clean output (e.g., force_all_finite warnings)\n",
    "\n",
    "def train_and_forecast(y_train, y_test, order, seasonal_order):\n",
    "    model = SARIMAX(y_train, order=order, seasonal_order=seasonal_order,\n",
    "                    enforce_stationarity=False, enforce_invertibility=False)\n",
    "    result = model.fit(disp=False)\n",
    "    forecast = result.forecast(steps=len(y_test))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, forecast))\n",
    "    return rmse, forecast\n",
    "\n",
    "# Your manual config\n",
    "manual_order = (1, 1, 3)\n",
    "manual_seasonal = (0, 1, 1, 24)\n",
    "\n",
    "print(\"üß™ Testing manual SARIMA config...\")\n",
    "manual_rmse, manual_forecast = train_and_forecast(y_train, y_test, manual_order, manual_seasonal)\n",
    "print(f\"üìâ Manual RMSE: {manual_rmse:.6f} EUR/kWh\")\n",
    "\n",
    "# AutoARIMA with lighter config (reduced search space)\n",
    "print(\"\\n‚öôÔ∏è Running light auto_arima (may take ~1‚Äì2 mins)...\")\n",
    "\n",
    "auto_model = auto_arima(\n",
    "    y_train,\n",
    "    seasonal=True,\n",
    "    m=24,\n",
    "    max_order=10,\n",
    "    max_p=2, max_q=2,\n",
    "    max_P=1, max_Q=1,\n",
    "    max_d=1, max_D=1,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    error_action=\"ignore\",\n",
    "    trace=False\n",
    ")\n",
    "\n",
    "auto_order = auto_model.order\n",
    "auto_seasonal = auto_model.seasonal_order\n",
    "\n",
    "print(f\"‚úÖ auto_arima suggested: Order={auto_order}, Seasonal={auto_seasonal}\")\n",
    "\n",
    "# Forecast and evaluate RMSE\n",
    "print(\"üß™ Testing auto_arima SARIMA config...\")\n",
    "auto_rmse, auto_forecast = train_and_forecast(y_train, y_test, auto_order, auto_seasonal)\n",
    "print(f\"üìâ AutoARIMA RMSE: {auto_rmse:.6f} EUR/kWh\")\n",
    "\n",
    "# Compare and select\n",
    "if auto_rmse < manual_rmse:\n",
    "    print(\"üöÄ Using auto_arima config (lower RMSE).\")\n",
    "    best_order = auto_order\n",
    "    best_seasonal_order = auto_seasonal\n",
    "    final_forecast = auto_forecast\n",
    "    final_rmse = auto_rmse\n",
    "else:\n",
    "    print(\"üîí Using manual config (lower RMSE).\")\n",
    "    best_order = manual_order\n",
    "    best_seasonal_order = manual_seasonal\n",
    "    final_forecast = manual_forecast\n",
    "    final_rmse = manual_rmse\n",
    "\n",
    "print(f\"\\n‚úÖ Final config: Order={best_order}, Seasonal={best_seasonal_order}\")\n",
    "print(f\"üèÅ Final RMSE: {final_rmse:.6f} EUR/kWh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942d516",
   "metadata": {},
   "source": [
    "# Step 6: Forecasting (SARIMA Univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Forecasting (SARIMA Univariate)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Align forecast index with test set\n",
    "forecast_index = y_test.index\n",
    "forecast_series = pd.Series(final_forecast, index=forecast_index)\n",
    "\n",
    "# Plot actual vs forecast\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=forecast_index,\n",
    "    y=y_test,\n",
    "    mode='lines',\n",
    "    name='Actual Price',\n",
    "    line=dict(color='orange')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=forecast_index,\n",
    "    y=forecast_series,\n",
    "    mode='lines',\n",
    "    name='Forecast (SARIMA)',\n",
    "    line=dict(color='blue', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"SARIMA Forecast vs Actual (Univariate)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Price (EUR/kWh)\",\n",
    "    template=\"plotly_white\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e44ae",
   "metadata": {},
   "source": [
    "# Step 6b: Naive Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6b: Naive Forecast\n",
    "\n",
    "# Shift training series by 24 hours to match forecast horizon\n",
    "naive_forecast = y_test.copy()\n",
    "seasonal_period = 24\n",
    "\n",
    "# Create a naive forecast by repeating the last 24h of training\n",
    "repeats = int(np.ceil(len(y_test) / seasonal_period))\n",
    "naive_values = np.tile(y_train[-seasonal_period:].values, repeats)[:len(y_test)]\n",
    "naive_forecast[:] = naive_values\n",
    "\n",
    "# Calculate RMSE\n",
    "naive_rmse = np.sqrt(mean_squared_error(y_test, naive_forecast))\n",
    "print(f\"Naive RMSE: {naive_rmse:.6f} EUR/kWh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e55e6f",
   "metadata": {},
   "source": [
    "# Step 6c: Benchmark Forecast (Oxygent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6c: Benchmark Forecast (Oxygent)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_start = pd.Timestamp(\"2025-03-24 00:00:01\")\n",
    "test_end   = pd.Timestamp(\"2025-03-31 23:00:00\")\n",
    "\n",
    "# Load and process Oxygent benchmark predictions\n",
    "oxygent_path = \"https://raw.githubusercontent.com/tvgerwe/ENEXIS/refs/heads/main/src/data/price_predictions_oxygent/Price_Preds_Processed_20250407.csv\"\n",
    "oxy_df = pd.read_csv(oxygent_path)\n",
    "\n",
    "oxy_df[\"target_hour\"] = pd.to_datetime(oxy_df[\"x\"] * 100000, unit=\"ms\", utc=True).dt.tz_localize(None).dt.floor(\"H\")\n",
    "oxy_df = oxy_df[(oxy_df[\"target_hour\"] >= test_start) & (oxy_df[\"target_hour\"] <= test_end)]\n",
    "\n",
    "# Get actuals from your main df\n",
    "actuals_df = df[[\"Price\"]].copy()\n",
    "actuals_df.index.name = \"target_hour\"\n",
    "actuals_df = actuals_df.reset_index()\n",
    "\n",
    "# Merge\n",
    "merged_oxy = pd.merge(oxy_df, actuals_df, on=\"target_hour\", how=\"inner\")\n",
    "\n",
    "# Rename merged columns for clarity\n",
    "merged_oxy.rename(columns={\"Price_y\": \"Price\"}, inplace=True)\n",
    "\n",
    "# Now drop missing\n",
    "merged_oxy = merged_oxy.dropna(subset=[\"y\", \"Price\"])\n",
    "\n",
    "# Evaluate RMSE\n",
    "oxy_rmse = np.sqrt(mean_squared_error(merged_oxy[\"Price\"], merged_oxy[\"y\"]))\n",
    "print(f\"Oxygent Benchmark RMSE: {oxy_rmse:.6f} EUR/kWh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c355bd",
   "metadata": {},
   "source": [
    "#step 7: Plotting All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21115dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 7: Plotting All Models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import timedelta\n",
    "\n",
    "# === Refit SARIMAX model (if needed) ===\n",
    "sarimax_model = SARIMAX(\n",
    "    y_train,\n",
    "    exog=X_train_scaled,\n",
    "    order=best_order,\n",
    "    seasonal_order=best_seasonal_order,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarimax_result = sarimax_model.fit(disp=False)\n",
    "sarimax_forecast = sarimax_result.forecast(steps=len(y_test), exog=X_test_scaled)\n",
    "sarimax_series = pd.Series(sarimax_forecast, index=y_test.index)\n",
    "\n",
    "# === Prepare Oxygent series ===\n",
    "oxy_latest = merged_oxy.sort_values(\"timestamp\").drop_duplicates(subset=\"target_hour\", keep=\"last\")\n",
    "oxy_latest = oxy_latest.set_index(\"target_hour\").sort_index()\n",
    "oxygent_series = oxy_latest.reindex(y_test.index)[\"y\"]\n",
    "\n",
    "# === Plot all models ===\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_test.index, y=y_test, mode='lines', name='Actual', line=dict(color='black')))\n",
    "fig.add_trace(go.Scatter(x=forecast_series.index, y=forecast_series, mode='lines', name='SARIMA Forecast', line=dict(color='blue', dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=sarimax_series.index, y=sarimax_series, mode='lines', name='SARIMAX Forecast', line=dict(color='green', dash='dash')))\n",
    "fig.add_trace(go.Scatter(x=naive_forecast.index, y=naive_forecast, mode='lines', name='Naive Forecast', line=dict(color='red', dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=oxygent_series.index, y=oxygent_series, mode='lines', name='Oxygent Benchmark', line=dict(color='orange', dash='dash')))\n",
    "\n",
    "# === Vertical gridlines at midnight + date annotations ===\n",
    "daily_lines = y_test.index.normalize().unique()\n",
    "\n",
    "vertical_day_lines = [\n",
    "    dict(\n",
    "        type='line',\n",
    "        x0=day,\n",
    "        x1=day,\n",
    "        y0=0,\n",
    "        y1=1,\n",
    "        xref='x',\n",
    "        yref='paper',\n",
    "        line=dict(color='lightgray', width=1, dash='dot')\n",
    "    )\n",
    "    for day in daily_lines\n",
    "]\n",
    "\n",
    "date_annotations = [\n",
    "    dict(\n",
    "        x=day,\n",
    "        y=1.02,\n",
    "        xref='x',\n",
    "        yref='paper',\n",
    "        text=day.strftime('%d-%b'),\n",
    "        showarrow=False,\n",
    "        font=dict(size=12, color='black'),\n",
    "        align=\"center\"\n",
    "    )\n",
    "    for day in daily_lines\n",
    "]\n",
    "\n",
    "# === Final layout ===\n",
    "fig.update_layout(\n",
    "    title=\"üìä Forecast Comparison: All Models\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Price (EUR/kWh)\",\n",
    "    template=\"plotly_white\",\n",
    "    hovermode=\"x unified\",\n",
    "    width=1500,\n",
    "    height=600,\n",
    "    xaxis=dict(\n",
    "        tickformat=\"%H:%M\",\n",
    "        dtick=7200000  # 2-hour ticks\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    ),\n",
    "    shapes=vertical_day_lines,\n",
    "    annotations=date_annotations\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Daily RMSE Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef391127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Daily RMSE Summary Table\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Combine all forecasts into a single DataFrame\n",
    "rmse_df = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"SARIMA\": forecast_series,\n",
    "    \"SARIMAX\": sarimax_series,\n",
    "    \"Naive\": naive_forecast,\n",
    "    \"Oxygent\": oxygent_series\n",
    "}).dropna()\n",
    "\n",
    "# Add date column for grouping\n",
    "rmse_df[\"date\"] = rmse_df.index.date\n",
    "\n",
    "# Group by date and calculate RMSE per model\n",
    "daily_rmse = rmse_df.groupby(\"date\").apply(\n",
    "    lambda group: pd.Series({\n",
    "        \"SARIMA_RMSE\": np.sqrt(mean_squared_error(group[\"Actual\"], group[\"SARIMA\"])),\n",
    "        \"SARIMAX_RMSE\": np.sqrt(mean_squared_error(group[\"Actual\"], group[\"SARIMAX\"])),\n",
    "        \"Naive_RMSE\": np.sqrt(mean_squared_error(group[\"Actual\"], group[\"Naive\"])),\n",
    "        \"Oxygent_RMSE\": np.sqrt(mean_squared_error(group[\"Actual\"], group[\"Oxygent\"]))\n",
    "    })\n",
    ").reset_index()\n",
    "# Add winner column based on min RMSE\n",
    "rmse_cols = [\"SARIMA_RMSE\", \"SARIMAX_RMSE\", \"Naive_RMSE\", \"Oxygent_RMSE\"]\n",
    "daily_rmse[\"Winner\"] = daily_rmse[rmse_cols].idxmin(axis=1).str.replace(\"_RMSE\", \"\")\n",
    "\n",
    "# Sort and round\n",
    "daily_rmse.sort_values(\"date\", inplace=True)\n",
    "daily_rmse = daily_rmse.round(6)\n",
    "\n",
    "# Show summary table\n",
    "from IPython.display import display\n",
    "display(daily_rmse)\n",
    "\n",
    "# Optional: bar plot\n",
    "fig = px.bar(\n",
    "    daily_rmse.melt(id_vars=[\"date\", \"Winner\"], var_name=\"Model\", value_name=\"RMSE\"),\n",
    "    x=\"date\",\n",
    "    y=\"RMSE\",\n",
    "    color=\"Model\",\n",
    "    barmode=\"group\",\n",
    "    title=\"üìä Daily RMSE Comparison by Model\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8414ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "\n",
    "# === Collect forecast errors by day ahead ===\n",
    "forecast_horizon_errors = {\n",
    "    \"Model\": [],\n",
    "    \"Horizon (days)\": [],\n",
    "    \"RMSE\": []\n",
    "}\n",
    "\n",
    "# Assume predictions are already aligned: y_test, forecast_series, sarimax_series, naive_forecast, oxygent_series\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"SARIMA\": forecast_series,\n",
    "    \"SARIMAX\": sarimax_series,\n",
    "    \"Naive\": naive_forecast,\n",
    "    \"Oxygent\": oxygent_series\n",
    "}).dropna()\n",
    "\n",
    "# Add hour index as time delta from forecast start\n",
    "forecast_df[\"hour\"] = (forecast_df.index - forecast_df.index[0]).total_seconds() / 3600\n",
    "forecast_df[\"day\"] = (forecast_df[\"hour\"] // 24).astype(int) + 1  # Day 1 to 7\n",
    "\n",
    "# === Calculate RMSE per model per forecast day ===\n",
    "for day in range(1, 8):\n",
    "    day_data = forecast_df[forecast_df[\"day\"] == day]\n",
    "    for model in [\"SARIMA\", \"SARIMAX\", \"Naive\", \"Oxygent\"]:\n",
    "        rmse = np.sqrt(mean_squared_error(day_data[\"Actual\"], day_data[model]))\n",
    "        forecast_horizon_errors[\"Model\"].append(model)\n",
    "        forecast_horizon_errors[\"Horizon (days)\"].append(day)\n",
    "        forecast_horizon_errors[\"RMSE\"].append(rmse)\n",
    "\n",
    "rmse_horizon_df = pd.DataFrame(forecast_horizon_errors)\n",
    "\n",
    "# === Overall RMSE per model ===\n",
    "overall_rmse = forecast_df[[\"SARIMA\", \"SARIMAX\", \"Naive\", \"Oxygent\"]].apply(\n",
    "    lambda preds: np.sqrt(mean_squared_error(forecast_df[\"Actual\"], preds))\n",
    ").reset_index()\n",
    "overall_rmse.columns = [\"Model\", \"Overall RMSE (EUR/kWh)\"]\n",
    "\n",
    "# === Best model per forecast day ===\n",
    "pivot = rmse_horizon_df.pivot(index=\"Horizon (days)\", columns=\"Model\", values=\"RMSE\")\n",
    "pivot[\"Best Model\"] = pivot.idxmin(axis=1)\n",
    "\n",
    "# === Print tables ===\n",
    "print(\"üìä Overall RMSE per Model:\")\n",
    "display(overall_rmse.round(6))\n",
    "\n",
    "print(\"\\nüìà RMSE per Forecast Horizon:\")\n",
    "display(rmse_horizon_df.pivot(index=\"Horizon (days)\", columns=\"Model\", values=\"RMSE\").round(6))\n",
    "\n",
    "print(\"\\nüèÜ Best Model per Day Ahead:\")\n",
    "display(pivot[[\"Best Model\"]])\n",
    "\n",
    "# === Plot RMSE per forecast horizon ===\n",
    "fig = px.line(\n",
    "    rmse_horizon_df,\n",
    "    x=\"Horizon (days)\",\n",
    "    y=\"RMSE\",\n",
    "    color=\"Model\",\n",
    "    title=\"üìâ RMSE per Forecast Day Ahead\",\n",
    "    markers=True,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.update_layout(yaxis_title=\"RMSE (EUR/kWh)\", xaxis=dict(dtick=1))\n",
    "fig.show()\n",
    "\n",
    "# === Optional: export to CSV ===\n",
    "# rmse_horizon_df.to_csv(\"forecast_horizon_rmse.csv\", index=False)\n",
    "# overall_rmse.to_csv(\"overall_rmse_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523457fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. RMSE per dag per methode ===\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from IPython.display import display\n",
    "\n",
    "strategies = [\"SARIMAX\", \"Lag_1\", \"Recursive\", \"Combined\"]\n",
    "rmse_results = []\n",
    "\n",
    "# ‚úÖ Dagelijks RMSE per model\n",
    "for day, group in eval_df.groupby(\"date\"):\n",
    "    row = {\"date\": day}\n",
    "    for strategy in strategies:\n",
    "        row[f\"{strategy}_RMSE\"] = np.sqrt(mean_squared_error(group[\"actual\"], group[strategy]))\n",
    "    rmse_results.append(row)\n",
    "\n",
    "# ‚úÖ DataFrame aanmaken\n",
    "rmse_df = pd.DataFrame(rmse_results)\n",
    "rmse_df = rmse_df.round(6).sort_values(\"date\")\n",
    "\n",
    "# ‚úÖ Gemiddelde per modelstrategie\n",
    "mean_row = {col: rmse_df[col].mean() for col in rmse_df.columns if col != \"date\"}\n",
    "mean_row[\"date\"] = \"Gemiddelde\"\n",
    "rmse_df = pd.concat([rmse_df, pd.DataFrame([mean_row])], ignore_index=True)\n",
    "\n",
    "# ‚úÖ Tabel tonen\n",
    "display(rmse_df)\n",
    "\n",
    "# ‚úÖ Visualisatie\n",
    "fig = px.line(\n",
    "    rmse_df.melt(id_vars=[\"date\"], var_name=\"Model\", value_name=\"RMSE\"),\n",
    "    x=\"date\",\n",
    "    y=\"RMSE\",\n",
    "    color=\"Model\",\n",
    "    title=\"üìâ RMSE per Dag per Strategie (inclusief Gemiddelde)\"\n",
    ")\n",
    "fig.update_layout(xaxis=dict(type=\"category\"))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc8702",
   "metadata": {},
   "source": [
    "# attempting over here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92621030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Bepaal best presterend model obv RMSE\n",
    "rmse_by_model = forecast_df[['SARIMA', 'SARIMAX', 'Naive', 'Oxygent']].apply(\n",
    "    lambda col: ((forecast_df['Actual'] - col) ** 2).mean() ** 0.5\n",
    ")\n",
    "best_model = rmse_by_model.idxmin()\n",
    "print(f\"‚úîÔ∏è Using best model based on RMSE: {best_model}\")\n",
    "\n",
    "# 2. Laad device-profielen\n",
    "device_profiles = pd.read_json(\n",
    "    \"https://raw.githubusercontent.com/tvgerwe/ENEXIS/refs/heads/main/src/data/profiles/device_usage_profile\"\n",
    ").to_dict(orient='records')\n",
    "\n",
    "# 3. Bereken optimale verbruiksuren\n",
    "optimal_schedules = []\n",
    "\n",
    "for device in device_profiles:\n",
    "    name = device['Device']\n",
    "    duration = device['Duration_h']\n",
    "    uses = device['Weekly_Uses']\n",
    "    total_hours_needed = duration * uses\n",
    "    allowed_hours = device['Constraints']['Allowed_Hours']\n",
    "    min_block = device['Constraints']['Min_Block_Hours']  # voor later gebruik\n",
    "\n",
    "    # Filter forecast op toegestane uren\n",
    "    valid_hours = forecast_df[forecast_df['hour'].isin(allowed_hours)].copy()\n",
    "\n",
    "    # Sorteer op voorspelde prijs van best presterend model\n",
    "    valid_hours_sorted = valid_hours.sort_values(by=best_model)\n",
    "\n",
    "    selected_hours = []\n",
    "    total_hours_allocated = 0\n",
    "\n",
    "    for _, row in valid_hours_sorted.iterrows():\n",
    "        if total_hours_allocated >= total_hours_needed:\n",
    "            break\n",
    "\n",
    "        selected_hours.append({\n",
    "            \"Device\": name,\n",
    "            \"Day\": row['day'],\n",
    "            \"Hour\": row['hour'],\n",
    "            \"Predicted_Price\": row[best_model]\n",
    "        })\n",
    "        total_hours_allocated += 1\n",
    "\n",
    "    optimal_schedules.extend(selected_hours)\n",
    "\n",
    "# 4. Maak een overzicht van geselecteerde uren\n",
    "df_schedule = pd.DataFrame(optimal_schedules)\n",
    "\n",
    "# 5. Rapport per apparaat\n",
    "df_report = df_schedule.groupby('Device').agg(\n",
    "    Total_Hours=('Hour', 'count'),\n",
    "    Avg_kWh_Price=('Predicted_Price', 'mean'),\n",
    "    Total_kWh_Cost=('Predicted_Price', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# 6. Bekijk resultaten\n",
    "display(df_schedule.head(10))\n",
    "display(df_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
