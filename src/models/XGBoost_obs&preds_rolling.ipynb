{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4101d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:25:37,131 - build_training_set - INFO - üöÄ Start build van trainingset\n",
      "2025-05-26 17:25:37,131 - build_training_set - INFO - üß† Observational data van 2025-01-01 00:00:00+00:00 t/m 2025-03-15 12:00:00+00:00\n",
      "2025-05-26 17:25:37,132 - build_training_set - INFO - üìÖ Forecast van run_date 2025-03-15 12:00:00+00:00, target range: 2025-03-15 12:00:00+00:00 ‚Üí 2025-03-22 23:00:00+00:00\n",
      "2025-05-26 17:25:37,159 - build_training_set - INFO - ‚úÖ Observational data geladen: 1765 rijen\n",
      "2025-05-26 17:25:37,315 - build_training_set - INFO - üßê Forecast rows: (27648, 27)\n",
      "2025-05-26 17:25:37,316 - build_training_set - INFO - üßê target_datetime min: 2025-01-01 00:00:00+00:00 | max: 2025-05-31 23:00:00+00:00\n",
      "2025-05-26 17:25:37,318 - build_training_set - INFO - üéØ Geselecteerde forecast rijen: 0\n",
      "2025-05-26 17:25:37,321 - build_training_set - INFO - ‚úÖ Added actual prices to 180 forecast rows\n",
      "/Users/Twan/Library/Mobile Documents/com~apple~CloudDocs/Data Science/Data Projects EASI/ENEXIS/src/utils/build_training_set.py:105: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_combined = pd.concat([df_actuals, df_preds], ignore_index=True)\n",
      "2025-05-26 17:25:37,330 - build_training_set - INFO - üì¶ Eindtabel bevat: 1765 rijen, 31 kolommen\n",
      "2025-05-26 17:25:37,330 - build_training_set - INFO - üßæ Kolommen: ['Price', 'target_datetime', 'Load', 'shortwave_radiation', 'temperature_2m', 'direct_normal_irradiance', 'diffuse_radiation', 'Flow_NO', 'yearday_cos', 'Flow_GB', 'month', 'is_dst', 'yearday_sin', 'is_non_working_day', 'hour_cos', 'is_weekend', 'cloud_cover', 'weekday_sin', 'hour_sin', 'weekday_cos', 'apparent_temperature', 'day_of_week', 'day_of_year', 'direct_radiation', 'hour', 'is_holiday', 'local_datetime', 'run_date', 'snowfall', 'wind_direction_10m', 'wind_speed_10m']\n",
      "2025-05-26 17:25:37,330 - build_training_set - INFO - ‚ùì Price NaN count: 0/1765 (0.0%)\n",
      "2025-05-26 17:25:37,341 - build_training_set - INFO - ‚úÖ Opgeslagen als training_set in WARP.db\n",
      "2025-05-26 17:25:37,342 - build_training_set - INFO - üîí Verbinding gesloten\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1765, 31)\n",
      "Price nulls: 0/1765\n",
      "Date range: 2025-01-01 00:00:00+00:00 to 2025-03-15 12:00:00+00:00\n",
      "     Price           target_datetime      Load  shortwave_radiation  \\\n",
      "0  0.01362 2025-01-01 00:00:00+00:00  12049.25                  0.0   \n",
      "1  0.00624 2025-01-01 01:00:00+00:00  11957.50                  0.0   \n",
      "2  0.00416 2025-01-01 02:00:00+00:00  11636.25                  0.0   \n",
      "3  0.00328 2025-01-01 03:00:00+00:00  11310.50                  0.0   \n",
      "4  0.00068 2025-01-01 04:00:00+00:00  11135.25                  0.0   \n",
      "5  0.00000 2025-01-01 05:00:00+00:00  11185.75                  0.0   \n",
      "6  0.00076 2025-01-01 06:00:00+00:00  11385.00                  0.0   \n",
      "7  0.00079 2025-01-01 07:00:00+00:00  11695.25                  0.0   \n",
      "8  0.00189 2025-01-01 08:00:00+00:00  12041.50                  0.0   \n",
      "9  0.00750 2025-01-01 09:00:00+00:00  12485.75                  0.0   \n",
      "\n",
      "   temperature_2m  direct_normal_irradiance  diffuse_radiation  Flow_NO  \\\n",
      "0             0.0                       0.0                0.0   -649.0   \n",
      "1             0.0                       0.0                0.0   -649.0   \n",
      "2             0.0                       0.0                0.0   -635.0   \n",
      "3             0.0                       0.0                0.0   -306.0   \n",
      "4             0.0                       0.0                0.0      0.0   \n",
      "5             0.0                       0.0                0.0      0.0   \n",
      "6             0.0                       0.0                0.0   -223.0   \n",
      "7             0.0                       0.0                0.0   -648.0   \n",
      "8             0.0                       0.0                0.0   -629.0   \n",
      "9             0.0                       0.0                0.0   -305.0   \n",
      "\n",
      "   yearday_cos  Flow_GB  ...  day_of_week  day_of_year  direct_radiation  \\\n",
      "0     0.999852     0.00  ...         <NA>         <NA>               NaN   \n",
      "1     0.999852     0.25  ...         <NA>         <NA>               NaN   \n",
      "2     0.999852     0.00  ...         <NA>         <NA>               NaN   \n",
      "3     0.999852     0.25  ...         <NA>         <NA>               NaN   \n",
      "4     0.999852     0.50  ...         <NA>         <NA>               NaN   \n",
      "5     0.999852     0.25  ...         <NA>         <NA>               NaN   \n",
      "6     0.999852     0.00  ...         <NA>         <NA>               NaN   \n",
      "7     0.999852     0.00  ...         <NA>         <NA>               NaN   \n",
      "8     0.999852     0.25  ...         <NA>         <NA>               NaN   \n",
      "9     0.999852     0.00  ...         <NA>         <NA>               NaN   \n",
      "\n",
      "   hour  is_holiday  local_datetime  run_date  snowfall  wind_direction_10m  \\\n",
      "0  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "1  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "2  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "3  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "4  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "5  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "6  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "7  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "8  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "9  <NA>        <NA>             NaN       NaN       NaN                 NaN   \n",
      "\n",
      "   wind_speed_10m  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "5             NaN  \n",
      "6             NaN  \n",
      "7             NaN  \n",
      "8             NaN  \n",
      "9             NaN  \n",
      "\n",
      "[10 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dynamic path setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root dynamically\n",
    "current_dir = Path.cwd()\n",
    "while current_dir.name != \"ENEXIS\" and current_dir.parent != current_dir:\n",
    "    current_dir = current_dir.parent\n",
    "project_root = current_dir\n",
    "\n",
    "# Add utils to path\n",
    "utils_path = project_root / \"src\" / \"utils\"\n",
    "sys.path.append(str(utils_path))\n",
    "\n",
    "# Import the function from the module (make sure the function exists in the file)\n",
    "from build_training_set import build_training_set\n",
    "\n",
    "# Test\n",
    "df = build_training_set(\n",
    "    train_start=\"2025-01-01 00:00:00\",\n",
    "    train_end=\"2025-03-15 11:00:00\",\n",
    "    run_date=\"2025-03-15 12:00:00\"\n",
    ")\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Price nulls: {df['Price'].isnull().sum()}/{len(df)}\")\n",
    "print(f\"Date range: {df['target_datetime'].min()} to {df['target_datetime'].max()}\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "\n",
    "# Test parameters\n",
    "base_start = \"2025-01-01 00:00:00\"\n",
    "base_end = \"2025-03-14 23:00:00\" \n",
    "base_run = \"2025-03-15 00:00:00\"\n",
    "\n",
    "# Forecast config\n",
    "forecast_horizon = 168  # 168 hours = 7 days\n",
    "\n",
    "# Storage for results\n",
    "rmse_results = []\n",
    "\n",
    "print(\"üîç Testing XGBoost - RMSE per forecast day\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in range(30):  # 30 rolling windows\n",
    "    start = pd.Timestamp(base_start) + pd.Timedelta(days=i)\n",
    "    end = pd.Timestamp(base_end) + pd.Timedelta(days=i)\n",
    "    run = pd.Timestamp(base_run) + pd.Timedelta(days=i)\n",
    "\n",
    "    try:\n",
    "        # Get training set\n",
    "        df = build_training_set(\n",
    "            train_start=start.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            train_end=end.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            run_date=run.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        )\n",
    "\n",
    "        if df is not None and len(df) > 0:\n",
    "            # Convert datetime\n",
    "            df['target_datetime'] = pd.to_datetime(df['target_datetime'], utc=True)\n",
    "            df = df.sort_values('target_datetime')\n",
    "            df = df.set_index('target_datetime')\n",
    "\n",
    "            # Define features\n",
    "            all_features = [\n",
    "                 'Load','shortwave_radiation','temperature_2m','direct_normal_irradiance','diffuse_radiation','Flow_NO','yearday_cos','Flow_GB',\n",
    "                 'month','is_dst','yearday_sin','wind_speed_10m','is_non_working_day','hour_cos','is_weekend','cloud_cover','weekday_sin','hour_sin','weekday_cos'\n",
    "            ]\n",
    "            target = 'Price'\n",
    "\n",
    "            train_cutoff = pd.Timestamp(end, tz=\"UTC\")\n",
    "            forecast_data = df[df.index > train_cutoff].copy()\n",
    "            train_data = df[df.index <= train_cutoff].copy()\n",
    "\n",
    "            # Clean forecast set\n",
    "            if len(forecast_data) >= forecast_horizon and forecast_data['Price'].notna().sum() > 0:\n",
    "                forecast_data = forecast_data.iloc[:forecast_horizon]  # Limit to 168h\n",
    "                X_train = train_data[all_features]\n",
    "                y_train = train_data[target]\n",
    "                X_test = forecast_data[all_features].copy()\n",
    "                y_test = forecast_data[target]\n",
    "\n",
    "                # Train model\n",
    "                model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Predict\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                # Evaluate per day\n",
    "                valid_data = forecast_data.copy()\n",
    "                valid_data['y_true'] = y_test\n",
    "                valid_data['y_pred'] = y_pred\n",
    "                valid_data['forecast_hour'] = range(len(valid_data))\n",
    "                valid_data['forecast_day'] = (valid_data['forecast_hour'] // 24) + 1\n",
    "\n",
    "                day_rmses = {}\n",
    "                for day in range(1, 8):\n",
    "                    day_data = valid_data[valid_data['forecast_day'] == day]\n",
    "                    if len(day_data) > 0:\n",
    "                        rmse = np.sqrt(mean_squared_error(day_data['y_true'], day_data['y_pred']))\n",
    "                        day_rmses[f'Day_{day}'] = rmse\n",
    "                    else:\n",
    "                        day_rmses[f'Day_{day}'] = np.nan\n",
    "\n",
    "                result = {\n",
    "                    'iteration': i + 1,\n",
    "                    'run_date': run.strftime('%Y-%m-%d'),\n",
    "                    'valid_predictions': len(valid_data),\n",
    "                    **day_rmses\n",
    "                }\n",
    "                rmse_results.append(result)\n",
    "                print(f\"Day {i+1}: ‚úÖ {len(valid_data)} predictions, Run: {run.strftime('%m-%d')}\")\n",
    "            else:\n",
    "                print(f\"Day {i+1}: ‚ùå No forecast data with actual prices\")\n",
    "        else:\n",
    "            print(f\"Day {i+1}: ‚ùå No training data\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Day {i+1}: ‚ùå Error: {e}\")\n",
    "\n",
    "# Create RMSE matrix\n",
    "if rmse_results:\n",
    "    rmse_df = pd.DataFrame(rmse_results)\n",
    "\n",
    "    print(f\"\\nüìä RMSE MATRIX - XGBoost Model\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Successful runs: {len(rmse_df)}/30\")\n",
    "\n",
    "    day_columns = [f'Day_{i}' for i in range(1, 8)]\n",
    "    available_day_cols = [col for col in day_columns if col in rmse_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "color_pal = sns.color_palette()\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edea3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('../data/WARP.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM training_set\", conn)\n",
    "conn.close()\n",
    "# change datetime to index\n",
    "df.set_index('target_datetime', inplace=True)\n",
    "# convert to datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price'].plot(kind='hist', bins=500)\n",
    "plt.ylim(top=120)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad43210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import timedelta\n",
    "\n",
    "# Feature and target setup\n",
    "features = [\n",
    "    'apparent_temperature',\n",
    "    'temperature_2m',\n",
    "    'direct_normal_irradiance',\n",
    "    'diffuse_radiation',\n",
    "    'yearday_sin',\n",
    "    'Flow_BE',\n",
    "    'hour_sin',\n",
    "    'is_non_working_day',\n",
    "    'is_dst',\n",
    "    'is_weekend',\n",
    "    'is_holiday',\n",
    "    'weekday_cos',\n",
    "    'wind_speed_10m',\n",
    "    'hour_cos',\n",
    "    'weekday_sin',\n",
    "    'cloud_cover',\n",
    "    'Flow_GB',\n",
    "    'yearday_cos',\n",
    "    'Flow_NO',\n",
    "    'Load'\n",
    "]\n",
    "target = 'Price'\n",
    "\n",
    "# Safe datetime handling\n",
    "if 'datetime' in df.columns:\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime')\n",
    "    df = df.set_index('datetime')\n",
    "else:\n",
    "    print(\"'datetime' column not found in columns. Sorting by index instead.\")\n",
    "    df = df.sort_index()\n",
    "\n",
    "# Forecast settings\n",
    "start_date = pd.Timestamp(\"2025-03-13 12:00\", tz='UTC')\n",
    "end_date = pd.Timestamp(\"2025-05-14 12:00\", tz='UTC')\n",
    "lag = timedelta(hours=36)\n",
    "forecast_horizon = timedelta(hours=144)\n",
    "\n",
    "# Store RMSEs\n",
    "rmses = []\n",
    "\n",
    "current_time = start_date\n",
    "while current_time <= end_date:\n",
    "    train_data = df[df.index < current_time]\n",
    "    test_start = current_time + lag # check current time  \n",
    "    test_end = test_start + forecast_horizon\n",
    "    test_data = df[(df.index >= test_start) & (df.index < test_end)]\n",
    "\n",
    "    if test_data.empty:\n",
    "        print(f\"No test data for forecast starting at {current_time}\")\n",
    "        current_time += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[target]\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    # Train and predict\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmses.append(rmse)\n",
    "\n",
    "    print(f\"Forecast origin: {current_time}, Predicting {test_start} to {test_end}, RMSE: {rmse:.3f}\")\n",
    "\n",
    "    current_time += timedelta(days=1)\n",
    "\n",
    "# Summary\n",
    "avg_rmse = np.mean(rmses)\n",
    "print(f\"\\nAverage RMSE over {len(rmses)} runs: {avg_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1843a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "MODEL_CODE = \"XGB_1fold_split\"\n",
    "PARAMETERS_USED = {\n",
    "    \"temp_2m\": True,\n",
    "    \"shortwave_radiation\": True,\n",
    "    \"windspeed_10m\": True\n",
    "}\n",
    "timestamp_predict = pd.to_datetime(\"2025-03-15 00:00:00\", utc=True)\n",
    "TARGET = 'Price'\n",
    "\n",
    "# Define features\n",
    "COMMON_FEATURES = [\n",
    "    'yearday_cos', 'yearday_sin', 'month',\n",
    "    'shortwave_radiation', 'windspeed_10m', 'apparent_temperature', 'temperature_2m',\n",
    "    'direct_normal_irradiance', 'diffuse_radiation',\n",
    "    'cloud_cover', , 'hour_cos', 'hour_sin', 'is_non_working_day',\n",
    "    'weekday_sin', 'weekday_cos', 'is_holiday',\n",
    "]\n",
    "\n",
    "# Add Load only to training features\n",
    "TRAIN_FEATURES = COMMON_FEATURES + ['Load', 'Flow_NO', 'Flow_GB', 'Flow_BE', 'Wind_Vol', 'Solar_Vol']\n",
    "TEST_FEATURES = COMMON_FEATURES\n",
    "\n",
    "# Sort by index\n",
    "df = df.sort_index()\n",
    "\n",
    "# Train-test split based on timestamp_predict\n",
    "train = df[df.index < timestamp_predict]\n",
    "test = df[df.index >= timestamp_predict]\n",
    "\n",
    "X_train = train[TRAIN_FEATURES]\n",
    "y_train = train[TARGET]\n",
    "X_test = test[TEST_FEATURES]\n",
    "y_test = test[TARGET]\n",
    "\n",
    "# Train model\n",
    "reg = xgb.XGBRegressor(\n",
    "    base_score=0.5,\n",
    "    booster='gbtree',\n",
    "    n_estimators=1200,\n",
    "    early_stopping_rounds=50,\n",
    "    objective='reg:squarederror',\n",
    "    max_depth=3,\n",
    "    learning_rate=0.02\n",
    ")\n",
    "\n",
    "reg.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Store predictions\n",
    "y_test.index = pd.to_datetime(y_test.index)\n",
    "pred_df = pd.DataFrame({\n",
    "    'datetime': y_test.index,\n",
    "    'y_true': y_test.values,\n",
    "    'y_pred': y_pred\n",
    "})\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"1-Fold RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for _, row in pred_df.iterrows():\n",
    "    results.append({\n",
    "        'timestamp_predict': timestamp_predict.strftime('%d-%m-%Y %H:%M'),\n",
    "        'datetime': row['datetime'].strftime('%d-%m-%Y %H:%M'),\n",
    "        'model_code': MODEL_CODE,\n",
    "        'price': round(row['y_pred'], 4),\n",
    "        'true_price': round(row['y_true'], 4),\n",
    "        'RSME': round(rmse, 4),\n",
    "        'fold': 1,\n",
    "        'parameters(JSON)': json.dumps(PARAMETERS_USED)\n",
    "    })\n",
    "\n",
    "# Save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model_results_log.csv\", mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import timedelta\n",
    "\n",
    "# Feature and target setup\n",
    "features = ['hour_cos', 'Load', 'hour_sin', 'weekday_sin', 'weekday_cos', 'Solar_Vol', 'Wind_Vol',\n",
    "            'WindOffshore_Vol', 'is_holiday','Total_Flow']\n",
    "\n",
    "target = 'Price'\n",
    "\n",
    "# Safe datetime handling\n",
    "if 'datetime' in df.columns:\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values('datetime')\n",
    "    df = df.set_index('datetime')\n",
    "else:\n",
    "    print(\"'datetime' column not found in columns. Sorting by index instead.\")\n",
    "    df = df.sort_index()\n",
    "\n",
    "# Forecast settings\n",
    "start_date = pd.Timestamp(\"2025-03-13 12:00\", tz='UTC')\n",
    "end_date = pd.Timestamp(\"2025-05-05 12:00\", tz='UTC')\n",
    "lag = timedelta(hours=36)\n",
    "forecast_horizon = timedelta(hours=144)\n",
    "\n",
    "# Store RMSEs\n",
    "rmses = []\n",
    "\n",
    "current_time = start_date\n",
    "while current_time <= end_date:\n",
    "    train_data = df[df.index < current_time]\n",
    "    test_start = current_time + lag\n",
    "    test_end = test_start + forecast_horizon\n",
    "    test_data = df[(df.index >= test_start) & (df.index < test_end)]\n",
    "\n",
    "    if test_data.empty:\n",
    "        print(f\"No test data for forecast starting at {current_time}\")\n",
    "        current_time += timedelta(days=1)\n",
    "        continue\n",
    "\n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[target]\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[target]\n",
    "\n",
    "    # Train and predict\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmses.append(rmse)\n",
    "\n",
    "    print(f\"Forecast origin: {current_time}, Predicting {test_start} to {test_end}, RMSE: {rmse:.3f}\")\n",
    "\n",
    "    current_time += timedelta(days=1)\n",
    "\n",
    "# Summary\n",
    "avg_rmse = np.mean(rmses)\n",
    "print(f\"\\nAverage RMSE over {len(rmses)} runs: {avg_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the forecast origin dates and RMSEs from the previous loop\n",
    "forecast_origins = []\n",
    "rmses_per_run = []\n",
    "\n",
    "start_date = pd.Timestamp(\"2025-03-13 12:00\", tz='UTC')\n",
    "end_date = pd.Timestamp(\"2025-05-05 12:00\", tz='UTC')\n",
    "num_runs = len(rmses)\n",
    "current_time = start_date\n",
    "\n",
    "for i in range(num_runs):\n",
    "    forecast_origins.append(current_time)\n",
    "    current_time += timedelta(days=1)\n",
    "\n",
    "# Plot RMSE vs. forecast origin date\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(forecast_origins, rmses, marker='o', linestyle='-', color=color_pal[0])\n",
    "plt.title('RMSE vs. First Predicted Date (per run)')\n",
    "plt.xlabel('Forecast Origin (First Predicted Date)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate RMSE per day (averaged over all runs where the day is included in the forecast horizon)\n",
    "\n",
    "# Assume forecast_origins and rmses are available from previous cells\n",
    "# Each run predicts 6 days (144 hours), so for each run, map RMSE to each predicted day\n",
    "\n",
    "# Build a DataFrame mapping each forecast run to its predicted days\n",
    "forecast_horizon_days = 6\n",
    "forecast_origin_dates = pd.to_datetime(forecast_origins)\n",
    "rmse_per_day = {}\n",
    "\n",
    "for run_idx, origin in enumerate(forecast_origin_dates):\n",
    "    for day_offset in range(forecast_horizon_days):\n",
    "        day = (origin + pd.Timedelta(hours=36) + pd.Timedelta(days=day_offset)).normalize()\n",
    "        if day not in rmse_per_day:\n",
    "            rmse_per_day[day] = []\n",
    "        rmse_per_day[day].append(rmses[run_idx])\n",
    "\n",
    "# Compute average RMSE per day\n",
    "avg_rmse_per_day = pd.Series({day: np.mean(vals) for day, vals in rmse_per_day.items()})\n",
    "avg_rmse_per_day = avg_rmse_per_day.sort_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(avg_rmse_per_day.index, avg_rmse_per_day.values, marker='o', linestyle='-', color=color_pal[1])\n",
    "plt.title('Average RMSE per Predicted Day (Averaged over all runs)')\n",
    "plt.xlabel('Predicted Day')\n",
    "plt.ylabel('Average RMSE')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1aeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the last trained model\n",
    "importances = model.feature_importances_\n",
    "feature_names = model.feature_names_in_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feat_imp_df)\n",
    "\n",
    "# Optional: Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df, palette='viridis')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
