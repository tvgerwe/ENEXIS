{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle           # Save and load data\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Setting Pandas options.\n",
    "pd.set_option(\"display.max_rows\", 50) # How to display all rows from data frame using pandas. Setting value to None to show all rows.\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_info_columns\", 100)\n",
    "pd.set_option(\"display.max_info_rows\", 1000000)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "#pd.set_option(\"styler.format.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Key and download directory from config file\n",
    "CONFIG_FILE = \"../config/api-call.json\"\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from a JSON file.\"\"\"\n",
    "    with open(config_path, \"r\") as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config parameters for API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "config = load_config(CONFIG_FILE)\n",
    "# print(config)\n",
    "API_ENDPOINT= config[\"ned\"][\"ned_api_endpoint\"]\n",
    "API_KEY = config[\"ned\"][\"demo-ned-api-key\"]\n",
    "DOWNLOAD_DIR = config[\"ned\"][\"ned_download_dir\"]\n",
    "\n",
    "# https://api.ned.nl/v1/utilizations?point=0&type=2&granularity=3&granularitytimezone=1&classification=2&activity=1&validfrom[strictly_before]=2020-11-17&validfrom[after]=2020-11-16\n",
    "\n",
    "\n",
    "# Ensure the download directory exists\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# API details (Replace with actual API endpoint)\n",
    "API_URL = API_ENDPOINT\n",
    "#HEADERS = {\"Authorization\": f\"X-AUTH-TOKEN {API_KEY}\"}\n",
    "\n",
    "# Headers with X-AUTH-TOKEN\n",
    "api_headers = {\n",
    "    \"X-AUTH-TOKEN\": API_KEY,  # Replace with your actual token\n",
    "    \"Content-Type\": \"application/json\"  # Optional, if sending JSON\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make API calls in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response 200  for  2024-12-05\n",
      "response 200  for  2024-12-06\n",
      "response 200  for  2024-12-07\n",
      "response 200  for  2024-12-08\n",
      "response 200  for  2024-12-09\n",
      "response 200  for  2024-12-10\n",
      "response 200  for  2024-12-11\n",
      "response 200  for  2024-12-12\n",
      "response 200  for  2024-12-13\n",
      "response 200  for  2024-12-14\n",
      "response 200  for  2024-12-15\n",
      "response 200  for  2024-12-16\n",
      "response 200  for  2024-12-17\n",
      "response 200  for  2024-12-18\n",
      "response 200  for  2024-12-19\n",
      "response 200  for  2024-12-20\n",
      "response 200  for  2024-12-21\n",
      "response 200  for  2024-12-22\n",
      "response 200  for  2024-12-23\n",
      "response 200  for  2024-12-24\n",
      "response 200  for  2024-12-25\n",
      "response 200  for  2024-12-26\n",
      "response 200  for  2024-12-27\n",
      "response 200  for  2024-12-28\n",
      "response 200  for  2024-12-29\n",
      "response 200  for  2024-12-30\n",
      "File downloaded successfully: ../data/powergen/power-gen-type-0.json with rows : 35040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Type\t    What is the type of energy carrier?\t0 All, 1 Wind, 2 Solar, 3 Biogas, 4 HeatPump, 8 Cofiring, 9 Geothermal, 10 Other, 11 Waste, 12 BioOil, 13 Biomass\n",
    "# 14 Wood, 17 WindOffshore, 18 FossilGasPower, 19 FossilHardCoal, 20 Nuclear, 21 WastePower, 22 WindOffshoreB, 23 NaturalGas, 24 Biomethane, 25 BiomassPower\n",
    "# 26 OtherPower, 27 ElectricityMix, 28 GasMix, 31 GasDistribution, 35 CHP Total, 50 SolarThermal, 51 WindOffshoreC, 53 IndustrialConsumersGasCombination\n",
    "# 54 IndustrialConsumersPowerGasCombination, 55 LocalDistributionCompaniesCombination, 56 AllConsumingGas\n",
    "\n",
    "\n",
    "# Define an array of n values (Custom values instead of a fixed range)\n",
    "# n_values = [0, 1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 35, 50, 51, 53, 54, 55, 56]  # Type values\n",
    "\n",
    "# n_values = [1, 2]  # Type values\n",
    "\n",
    "n_values = [0]  # Type values\n",
    "\n",
    "# Date Range\n",
    "start_date = datetime(2024, 1, 1)\n",
    "next_date = datetime(2024, 1, 2)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "\n",
    "# Initialize list to collect merged 'hydra:member' data\n",
    "merged_data = []\n",
    "\n",
    "# Loop through each date\n",
    "current_date = next_date\n",
    "while current_date <= end_date:\n",
    "    # Format date for API\n",
    "    before_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    after_date = (current_date - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for gen_type in n_values:\n",
    "    #params = {\"n\": n}  # Pass n as a parameter\n",
    "        api_params={\n",
    "            \"point\": \"0\",\n",
    "            \"type\": gen_type,\n",
    "            \"granularity\": \"4\",\n",
    "            \"granularitytimezone\": \"1\",\n",
    "            \"classification\": \"2\",\n",
    "            \"activity\": \"1\",\n",
    "            \"validfrom[strictly_before]\": before_date,\n",
    "            \"validfrom[after]\": after_date\n",
    "        }\n",
    "\n",
    "        \"\"\"Download a data file from an API and save it in the specified directory.\"\"\"\n",
    "        response = requests.get(API_URL, headers=api_headers, params=api_params)\n",
    "\n",
    "        print(\"response\", response.status_code, \" for \", after_date)\n",
    "\n",
    "        # Convert JSON to Pandas DataFrame\n",
    "            \n",
    "        if response.status_code == 200 and response.text.strip():\n",
    "            # JSON in bytes format\n",
    "            json_bytes = response.content\n",
    "\n",
    "            # Convert bytes → string → dictionary\n",
    "            json_dict = json.loads(json_bytes.decode(\"utf-8\"))\n",
    "            # print(json_dict)\n",
    "\n",
    "            # Extract 'hydra:member' and merge it\n",
    "            if \"hydra:member\" in json_dict and isinstance(json_dict[\"hydra:member\"], list):\n",
    "                merged_data.extend(json_dict[\"hydra:member\"])  # Merge lists\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            # df = pd.DataFrame.from_dict(merged_data, orient=\"index\")\n",
    "\n",
    "            # Convert the list of utilizations into a DataFrame\n",
    "            # json_data = pd.DataFrame(merged_data[\"hydra:member\"])\n",
    "\n",
    "            # print(\"no of members are : \", merged_data.shape[0])\n",
    "\n",
    "            # Display the DataFrame as a table\n",
    "            # print(\"\\nConverted JSON Payload to Table Format:\\n\")\n",
    "            # print(json_data.to_string(index=False))\n",
    "        else:\n",
    "            \n",
    "            print(f\"Error for {gen_type} : {response.status_code} - {response.text}\")\n",
    "        #filtered_df = filter_response_data(response_data)\n",
    "        time.sleep(1)  # Optional delay to avoid rate limits   \n",
    "     # Move to next day\n",
    "    start_date = current_date\n",
    "    current_date += timedelta(days=1)         \n",
    "file_path = os.path.join(DOWNLOAD_DIR, f\"power-gen-type-{gen_type}.json\")  # Change extension as needed\n",
    "# Save the merged data to a single JSON file\n",
    "            \n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:  # Ensure text mode & UTF-8 encoding\n",
    "    json.dump(merged_data, f, indent=4, ensure_ascii=False)  # Ensure proper string encoding\n",
    "\n",
    "print(f\"File downloaded successfully: {file_path}\", \"with rows :\", len(merged_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_response_data(json_dict):\n",
    "\n",
    "    # Convert the list of utilizations into a DataFrame\n",
    "    # json_data = pd.DataFrame(json_dict[\"hydra:member\"])\n",
    "    \n",
    "    # f_describe(df, 10)\n",
    "    #df_orig_num    = json_data.select_dtypes(include='number')\n",
    "    #l_df_num_names = df_orig_num.columns.tolist()\n",
    "\n",
    "    # print(l_df_num_names)\n",
    "    # print(f\"\\nNumber of numerical variables: {len(l_df_num_names)}\")\n",
    "\n",
    "    #df_orig_cat    = json_data.select_dtypes(include='object')\n",
    "    #l_df_cat_names = list(df_orig_cat.columns)\n",
    "\n",
    "    # print(f\"\\nNumber of categorical variables: {len(l_df_cat_names)}\")\n",
    "    # print(l_df_cat_names)\n",
    "\n",
    "    # formatted_df = json_to_table(json_data)\n",
    "\n",
    "    # Convert 'capacity' to numeric, handling errors by setting non-numeric values to NaN\n",
    "    # formatted_df['capacity'] = pd.to_numeric(formatted_df['capacity'], errors='coerce')\n",
    "\n",
    "    # Filter, excluding rows where capacity is NaN\n",
    "    # filtered_df = formatted_df[formatted_df['capacity'] > 0].dropna(subset=['capacity'])\n",
    "\n",
    "    # print(filtered_df.shape[0])\n",
    "    # print(filtered_df)\n",
    "\n",
    "    # Create dictionary 'dc_ned_json_data_1' with objects that will be used in the next exercises.\n",
    "    #dc_ned_json_data_1 = {\n",
    "    #    'df_orig': json_data    \n",
    "    #}\n",
    "\n",
    "    # Save dc_exercise_1_2_3 as 'dc_ned_json_data_1.pkl'\n",
    "    #with open('../data/dc-ned-json-data-1.pkl', 'wb') as pickle_file:\n",
    "    #    pickle.dump(dc_ned_json_data_1, pickle_file)\n",
    "\n",
    "    # Display the DataFrame as a table\n",
    "    # print(\"\\nConverted JSON Payload to Table Format:\\n\")\n",
    "    # print(json_data.to_string(index=False))\n",
    "\n",
    "    #if formatted_df is not None:\n",
    "    #    # Print the DataFrame (table format)\n",
    "    #    print(formatted_df.head(3))\n",
    "    # return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionl to make API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def json_to_table(json_data):\n",
    "    #Converts JSON utilization data to a Pandas DataFrame for table display.\n",
    "    # Args: json_data: The JSON data (either a string or a Python dictionary).\n",
    "    # Returns: A Pandas DataFrame or None if there's an error.\n",
    "    \n",
    "    # try:\n",
    "        # If the input is a JSON string, parse it\n",
    "        #if isinstance(json_data, str):\n",
    "        #    data = json.loads(json_data)\n",
    "        #elif isinstance(json_data, dict): # if it is already a dictionary\n",
    "        #    data = json_data\n",
    "        #else:\n",
    "        #    print(\"Invalid input: Please provide a JSON string or dictionary.\")\n",
    "        #    return None\n",
    "\n",
    "        # Extract the 'hydra:member' array which contains the utilization data\n",
    "        #utilization_data = data.get('hydra:member', [])  # Handle missing key\n",
    "\n",
    "        # Create a list of dictionaries, where each dictionary represents a row\n",
    "        #rows = []\n",
    "        #for item in utilization_data:\n",
    "        #    # Select the fields you want to include in the table\n",
    "        #    row = {\n",
    "        #        'id': item.get('id'),\n",
    "        #        'power-gen-type': item.get('type').split(\"/\")[-1],\n",
    "                #'capacity': item.get('capacity'),\n",
    "                #'volume': item.get('volume'),\n",
    "                #'percentage': item.get('percentage'),\n",
    "                # 'emission': item.get('emission'),\n",
    "                #'emissionfactor': item.get('emissionfactor'),\n",
    "                # '@id': item.get('@id'),\n",
    "                # '@type': item.get('@type'),\n",
    "                # 'point': item.get('point'), # Include point for more context\n",
    "                # 'type': item.get('type'), # Include type for more context\n",
    "                #'granularity': item.get('granularity'), # Include granularity for more context\n",
    "                #'granularitytimezone': item.get('granularitytimezone'), # Include granularity for more context\n",
    "                # 'activity': item.get('activity'), # Include granularity for more context\n",
    "                #'classification': item.get('classification'),\n",
    "                # 'validfrom': item.get('validfrom'),\n",
    "        #        'validto': item.get('validto')#,\n",
    "                #'lastupdate': item.get('lastupdate')\n",
    "        #    }\n",
    "        #    rows.append(row)\n",
    "\n",
    "        # Create a Pandas DataFrame from the list of dictionaries\n",
    "        #df = pd.DataFrame(rows)\n",
    "        \n",
    "        #print(\"Number of rows : \", df.shape[0])\n",
    "        #print(df.head(3))\n",
    "\n",
    "        #return df\n",
    "\n",
    "    # except json.JSONDecodeError:\n",
    "        print(\"Error: Invalid JSON format.\")\n",
    "        return None\n",
    "    # except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enexis-data-visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
