{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "164bdd2f",
   "metadata": {},
   "source": [
    "worked after meeting with Maikel to change format to lastupdate, validto, volume_Type1, Volume_type2, etc. \n",
    "using pivot function... issue is that last update values are unique to Type, resulting in many empty cells, typically, for all other Types than the Type that was updated that exact second.... \n",
    "\n",
    "I'll look again when I have time, but if any of you has time to look into this, great! be careful, code to add it to WARP.db is commented out, so review the df direclty instead (data wrangler recommended)\n",
    "Twan, 9 May 22:00 CET\n",
    "\n",
    "Twan 10 May 6:25: allmost have a solution!!! just need to make the current_datetime (time of fetch) less granular... that way to collade. will do so tomorrow!\n",
    "\n",
    " group current_datetime values that are within a 1 minute range, and change all in the group to the most recent current_datetime value in each group, as definition for a new variable 'fetch_moment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5154933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where validfrom is earlier than lastupdate: 8677\n",
      "               type    volume                   validto    current_datetime  \\\n",
      "1463    /v1/types/1   2141122 2025-04-02 09:00:00+00:00 2025-04-02 08:17:40   \n",
      "29823  /v1/types/17   2799828 2025-04-02 09:00:00+00:00 2025-04-02 08:17:41   \n",
      "30373   /v1/types/2  11265053 2025-04-02 09:00:00+00:00 2025-04-02 08:17:41   \n",
      "1997   /v1/types/20    485000 2025-04-02 09:00:00+00:00 2025-04-02 08:17:42   \n",
      "11076  /v1/types/21    365000 2025-04-02 09:00:00+00:00 2025-04-02 08:17:43   \n",
      "36932  /v1/types/26    221000 2025-04-02 09:00:00+00:00 2025-04-02 08:17:43   \n",
      "1464    /v1/types/1   2219175 2025-04-02 10:00:00+00:00 2025-04-02 08:17:40   \n",
      "29824  /v1/types/17   2716766 2025-04-02 10:00:00+00:00 2025-04-02 08:17:41   \n",
      "30374   /v1/types/2  14442681 2025-04-02 10:00:00+00:00 2025-04-02 08:17:41   \n",
      "1998   /v1/types/20    485000 2025-04-02 10:00:00+00:00 2025-04-02 08:17:42   \n",
      "11077  /v1/types/21    365000 2025-04-02 10:00:00+00:00 2025-04-02 08:17:43   \n",
      "36933  /v1/types/26    221000 2025-04-02 10:00:00+00:00 2025-04-02 08:17:43   \n",
      "1465    /v1/types/1   2379837 2025-04-02 11:00:00+00:00 2025-04-02 08:17:40   \n",
      "29825  /v1/types/17   2775487 2025-04-02 11:00:00+00:00 2025-04-02 08:17:41   \n",
      "30375   /v1/types/2  17357228 2025-04-02 11:00:00+00:00 2025-04-02 08:17:41   \n",
      "1999   /v1/types/20    485000 2025-04-02 11:00:00+00:00 2025-04-02 08:17:42   \n",
      "11078  /v1/types/21    365000 2025-04-02 11:00:00+00:00 2025-04-02 08:17:43   \n",
      "36934  /v1/types/26    221000 2025-04-02 11:00:00+00:00 2025-04-02 08:17:43   \n",
      "1466    /v1/types/1   2802929 2025-04-02 12:00:00+00:00 2025-04-02 08:17:40   \n",
      "29826  /v1/types/17   2580169 2025-04-02 12:00:00+00:00 2025-04-02 08:17:41   \n",
      "\n",
      "             fetch_moment  \n",
      "1463  2025-04-02 08:17:43  \n",
      "29823 2025-04-02 08:17:43  \n",
      "30373 2025-04-02 08:17:43  \n",
      "1997  2025-04-02 08:17:43  \n",
      "11076 2025-04-02 08:17:43  \n",
      "36932 2025-04-02 08:17:43  \n",
      "1464  2025-04-02 08:17:43  \n",
      "29824 2025-04-02 08:17:43  \n",
      "30374 2025-04-02 08:17:43  \n",
      "1998  2025-04-02 08:17:43  \n",
      "11077 2025-04-02 08:17:43  \n",
      "36933 2025-04-02 08:17:43  \n",
      "1465  2025-04-02 08:17:43  \n",
      "29825 2025-04-02 08:17:43  \n",
      "30375 2025-04-02 08:17:43  \n",
      "1999  2025-04-02 08:17:43  \n",
      "11078 2025-04-02 08:17:43  \n",
      "36934 2025-04-02 08:17:43  \n",
      "1466  2025-04-02 08:17:43  \n",
      "29826 2025-04-02 08:17:43  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Connect to the SQLite database\n",
    "db_path = '../data/WARP.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Read the raw_NED_preds table into a DataFrame\n",
    "df_NED_preds_processed = pd.read_sql_query(\"SELECT * FROM raw_NED_preds\", conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Zet datumkolommen om naar datetime\n",
    "df_NED_preds_processed['validfrom'] = pd.to_datetime(df_NED_preds_processed['validfrom'])\n",
    "df_NED_preds_processed['validto'] = pd.to_datetime(df_NED_preds_processed['validto'])\n",
    "df_NED_preds_processed['lastupdate'] = pd.to_datetime(df_NED_preds_processed['lastupdate'])\n",
    "df_NED_preds_processed['current_datetime'] = pd.to_datetime(df_NED_preds_processed['current_datetime'])\n",
    "\n",
    "# Zet 'lastupdate' als index en zorg dat deze ook datetime is\n",
    "#df_NED_preds_processed.set_index('lastupdate', inplace=True)\n",
    "#df_NED_preds_processed.index = pd.to_datetime(df_NED_preds_processed.index)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate rows where validfrom is earlier than lastupdate\n",
    "mask = df_NED_preds_processed['validfrom'] >= df_NED_preds_processed['lastupdate']\n",
    "# Keep only rows that match this condition\n",
    "df_NED_preds_processed = df_NED_preds_processed[mask]\n",
    "print(f\"Number of rows where validfrom is earlier than lastupdate: {(~mask).sum()}\")\n",
    "# Sort by current_datetime to ensure correct grouping\n",
    "df_NED_preds_processed = df_NED_preds_processed.sort_values('current_datetime')\n",
    "\n",
    "\n",
    "# dealing with fact that current_datetime is not always the same across Types fetched 'simultaneously':\n",
    "# Group current_datetime values within 1 minute and assign the most recent (max) value in each group as 'fetch_moment'\n",
    "df_NED_preds_processed['fetch_moment'] = (\n",
    "    df_NED_preds_processed['current_datetime']\n",
    "    .diff().gt(pd.Timedelta('1min')).cumsum()\n",
    ")\n",
    "# Map each group to its max current_datetime\n",
    "fetch_moment_map = df_NED_preds_processed.groupby('fetch_moment')['current_datetime'].transform('max')\n",
    "df_NED_preds_processed['fetch_moment'] = fetch_moment_map\n",
    "\n",
    "# Verwijder irrelevante kolommen\n",
    "df_NED_preds_processed = df_NED_preds_processed.drop(columns=[\n",
    "    '@id', '@type', 'id', 'point', 'granularity', 'granularitytimezone', 'activity', 'classification', 'capacity','percentage','emission','emissionfactor','validfrom','lastupdate'])\n",
    "\n",
    "\n",
    "# Verander de naam van de kolom 'type' naar 'PRED_Type'\n",
    "#df_NED_preds_processed['type'] = df_NED_preds_processed['type'].str.replace('/v1/types/', 'PRED_Type_')\n",
    "#print(\"Unique values in 'type':\", df_NED_preds_processed['type'].unique())\n",
    "\n",
    "# Sort the DataFrame by the index,  by 'validto', asnd by 'type'\n",
    "\n",
    "df_NED_preds_processed = df_NED_preds_processed.sort_values(by=['fetch_moment','validto', 'type'])\n",
    "print(df_NED_preds_processed.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbba70e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fetch_moment                   validto  Volume_/v1/types/1  \\\n",
      "0 2025-04-02 08:17:43 2025-04-02 09:00:00+00:00           2141122.0   \n",
      "1 2025-04-02 08:17:43 2025-04-02 10:00:00+00:00           2219175.0   \n",
      "2 2025-04-02 08:17:43 2025-04-02 11:00:00+00:00           2379837.0   \n",
      "3 2025-04-02 08:17:43 2025-04-02 12:00:00+00:00           2802929.0   \n",
      "4 2025-04-02 08:17:43 2025-04-02 13:00:00+00:00           3373530.0   \n",
      "\n",
      "   Volume_/v1/types/17  Volume_/v1/types/2  Volume_/v1/types/20  \\\n",
      "0            2799828.0          11265053.0             485000.0   \n",
      "1            2716766.0          14442681.0             485000.0   \n",
      "2            2775487.0          17357228.0             485000.0   \n",
      "3            2580169.0          18601126.0             485000.0   \n",
      "4            2731686.0          18169871.0             485000.0   \n",
      "\n",
      "   Volume_/v1/types/21  Volume_/v1/types/26  Volume_/v1/types/59  \n",
      "0             365000.0             221000.0                  NaN  \n",
      "1             365000.0             221000.0                  NaN  \n",
      "2             365000.0             221000.0                  NaN  \n",
      "3             365000.0             221000.0                  NaN  \n",
      "4             365000.0             221000.0                  NaN  \n"
     ]
    }
   ],
   "source": [
    "# Pivot the table\n",
    "pivoted = df_NED_preds_processed.pivot_table(\n",
    "    index=['fetch_moment', 'validto'],  # keep these as index\n",
    "    columns='type',                   # columns become unique values from 'type'\n",
    "    values='volume',                  # values to fill in the new columns\n",
    "    aggfunc='first'                   # if duplicates exist, take the first\n",
    ")\n",
    "\n",
    "# Optional: flatten column names and rename to match desired output\n",
    "pivoted.columns = [f'Volume_{col}' for col in pivoted.columns]\n",
    "\n",
    "\n",
    "# To avoid tuple-as-single-column issue:\n",
    "pivoted = pivoted.reset_index()\n",
    "print(pivoted.head())\n",
    "\n",
    "# Save the processed DataFrame to a new SQLite database\n",
    "output_db_path = '../data/WARP.db'\n",
    "conn = sqlite3.connect(output_db_path)\n",
    "pivoted.to_sql('processed_NED_preds', conn, if_exists='replace', index=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2f10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 27 NaN values in volume_pred_type_17_d0\n",
      "Filled 1 NaN values in volume_pred_type_17_d1\n",
      "Filled 1 NaN values in volume_pred_type_17_d2\n",
      "Filled 1 NaN values in volume_pred_type_17_d3\n",
      "Filled 1 NaN values in volume_pred_type_17_d4\n",
      "Filled 1 NaN values in volume_pred_type_17_d5\n",
      "Filled 1 NaN values in volume_pred_type_17_d6\n",
      "Filled 38 NaN values in volume_pred_type_17_d7\n",
      "Filled 27 NaN values in volume_pred_type_1_d0\n",
      "Filled 1 NaN values in volume_pred_type_1_d1\n",
      "Filled 1 NaN values in volume_pred_type_1_d2\n",
      "Filled 1 NaN values in volume_pred_type_1_d3\n",
      "Filled 1 NaN values in volume_pred_type_1_d4\n",
      "Filled 1 NaN values in volume_pred_type_1_d5\n",
      "Filled 1 NaN values in volume_pred_type_1_d6\n",
      "Filled 38 NaN values in volume_pred_type_1_d7\n",
      "Filled 27 NaN values in volume_pred_type_20_d0\n",
      "Filled 1 NaN values in volume_pred_type_20_d1\n",
      "Filled 1 NaN values in volume_pred_type_20_d2\n",
      "Filled 1 NaN values in volume_pred_type_20_d3\n",
      "Filled 1 NaN values in volume_pred_type_20_d4\n",
      "Filled 1 NaN values in volume_pred_type_20_d5\n",
      "Filled 1 NaN values in volume_pred_type_20_d6\n",
      "Filled 38 NaN values in volume_pred_type_20_d7\n",
      "Filled 27 NaN values in volume_pred_type_21_d0\n",
      "Filled 1 NaN values in volume_pred_type_21_d1\n",
      "Filled 1 NaN values in volume_pred_type_21_d2\n",
      "Filled 1 NaN values in volume_pred_type_21_d3\n",
      "Filled 1 NaN values in volume_pred_type_21_d4\n",
      "Filled 1 NaN values in volume_pred_type_21_d5\n",
      "Filled 1 NaN values in volume_pred_type_21_d6\n",
      "Filled 38 NaN values in volume_pred_type_21_d7\n",
      "Filled 27 NaN values in volume_pred_type_26_d0\n",
      "Filled 1 NaN values in volume_pred_type_26_d1\n",
      "Filled 1 NaN values in volume_pred_type_26_d2\n",
      "Filled 1 NaN values in volume_pred_type_26_d3\n",
      "Filled 1 NaN values in volume_pred_type_26_d4\n",
      "Filled 1 NaN values in volume_pred_type_26_d5\n",
      "Filled 1 NaN values in volume_pred_type_26_d6\n",
      "Filled 38 NaN values in volume_pred_type_26_d7\n",
      "Filled 27 NaN values in volume_pred_type_2_d0\n",
      "Filled 1 NaN values in volume_pred_type_2_d1\n",
      "Filled 1 NaN values in volume_pred_type_2_d2\n",
      "Filled 1 NaN values in volume_pred_type_2_d3\n",
      "Filled 1 NaN values in volume_pred_type_2_d4\n",
      "Filled 1 NaN values in volume_pred_type_2_d5\n",
      "Filled 1 NaN values in volume_pred_type_2_d6\n",
      "Filled 38 NaN values in volume_pred_type_2_d7\n",
      "Filled 25 NaN values in volume_pred_type_59_d0\n",
      "Filled 6 NaN values in volume_pred_type_59_d1\n",
      "Filled 6 NaN values in volume_pred_type_59_d2\n",
      "Filled 6 NaN values in volume_pred_type_59_d3\n",
      "Filled 6 NaN values in volume_pred_type_59_d4\n",
      "Filled 6 NaN values in volume_pred_type_59_d5\n",
      "Filled 6 NaN values in volume_pred_type_59_d6\n",
      "Filled 26 NaN values in volume_pred_type_59_d7\n"
     ]
    }
   ],
   "source": [
    "'''# dealing with NaN values, specifically those cells with numberical values in (both) adjacent cells\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# First make a copy to avoid modifying the original dataframe\n",
    "df_filled = df_wide.copy()\n",
    "\n",
    "# Ensure index is datetime for time-based interpolation\n",
    "df_filled.index = pd.to_datetime(df_filled.index)\n",
    "\n",
    "# For each column in the dataframe\n",
    "for column in df_filled.columns:\n",
    "    # Forward and backward fill to get values for interpolation\n",
    "    series = df_filled[column]\n",
    "    \n",
    "    # Get the index as datetime for hourly interpolation\n",
    "    index_as_datetime = pd.to_datetime(series.index)\n",
    "    \n",
    "    # Only interpolate if there's a value both before and after (linear interpolation)\n",
    "    df_filled[column] = series.interpolate(\n",
    "        method='time',\n",
    "        limit=1, # limit=1 ensures we only interpolate for consecutive hours\n",
    "        limit_direction='both' # limit_direction='both' ensures we only interpolate between actual values\n",
    "    )\n",
    "\n",
    "# Print some statistics about the filling\n",
    "for column in df_filled.columns:\n",
    "    filled_count = df_filled[column].count() - df_wide[column].count()\n",
    "    if filled_count > 0:\n",
    "        print(f\"Filled {filled_count} NaN values in {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8492f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_column                volume_pred_type_17_d0  volume_pred_type_17_d1  \\\n",
      "validto                                                                     \n",
      "2025-04-09 02:00:00+00:00               1264364.0               1078600.0   \n",
      "2025-04-09 03:00:00+00:00               1181091.0                953443.0   \n",
      "2025-04-09 04:00:00+00:00                899096.0                844335.0   \n",
      "2025-04-09 05:00:00+00:00               1004562.0                807438.0   \n",
      "2025-04-09 06:00:00+00:00               1551765.0                949137.0   \n",
      "\n",
      "pred_column                volume_pred_type_17_d2  volume_pred_type_17_d3  \\\n",
      "validto                                                                     \n",
      "2025-04-09 02:00:00+00:00               1105664.0                977644.0   \n",
      "2025-04-09 03:00:00+00:00               1024192.0                862923.0   \n",
      "2025-04-09 04:00:00+00:00               1000249.0                825005.0   \n",
      "2025-04-09 05:00:00+00:00               1151357.0                973646.0   \n",
      "2025-04-09 06:00:00+00:00               1372373.0               1199476.0   \n",
      "\n",
      "pred_column                volume_pred_type_17_d4  volume_pred_type_17_d5  \\\n",
      "validto                                                                     \n",
      "2025-04-09 02:00:00+00:00               1294379.0                306605.0   \n",
      "2025-04-09 03:00:00+00:00               1302783.0                270769.0   \n",
      "2025-04-09 04:00:00+00:00               1350416.0                259175.0   \n",
      "2025-04-09 05:00:00+00:00               1535660.0                319728.0   \n",
      "2025-04-09 06:00:00+00:00               1737786.0                413195.0   \n",
      "\n",
      "pred_column                volume_pred_type_17_d6  volume_pred_type_17_d7  \\\n",
      "validto                                                                     \n",
      "2025-04-09 02:00:00+00:00                593064.0                178290.0   \n",
      "2025-04-09 03:00:00+00:00                521834.0                241233.0   \n",
      "2025-04-09 04:00:00+00:00                466625.0                328789.0   \n",
      "2025-04-09 05:00:00+00:00                459359.0                438686.0   \n",
      "2025-04-09 06:00:00+00:00                466290.0                572909.0   \n",
      "\n",
      "pred_column                volume_pred_type_1_d0  volume_pred_type_1_d1  ...  \\\n",
      "validto                                                                  ...   \n",
      "2025-04-09 02:00:00+00:00               229897.0               212431.0  ...   \n",
      "2025-04-09 03:00:00+00:00               251282.0               276552.0  ...   \n",
      "2025-04-09 04:00:00+00:00               281551.0               283434.0  ...   \n",
      "2025-04-09 05:00:00+00:00               298542.0               300764.0  ...   \n",
      "2025-04-09 06:00:00+00:00               338972.0               336384.0  ...   \n",
      "\n",
      "pred_column                volume_pred_type_2_d6  volume_pred_type_2_d7  \\\n",
      "validto                                                                   \n",
      "2025-04-09 02:00:00+00:00                    0.0                    0.0   \n",
      "2025-04-09 03:00:00+00:00                    0.0                    0.0   \n",
      "2025-04-09 04:00:00+00:00                    0.0                    0.0   \n",
      "2025-04-09 05:00:00+00:00                    0.0                    0.0   \n",
      "2025-04-09 06:00:00+00:00               379257.0               368137.0   \n",
      "\n",
      "pred_column                volume_pred_type_59_d0  volume_pred_type_59_d1  \\\n",
      "validto                                                                     \n",
      "2025-04-09 02:00:00+00:00               8678501.0                     NaN   \n",
      "2025-04-09 03:00:00+00:00               8692416.0                     NaN   \n",
      "2025-04-09 04:00:00+00:00               8819530.0                     NaN   \n",
      "2025-04-09 05:00:00+00:00               9574940.0                     NaN   \n",
      "2025-04-09 06:00:00+00:00              10627568.0                     NaN   \n",
      "\n",
      "pred_column                volume_pred_type_59_d2  volume_pred_type_59_d3  \\\n",
      "validto                                                                     \n",
      "2025-04-09 02:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 03:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 04:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 05:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 06:00:00+00:00                     NaN                     NaN   \n",
      "\n",
      "pred_column                volume_pred_type_59_d4  volume_pred_type_59_d5  \\\n",
      "validto                                                                     \n",
      "2025-04-09 02:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 03:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 04:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 05:00:00+00:00                     NaN                     NaN   \n",
      "2025-04-09 06:00:00+00:00                     NaN                     NaN   \n",
      "\n",
      "pred_column                volume_pred_type_59_d6  volume_pred_type_59_d7  \n",
      "validto                                                                    \n",
      "2025-04-09 02:00:00+00:00                     NaN                     NaN  \n",
      "2025-04-09 03:00:00+00:00                     NaN                     NaN  \n",
      "2025-04-09 04:00:00+00:00                     NaN                     NaN  \n",
      "2025-04-09 05:00:00+00:00                     NaN                     NaN  \n",
      "2025-04-09 06:00:00+00:00                     NaN                     NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "'''import sqlite3  \n",
    "\n",
    "# Save the filled DataFrame to a new SQLite database\n",
    "output_db_path = '../data/WARP.db'\n",
    "conn = sqlite3.connect(output_db_path)  \n",
    "df_filled.to_sql('processed_NED_preds', conn, if_exists='replace', index=True)\n",
    "conn.close()\n",
    "# Check the filled DataFrame\n",
    "print(df_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (801, 57)\n",
      "First five rows of the DataFrame:\n",
      "                     validto  volume_pred_type_17_d0  volume_pred_type_17_d1  \\\n",
      "0  2025-04-09 02:00:00+00:00               1264364.0               1078600.0   \n",
      "1  2025-04-09 03:00:00+00:00               1181091.0                953443.0   \n",
      "2  2025-04-09 04:00:00+00:00                899096.0                844335.0   \n",
      "3  2025-04-09 05:00:00+00:00               1004562.0                807438.0   \n",
      "4  2025-04-09 06:00:00+00:00               1551765.0                949137.0   \n",
      "\n",
      "   volume_pred_type_17_d2  volume_pred_type_17_d3  volume_pred_type_17_d4  \\\n",
      "0               1105664.0                977644.0               1294379.0   \n",
      "1               1024192.0                862923.0               1302783.0   \n",
      "2               1000249.0                825005.0               1350416.0   \n",
      "3               1151357.0                973646.0               1535660.0   \n",
      "4               1372373.0               1199476.0               1737786.0   \n",
      "\n",
      "   volume_pred_type_17_d5  volume_pred_type_17_d6  volume_pred_type_17_d7  \\\n",
      "0                306605.0                593064.0                178290.0   \n",
      "1                270769.0                521834.0                241233.0   \n",
      "2                259175.0                466625.0                328789.0   \n",
      "3                319728.0                459359.0                438686.0   \n",
      "4                413195.0                466290.0                572909.0   \n",
      "\n",
      "   volume_pred_type_1_d0  ...  volume_pred_type_2_d6  volume_pred_type_2_d7  \\\n",
      "0               229897.0  ...                    0.0                    0.0   \n",
      "1               251282.0  ...                    0.0                    0.0   \n",
      "2               281551.0  ...                    0.0                    0.0   \n",
      "3               298542.0  ...                    0.0                    0.0   \n",
      "4               338972.0  ...               379257.0               368137.0   \n",
      "\n",
      "   volume_pred_type_59_d0  volume_pred_type_59_d1  volume_pred_type_59_d2  \\\n",
      "0               8678501.0                     NaN                     NaN   \n",
      "1               8692416.0                     NaN                     NaN   \n",
      "2               8819530.0                     NaN                     NaN   \n",
      "3               9574940.0                     NaN                     NaN   \n",
      "4              10627568.0                     NaN                     NaN   \n",
      "\n",
      "   volume_pred_type_59_d3  volume_pred_type_59_d4  volume_pred_type_59_d5  \\\n",
      "0                     NaN                     NaN                     NaN   \n",
      "1                     NaN                     NaN                     NaN   \n",
      "2                     NaN                     NaN                     NaN   \n",
      "3                     NaN                     NaN                     NaN   \n",
      "4                     NaN                     NaN                     NaN   \n",
      "\n",
      "   volume_pred_type_59_d6  volume_pred_type_59_d7  \n",
      "0                     NaN                     NaN  \n",
      "1                     NaN                     NaN  \n",
      "2                     NaN                     NaN  \n",
      "3                     NaN                     NaN  \n",
      "4                     NaN                     NaN  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "'''# Connect to the SQLite database and read the processed_NED_preds table, to verify the data\n",
    "conn = sqlite3.connect('../data/WARP.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM processed_NED_preds\", conn)\n",
    "conn.close()\n",
    "\n",
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"First five rows of the DataFrame:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
