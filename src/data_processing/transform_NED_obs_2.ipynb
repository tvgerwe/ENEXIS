{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59485514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               name\n",
      "0                       raw_ned_obs\n",
      "1                 transform_ned_obs\n",
      "2                 raw_weather_preds\n",
      "3                   raw_weather_obs\n",
      "4             process_weather_preds\n",
      "5               transform_ned_obs_2\n",
      "6                     raw_NED_preds\n",
      "7               processed_NED_preds\n",
      "8                    raw_entsoe_obs\n",
      "9              transform_entsoe_obs\n",
      "10                       raw_ned_df\n",
      "11                     dim_datetime\n",
      "12           raw_meteo_forecast_now\n",
      "13          raw_meteo_preds_history\n",
      "14                    raw_meteo_obs\n",
      "15     transform_meteo_forecast_now\n",
      "16            transform_weather_obs\n",
      "17  transform_weather_preds_history\n",
      "18                      master_warp\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('../Data/WARP.db')\n",
    "# check which tables are in the database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query, conn)\n",
    "print(tables)\n",
    "df = pd.read_sql_query(\"SELECT * FROM raw_NED_obs\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58917a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40807 entries, 0 to 40806\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   @id                  40807 non-null  object\n",
      " 1   @type                40807 non-null  object\n",
      " 2   id                   40807 non-null  object\n",
      " 3   point                40807 non-null  object\n",
      " 4   type                 40807 non-null  object\n",
      " 5   granularity          40807 non-null  object\n",
      " 6   granularitytimezone  40807 non-null  object\n",
      " 7   activity             40807 non-null  object\n",
      " 8   classification       40807 non-null  object\n",
      " 9   capacity             40807 non-null  object\n",
      " 10  volume               40807 non-null  object\n",
      " 11  percentage           40807 non-null  object\n",
      " 12  emission             40807 non-null  object\n",
      " 13  emissionfactor       40807 non-null  object\n",
      " 14  validfrom            40807 non-null  object\n",
      " 15  validto              40807 non-null  object\n",
      " 16  lastupdate           40807 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "                            @id        @type           id         point  \\\n",
      "0  /v1/utilizations/23789747311  Utilization  23789747311  /v1/points/0   \n",
      "1  /v1/utilizations/23792908676  Utilization  23792908676  /v1/points/0   \n",
      "2  /v1/utilizations/23796069299  Utilization  23796069299  /v1/points/0   \n",
      "3  /v1/utilizations/23799229604  Utilization  23799229604  /v1/points/0   \n",
      "4  /v1/utilizations/23802389941  Utilization  23802389941  /v1/points/0   \n",
      "\n",
      "          type          granularity           granularitytimezone  \\\n",
      "0  /v1/types/2  /v1/granularities/5  /v1/granularity_time_zones/0   \n",
      "1  /v1/types/2  /v1/granularities/5  /v1/granularity_time_zones/0   \n",
      "2  /v1/types/2  /v1/granularities/5  /v1/granularity_time_zones/0   \n",
      "3  /v1/types/2  /v1/granularities/5  /v1/granularity_time_zones/0   \n",
      "4  /v1/types/2  /v1/granularities/5  /v1/granularity_time_zones/0   \n",
      "\n",
      "           activity         classification capacity volume percentage  \\\n",
      "0  /v1/activities/1  /v1/classifications/2        0      0        0.0   \n",
      "1  /v1/activities/1  /v1/classifications/2        0      0        0.0   \n",
      "2  /v1/activities/1  /v1/classifications/2        0      0        0.0   \n",
      "3  /v1/activities/1  /v1/classifications/2        0      0        0.0   \n",
      "4  /v1/activities/1  /v1/classifications/2        0      0        0.0   \n",
      "\n",
      "  emission emissionfactor                  validfrom  \\\n",
      "0        0              0  2021-12-31T23:00:00+00:00   \n",
      "1        0              0  2022-01-01T00:00:00+00:00   \n",
      "2        0              0  2022-01-01T01:00:00+00:00   \n",
      "3        0              0  2022-01-01T02:00:00+00:00   \n",
      "4        0              0  2022-01-01T03:00:00+00:00   \n",
      "\n",
      "                     validto                 lastupdate  \n",
      "0  2022-01-01T00:00:00+00:00  2024-04-23T13:28:17+00:00  \n",
      "1  2022-01-01T01:00:00+00:00  2024-04-23T13:28:17+00:00  \n",
      "2  2022-01-01T02:00:00+00:00  2024-04-23T13:28:17+00:00  \n",
      "3  2022-01-01T03:00:00+00:00  2024-04-23T13:28:17+00:00  \n",
      "4  2022-01-01T04:00:00+00:00  2024-04-23T13:28:17+00:00  \n",
      "Unique values in 'type': ['/v1/types/2' '/v1/types/1' '/v1/types/17' '/v1/types/20']\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())\n",
    "print(\"Unique values in 'type':\", df['type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d304c529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "/v1/types/2     31234\n",
      "/v1/types/1      3191\n",
      "/v1/types/17     3191\n",
      "/v1/types/20     3191\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "type_counts = df['type'].value_counts()\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1b5af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           type  total_rows  unique_timestamps  columns_count\n",
      "0   /v1/types/1        3191               3191             17\n",
      "1  /v1/types/17        3191               3191             17\n",
      "2   /v1/types/2       31234              29495             17\n",
      "3  /v1/types/20        3191               3191             17\n",
      "           type              min_validfrom              max_validfrom\n",
      "0   /v1/types/1  2024-12-31T23:00:00+00:00  2025-05-13T21:00:00+00:00\n",
      "1  /v1/types/17  2024-12-31T23:00:00+00:00  2025-05-13T21:00:00+00:00\n",
      "2   /v1/types/2  2021-12-31T23:00:00+00:00  2025-05-13T21:00:00+00:00\n",
      "3  /v1/types/20  2024-12-31T23:00:00+00:00  2025-05-13T21:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data (if not already in a DataFrame)\n",
    "# df = pd.read_csv(\"your_file.csv\")  # or however you're loading it\n",
    "\n",
    "# Grouped summary per type\n",
    "summary = df.groupby('type').agg(\n",
    "    total_rows=('validfrom', 'count'),\n",
    "    unique_timestamps=('validfrom', pd.Series.nunique),\n",
    "    columns_count=('validfrom', lambda x: df[df['@type'] == x.name].shape[1])\n",
    ").reset_index()\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Time range based on validfrom, per 'type'\n",
    "time_ranges = df.groupby('type').agg(\n",
    "    min_validfrom=('validfrom', 'min'),\n",
    "    max_validfrom=('validfrom', 'max')\n",
    ").reset_index()\n",
    "\n",
    "print(time_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4049ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " type       0\n",
      "volume     0\n",
      "validto    0\n",
      "dtype: int64\n",
      "             type   volume                    validto\n",
      "29250  Obs_Type_2  2423299  2025-05-03T18:00:00+00:00\n",
      "29251  Obs_Type_2   973805  2025-05-03T19:00:00+00:00\n",
      "29252  Obs_Type_2    38333  2025-05-03T20:00:00+00:00\n",
      "29253  Obs_Type_2        0  2025-05-03T21:00:00+00:00\n",
      "29254  Obs_Type_2        0  2025-05-03T22:00:00+00:00\n",
      "Unique values in 'type': ['Obs_Type_2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_NED_obs_processed = df.drop(columns=[\n",
    "    '@id', '@type', 'id', 'point', 'granularity', 'lastupdate', 'granularitytimezone', 'activity', 'classification', 'capacity','percentage','emission','emissionfactor','validfrom',])\n",
    "df_NED_obs_processed['type'] = df_NED_obs_processed['type'].str.replace('/v1/types/', 'Obs_Type_')\n",
    "\n",
    "missing_values = df_NED_obs_processed.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "print(df_NED_obs_processed.tail())\n",
    "\n",
    "print(\"Unique values in 'type':\", df_NED_obs_processed['type'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table\n",
    "df_NED_obs_pivoted = df_NED_obs_processed.pivot_table(\n",
    "    index=['validto'],  # keep these as index\n",
    "    columns='type',                   # columns become unique values from 'type'\n",
    "    values='volume',                  # values to fill in the new columns\n",
    "    aggfunc='first'                   # if duplicates exist, take the first\n",
    ")\n",
    "\n",
    "print(\"Pivoted DataFrame:\\n\", df_NED_obs_pivoted.head())\n",
    "# Reset the index to make 'validto' a column again\n",
    "df_NED_obs_pivoted.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed DataFrame to a new table in the database\n",
    "conn = sqlite3.connect('../Data/WARP.db')\n",
    "df_NED_obs_processed.to_sql('transform_ned_obs_2', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecaac3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29255 entries, 0 to 29254\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    29255 non-null  object\n",
      " 1   volume  29255 non-null  object\n",
      " 2   date    29255 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 685.8+ KB\n",
      "None\n",
      "         type volume                       date\n",
      "0  Obs_Type_2      0  2022-01-01T00:00:00+00:00\n",
      "1  Obs_Type_2      0  2022-01-01T01:00:00+00:00\n",
      "2  Obs_Type_2      0  2022-01-01T02:00:00+00:00\n",
      "3  Obs_Type_2      0  2022-01-01T03:00:00+00:00\n",
      "4  Obs_Type_2      0  2022-01-01T04:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Reopen the database and load the new table as a temporary DataFrame\n",
    "conn = sqlite3.connect('../Data/WARP.db')\n",
    "df_temp = pd.read_sql_query(\"SELECT * FROM transform_ned_obs_2\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Print feature overview\n",
    "print(df_temp.info())\n",
    "print(df_temp.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
