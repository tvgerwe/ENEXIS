{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code: merges CSV files, shows which days and hours are in the collective database, creates df, converts x, y, values in to date-time and price including VAT and energy tax 2025 (0.1228). it should prompt for energy tax values, allowing to enter future tax values.\n",
    "\n",
    "it shows the development of price predictions for the period -4 hours till 7 x 24 hours in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 09:50:29,488 - INFO - Successfully read oxygent_data/time_series_data_20250329 00:09 2.csv\n",
      "2025-05-31 09:50:29,489 - INFO - Successfully read oxygent_data/time_series_data_20250330 02:24 2.csv\n",
      "2025-05-31 09:50:29,490 - INFO - Successfully read oxygent_data/time_series_data_20250402 08:22 2.csv\n",
      "2025-05-31 09:50:29,491 - INFO - Successfully read oxygent_data/time_series_data_20250403 02:51 2.csv\n",
      "2025-05-31 09:50:29,492 - INFO - Successfully read oxygent_data/time_series_data_20250404 05:12 2.csv\n",
      "2025-05-31 09:50:29,493 - INFO - Successfully read oxygent_data/time_series_data_20250405 03:19 2.csv\n",
      "2025-05-31 09:50:29,494 - INFO - Successfully read oxygent_data/time_series_data_20250406 03:31 2.csv\n",
      "2025-05-31 09:50:29,495 - INFO - Successfully read oxygent_data/time_series_data_20250407 03:31 2.csv\n",
      "2025-05-31 09:50:29,496 - INFO - Successfully read oxygent_data/time_series_data_20250411 12-00.csv\n",
      "2025-05-31 09:50:29,497 - INFO - Successfully read oxygent_data/time_series_data_20250412 00-00.csv\n",
      "2025-05-31 09:50:29,498 - INFO - Successfully read oxygent_data/time_series_data_20250413 00-00.csv\n",
      "2025-05-31 09:50:29,499 - INFO - Successfully read oxygent_data/time_series_data_20250414 00-00.csv\n",
      "2025-05-31 09:50:29,500 - INFO - Successfully read oxygent_data/time_series_data_20250415 00-00.csv\n",
      "2025-05-31 09:50:29,501 - INFO - Successfully read oxygent_data/time_series_data_20250416 00-00.csv\n",
      "2025-05-31 09:50:29,503 - INFO - Successfully read oxygent_data/time_series_data_20250417 00-00.csv\n",
      "2025-05-31 09:50:29,504 - INFO - Successfully read oxygent_data/time_series_data_20250418 00-00.csv\n",
      "2025-05-31 09:50:29,505 - INFO - Successfully read oxygent_data/time_series_data_20250419 00-00.csv\n",
      "2025-05-31 09:50:29,506 - INFO - Successfully read oxygent_data/time_series_data_20250420 00-00.csv\n",
      "2025-05-31 09:50:29,507 - INFO - Successfully read oxygent_data/time_series_data_20250421 00-00.csv\n",
      "2025-05-31 09:50:29,508 - INFO - Successfully read oxygent_data/time_series_data_20250422 00-00.csv\n",
      "2025-05-31 09:50:29,509 - INFO - Successfully read oxygent_data/time_series_data_20250423 00-00.csv\n",
      "2025-05-31 09:50:29,510 - INFO - Successfully read oxygent_data/time_series_data_20250424 00-00.csv\n",
      "2025-05-31 09:50:29,511 - INFO - Successfully read oxygent_data/time_series_data_20250425 00-00.csv\n",
      "2025-05-31 09:50:29,512 - INFO - Successfully read oxygent_data/time_series_data_20250426 00-00.csv\n",
      "2025-05-31 09:50:29,513 - INFO - Successfully read oxygent_data/time_series_data_20250427 00-00.csv\n",
      "2025-05-31 09:50:29,514 - INFO - Successfully read oxygent_data/time_series_data_20250428 00-00.csv\n",
      "2025-05-31 09:50:29,515 - INFO - Successfully read oxygent_data/time_series_data_20250429 00-00.csv\n",
      "2025-05-31 09:50:29,516 - INFO - Successfully read oxygent_data/time_series_data_20250430 00-00.csv\n",
      "2025-05-31 09:50:29,517 - INFO - Successfully read oxygent_data/time_series_data_20250501 00-00.csv\n",
      "2025-05-31 09:50:29,518 - INFO - Successfully read oxygent_data/time_series_data_20250502 00-00.csv\n",
      "2025-05-31 09:50:29,519 - INFO - Successfully read oxygent_data/time_series_data_20250506 00-00.csv\n",
      "2025-05-31 09:50:29,520 - INFO - Successfully read oxygent_data/time_series_data_20250507 00-00.csv\n",
      "2025-05-31 09:50:29,521 - INFO - Successfully read oxygent_data/time_series_data_20250508 00-00.csv\n",
      "2025-05-31 09:50:29,522 - INFO - Successfully read oxygent_data/time_series_data_20250509 00-00.csv\n",
      "2025-05-31 09:50:29,523 - INFO - Successfully read oxygent_data/time_series_data_20250510 00-00.csv\n",
      "2025-05-31 09:50:29,524 - INFO - Successfully read oxygent_data/time_series_data_20250511 00-00.csv\n",
      "2025-05-31 09:50:29,525 - INFO - Successfully read oxygent_data/time_series_data_20250512 00-00.csv\n",
      "2025-05-31 09:50:29,526 - INFO - Successfully read oxygent_data/time_series_data_20250513 00-00.csv\n",
      "2025-05-31 09:50:29,526 - INFO - Successfully read oxygent_data/time_series_data_20250514 00-00.csv\n",
      "2025-05-31 09:50:29,527 - INFO - Successfully read oxygent_data/time_series_data_20250515 00-00.csv\n",
      "2025-05-31 09:50:29,528 - INFO - Successfully read oxygent_data/time_series_data_20250519 00-00.csv\n",
      "2025-05-31 09:50:29,529 - INFO - Successfully read oxygent_data/time_series_data_20250519 12-37.csv\n",
      "2025-05-31 09:50:29,530 - INFO - Successfully read oxygent_data/time_series_data_20250520 00-00.csv\n",
      "2025-05-31 09:50:29,531 - INFO - Successfully read oxygent_data/time_series_data_20250520 12-37.csv\n",
      "2025-05-31 09:50:29,532 - INFO - Successfully read oxygent_data/time_series_data_20250521 00-00.csv\n",
      "2025-05-31 09:50:29,533 - INFO - Successfully read oxygent_data/time_series_data_20250528 00-00.csv\n",
      "2025-05-31 09:50:29,539 - INFO - Successfully read oxygent_data/append_prices_preds_from26March 2.CSV\n",
      "2025-05-31 09:50:29,692 - INFO - Successfully read oxygent_data/merged_data_price_preds_upto25Mar 2.csv\n",
      "2025-05-31 09:50:30,581 - INFO - Merged 48 files into 'merged_data_price_preds.csv'\n"
     ]
    }
   ],
   "source": [
    "# combine all price prediction files into a single database merged_df, which is also saved as CSV file \"merged_data_price_preds.csv\", located in same folder as this notebook\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the folder containing the CSV files\n",
    "folder_path = Path(\"oxygent_data\")\n",
    "\n",
    "# Get all CSV files in the folder\n",
    "csv_files = list(folder_path.glob(\"*.csv\")) + list(folder_path.glob(\"*.CSV\"))\n",
    "\n",
    "# Sort files based on timestamp in filename\n",
    "csv_files.sort(key=lambda x: x.stem.split(\"_\")[-1].replace(\":\", \"\"))\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "        logging.info(f\"Successfully read {file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading {file}: {e}\")\n",
    "\n",
    "if df_list:\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save the merged data\n",
    "    output_file = \"merged_data_price_preds.csv\"\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    logging.info(f\"Merged {len(csv_files)} files into '{output_file}'\")\n",
    "else:\n",
    "    logging.warning(\"No files were read successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 x        y                         timestamp  subarray  \\\n",
      "0       17431164.0  0.08521  2025-03-29T00:09:51.091516+00:00         0   \n",
      "1       17431200.0  0.07905  2025-03-29T00:09:51.091516+00:00         0   \n",
      "2       17431236.0  0.07899  2025-03-29T00:09:51.091516+00:00         0   \n",
      "3       17431272.0  0.07789  2025-03-29T00:09:51.091516+00:00         0   \n",
      "4       17431308.0  0.07847  2025-03-29T00:09:51.091516+00:00         0   \n",
      "...            ...      ...                               ...       ...   \n",
      "745203  17435196.0  0.10000  2025-03-25T19:00:04.963399+00:00         5   \n",
      "745204  17435232.0  0.11000  2025-03-25T19:00:04.963399+00:00         5   \n",
      "745205  17435268.0  0.11700  2025-03-25T19:00:04.963399+00:00         5   \n",
      "745206  17435304.0  0.10400  2025-03-25T19:00:04.963399+00:00         5   \n",
      "745207  17435340.0  0.09000  2025-03-25T19:00:04.963399+00:00         5   \n",
      "\n",
      "       date_timestamp  hour_timestamp  \n",
      "0          2025-03-29               0  \n",
      "1          2025-03-29               0  \n",
      "2          2025-03-29               0  \n",
      "3          2025-03-29               0  \n",
      "4          2025-03-29               0  \n",
      "...               ...             ...  \n",
      "745203     2025-03-25              19  \n",
      "745204     2025-03-25              19  \n",
      "745205     2025-03-25              19  \n",
      "745206     2025-03-25              19  \n",
      "745207     2025-03-25              19  \n",
      "\n",
      "[745208 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract dates from the 'timestamp' column\n",
    "merged_df['date_timestamp'] = pd.to_datetime(merged_df['timestamp']).dt.date\n",
    "# Extract hour from the 'timestamp' column\n",
    "merged_df['hour_timestamp'] = pd.to_datetime(merged_df['timestamp']).dt.hour\n",
    "\n",
    "\n",
    "# Print df headers\n",
    "print(merged_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Range Summary:\n",
      "First date: 2025-02-24\n",
      "Last date: 2025-05-28\n",
      "Total days in range: 94\n",
      "Days with data: 78\n",
      "Coverage: 83.0%\n",
      "\n",
      "Missing dates:\n",
      "2025-03-27\n",
      "2025-04-08\n",
      "2025-04-09\n",
      "2025-04-10\n",
      "2025-05-03\n",
      "2025-05-04\n",
      "2025-05-05\n",
      "2025-05-16\n",
      "2025-05-17\n",
      "2025-05-18\n",
      "2025-05-22\n",
      "2025-05-23\n",
      "2025-05-24\n",
      "2025-05-25\n",
      "2025-05-26\n",
      "2025-05-27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Convert date_timestamp to datetime format\n",
    "merged_df['date_timestamp'] = pd.to_datetime(merged_df['date_timestamp'])\n",
    "\n",
    "# Get unique dates\n",
    "unique_dates = merged_df['date_timestamp'].dt.date.unique()\n",
    "unique_dates.sort()\n",
    "\n",
    "# Calculate date range statistics\n",
    "first_date = min(unique_dates)\n",
    "last_date = max(unique_dates)\n",
    "total_days = (last_date - first_date).days + 1\n",
    "available_days = len(unique_dates)\n",
    "\n",
    "print(f\"Data Range Summary:\")\n",
    "print(f\"First date: {first_date}\")\n",
    "print(f\"Last date: {last_date}\")\n",
    "print(f\"Total days in range: {total_days}\")\n",
    "print(f\"Days with data: {available_days}\")\n",
    "print(f\"Coverage: {(available_days/total_days)*100:.1f}%\")\n",
    "\n",
    "# Check for missing dates\n",
    "date_range = pd.date_range(start=first_date, end=last_date, freq='D')\n",
    "missing_dates = set(date_range.date) - set(unique_dates)\n",
    "\n",
    "if missing_dates:\n",
    "    print(\"\\nMissing dates:\")\n",
    "    for date in sorted(missing_dates):\n",
    "        print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range in filtered data:\n",
      "Start date: 2025-04-12\n",
      "End date: 2025-05-02\n",
      "\n",
      "Number of rows in filtered data: 21354\n"
     ]
    }
   ],
   "source": [
    "# Filter merged_df for dates between April 12, 2025 and May 2, 2025\n",
    "merged_df = merged_df[\n",
    "    (merged_df['date_timestamp'] > '2025-04-11') & \n",
    "    (merged_df['date_timestamp'] < '2025-05-03')\n",
    "]\n",
    "\n",
    "\n",
    "# Get the date range\n",
    "date_range = pd.to_datetime(merged_df['date_timestamp']).dt.date.unique()\n",
    "print(\"Date range in filtered data:\")\n",
    "print(f\"Start date: {min(date_range)}\")\n",
    "print(f\"End date: {max(date_range)}\")\n",
    "print(f\"\\nNumber of rows in filtered data: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                x       y                         timestamp  subarray  \\\n",
      "9209   17443260.0  0.0851  2025-04-12T00:00:05.000491+00:00         0   \n",
      "9210   17443296.0  0.0890  2025-04-12T00:00:05.000491+00:00         0   \n",
      "9211   17443332.0  0.0753  2025-04-12T00:00:05.000491+00:00         0   \n",
      "9212   17443368.0  0.0750  2025-04-12T00:00:05.000491+00:00         0   \n",
      "9213   17443404.0  0.0851  2025-04-12T00:00:05.000491+00:00         0   \n",
      "...           ...     ...                               ...       ...   \n",
      "30558  17467344.0  0.0610  2025-05-02T00:00:05.000644+00:00         5   \n",
      "30559  17467380.0  0.0290  2025-05-02T00:00:05.000644+00:00         5   \n",
      "30560  17467416.0  0.0140  2025-05-02T00:00:05.000644+00:00         5   \n",
      "30561  17467452.0  0.0010  2025-05-02T00:00:05.000644+00:00         5   \n",
      "30562  17467488.0  0.0030  2025-05-02T00:00:05.000644+00:00         5   \n",
      "\n",
      "      date_timestamp  hour_timestamp           date_time  \n",
      "9209      2025-04-12               0 2025-04-11 01:00:00  \n",
      "9210      2025-04-12               0 2025-04-11 02:00:00  \n",
      "9211      2025-04-12               0 2025-04-11 03:00:00  \n",
      "9212      2025-04-12               0 2025-04-11 04:00:00  \n",
      "9213      2025-04-12               0 2025-04-11 05:00:00  \n",
      "...              ...             ...                 ...  \n",
      "30558     2025-05-02               0 2025-05-08 22:00:00  \n",
      "30559     2025-05-02               0 2025-05-08 23:00:00  \n",
      "30560     2025-05-02               0 2025-05-09 00:00:00  \n",
      "30561     2025-05-02               0 2025-05-09 01:00:00  \n",
      "30562     2025-05-02               0 2025-05-09 02:00:00  \n",
      "\n",
      "[21354 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# sort df by timestamp, secondly by subarray, thirdly by 'x', to easy interpretation of transformation of x to proper datetime format\n",
    "merged_df = merged_df.sort_values(by=['timestamp', 'subarray', 'x'])\n",
    "\n",
    "# ensure conversion from net price to price including taxes..\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure 'x' column is numeric\n",
    "merged_df['x'] = pd.to_numeric(merged_df['x'], errors='coerce')\n",
    "\n",
    "\n",
    "# Convert 'x' to a datetime column\n",
    "merged_df['date_time'] = merged_df['x'].apply(lambda x: datetime.fromtimestamp(x * 100000 / 1000))\n",
    "\n",
    "# Reorder columns\n",
    "merged_df = merged_df[['x', 'y', 'timestamp', 'subarray', 'date_timestamp', 'hour_timestamp', 'date_time']]\n",
    "\n",
    "print(merged_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Build a mapping of year to energy tax rate\n",
    "years = merged_df['date_time'].dt.year.unique()\n",
    "energy_tax_rates = {}\n",
    "for year in sorted(years):\n",
    "    if year == 2025:\n",
    "        energy_tax_rates[year] = 0.1228\n",
    "    else:\n",
    "        rate_input = input(f\"Enter energy tax rate for year {year}: \")\n",
    "        try:\n",
    "            energy_tax_rates[year] = float(rate_input)\n",
    "        except Exception as e:\n",
    "            print(f\"Invalid input, defaulting energy tax rate for {year} to 0.0\")\n",
    "            energy_tax_rates[year] = 0.0\n",
    "\n",
    "print(\"Energy tax rates by year:\", energy_tax_rates)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''# applying 2025 tax rate and VAT to calcuate electricity price including taxes\n",
    "# Ensure 'y' column is numeric\n",
    "merged_df['y'] = pd.to_numeric(merged_df['y'], errors='coerce')\n",
    "\n",
    "merged_df['Price'] = merged_df['y'] * 1.21 + energy_tax_rates[2025]\n",
    "print(merged_df)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted head values:\n",
      "               x       y                         timestamp  subarray  \\\n",
      "9209  17443260.0  0.0851  2025-04-12T00:00:05.000491+00:00         0   \n",
      "9233  17443260.0  0.0170  2025-04-12T00:00:05.000491+00:00         1   \n",
      "\n",
      "     date_timestamp  hour_timestamp           date_time  \n",
      "9209     2025-04-12               0 2025-04-11 01:00:00  \n",
      "9233     2025-04-12               0 2025-04-11 01:00:00  \n",
      "\n",
      "Sorted tail values:\n",
      "DataFrame saved as '../../src/data/price_predictions_oxygent/Price_Preds_Processed_20250531.csv'\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# re-Sort merged_df based on the proper datetime column to avoid plotting errors !!\n",
    "merged_df = merged_df.sort_values(by=['date_timestamp', 'hour_timestamp', 'date_time'])\n",
    "\n",
    "print(\"Sorted head values:\")\n",
    "print(merged_df.head(2))\n",
    "print()\n",
    "print(\"Sorted tail values:\")\n",
    "\n",
    "# Save the DataFrame as a CSV file with the current date in the filename\n",
    "# Define the path to save the CSV file\n",
    "output_path = Path(\"../../src/data/price_predictions_oxygent\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "output_filename = output_path / f\"Price_Preds_Processed_{current_date}.csv\"\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"DataFrame saved as '{output_filename}'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
