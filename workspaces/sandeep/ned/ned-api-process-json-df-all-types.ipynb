{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle           # Save and load data\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Setting Pandas options.\n",
    "pd.set_option(\"display.max_rows\", 50) # How to display all rows from data frame using pandas. Setting value to None to show all rows.\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_info_columns\", 100)\n",
    "pd.set_option(\"display.max_info_rows\", 1000000)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "#pd.set_option(\"styler.format.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Key and download directory from config file\n",
    "CONFIG_FILE = \"../config/api-call.json\"\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from a JSON file.\"\"\"\n",
    "    with open(config_path, \"r\") as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config parameters for loading JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "config = load_config(CONFIG_FILE)\n",
    "# print(config)\n",
    "DOWNLOAD_DIR = config[\"ned\"][\"ned_download_dir\"]\n",
    "# Folder path containing files\n",
    "folder_path = config[\"ned\"][\"ned_download_dir\"]\n",
    "# File pattern to match (e.g., all CSV files that start with \"data_\")\n",
    "file_pattern = \"power-gen-type-0\"  # Change this based on your naming convention\n",
    "file = \"power-gen-type-2022-2024-0.json\"\n",
    "# Ensure the download directory exists\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch JSON files in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the processing\n",
      "File name is : <_io.TextIOWrapper name='../data/powergen/power-gen-type-2022-2024-0.json' mode='r' encoding='utf-8'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mixing dicts with non-Series may lead to ambiguous ordering.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m     exit()\n\u001b[0;32m---> 26\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows in df are : \u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m DataFrame created successfully!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/enexis-data-visualization/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/miniconda3/envs/enexis-data-visualization/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/enexis-data-visualization/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/enexis-data-visualization/lib/python3.12/site-packages/pandas/core/internals/construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n",
      "\u001b[0;31mValueError\u001b[0m: Mixing dicts with non-Series may lead to ambiguous ordering."
     ]
    }
   ],
   "source": [
    "\n",
    "# Type\t    What is the type of energy carrier?\t0 All, 1 Wind, 2 Solar, 3 Biogas, 4 HeatPump, 8 Cofiring, 9 Geothermal, 10 Other, 11 Waste, 12 BioOil, 13 Biomass\n",
    "# 14 Wood, 17 WindOffshore, 18 FossilGasPower, 19 FossilHardCoal, 20 Nuclear, 21 WastePower, 22 WindOffshoreB, 23 NaturalGas, 24 Biomethane, 25 BiomassPower\n",
    "# 26 OtherPower, 27 ElectricityMix, 28 GasMix, 31 GasDistribution, 35 CHP Total, 50 SolarThermal, 51 WindOffshoreC, 53 IndustrialConsumersGasCombination\n",
    "# 54 IndustrialConsumersPowerGasCombination, 55 LocalDistributionCompaniesCombination, 56 AllConsumingGas\n",
    "\n",
    "\n",
    "# Define an array of n values (Custom values instead of a fixed range)\n",
    "# n_values = [0, 1, 2, 4, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 35, 50, 51, 53, 54, 55, 56]  # Type values\n",
    "\n",
    "\n",
    "print(\"starting the processing\")\n",
    "\n",
    "# file_path = os.path.join(folder_path, file)\n",
    "file_path = \"../data/powergen/power-gen-type-2022-2024-0.json\"\n",
    "# df_name = os.path.splitext(file)[0]  # Removes .json extension\n",
    "df_name = \"power-gen-type-2022-2024-0\"\n",
    "        \n",
    "try:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f\"File name is : {f}\")\n",
    "        data = json.load(f)  # Load JSON data\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n",
    "    exit()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"rows in df are : \", df.shape[0])\n",
    "print(\"\\n DataFrame created successfully!\\n\")\n",
    "# print(df.head())  # Display first few rows\n",
    "\n",
    "df_orig_num    = df.select_dtypes(include='number')\n",
    "l_df_num_names = df_orig_num.columns.tolist()\n",
    "print(l_df_num_names)\n",
    "print(f\"\\nNumber of numerical variables: {len(l_df_num_names)}\")\n",
    "\n",
    "df_orig_cat    = df.select_dtypes(include='object')\n",
    "l_df_cat_names = list(df_orig_cat.columns)\n",
    "\n",
    "print(f\"\\nNumber of categorical variables: {len(l_df_cat_names)}\")\n",
    "print(l_df_cat_names)\n",
    "\n",
    "\n",
    "# Create a list of dictionaries, where each dictionary represents a row\n",
    "rows = []\n",
    "for item in data:\n",
    "    # Select the fields you want to include in the table\n",
    "    row = {\n",
    "        'id': item.get('id'),\n",
    "        'power-gen-type': item.get('type').split(\"/\")[-1],\n",
    "        'capacity': item.get('capacity'),                    \n",
    "        'validto': item.get('validto')                \n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of dictionaries\n",
    "formatted_df = pd.DataFrame(rows)\n",
    "\n",
    "print(formatted_df.shape[0])\n",
    "print(formatted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_response_data(json_dict):\n",
    "\n",
    "    # Convert the list of utilizations into a DataFrame\n",
    "    # json_data = pd.DataFrame(json_dict[\"hydra:member\"])\n",
    "    \n",
    "    # f_describe(df, 10)\n",
    "    #df_orig_num    = json_data.select_dtypes(include='number')\n",
    "    #l_df_num_names = df_orig_num.columns.tolist()\n",
    "\n",
    "    # print(l_df_num_names)\n",
    "    # print(f\"\\nNumber of numerical variables: {len(l_df_num_names)}\")\n",
    "\n",
    "    #df_orig_cat    = json_data.select_dtypes(include='object')\n",
    "    #l_df_cat_names = list(df_orig_cat.columns)\n",
    "\n",
    "    # print(f\"\\nNumber of categorical variables: {len(l_df_cat_names)}\")\n",
    "    # print(l_df_cat_names)\n",
    "\n",
    "    # formatted_df = json_to_table(json_data)\n",
    "\n",
    "    # Convert 'capacity' to numeric, handling errors by setting non-numeric values to NaN\n",
    "    # formatted_df['capacity'] = pd.to_numeric(formatted_df['capacity'], errors='coerce')\n",
    "\n",
    "    # Filter, excluding rows where capacity is NaN\n",
    "    # filtered_df = formatted_df[formatted_df['capacity'] > 0].dropna(subset=['capacity'])\n",
    "\n",
    "    # print(filtered_df.shape[0])\n",
    "    # print(filtered_df)\n",
    "\n",
    "    # Create dictionary 'dc_ned_json_data_1' with objects that will be used in the next exercises.\n",
    "    #dc_ned_json_data_1 = {\n",
    "    #    'df_orig': json_data    \n",
    "    #}\n",
    "\n",
    "    # Save dc_exercise_1_2_3 as 'dc_ned_json_data_1.pkl'\n",
    "    #with open('../data/dc-ned-json-data-1.pkl', 'wb') as pickle_file:\n",
    "    #    pickle.dump(dc_ned_json_data_1, pickle_file)\n",
    "\n",
    "    # Display the DataFrame as a table\n",
    "    # print(\"\\nConverted JSON Payload to Table Format:\\n\")\n",
    "    # print(json_data.to_string(index=False))\n",
    "\n",
    "    #if formatted_df is not None:\n",
    "    #    # Print the DataFrame (table format)\n",
    "    #    print(formatted_df.head(3))\n",
    "    # return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enexis-data-visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
