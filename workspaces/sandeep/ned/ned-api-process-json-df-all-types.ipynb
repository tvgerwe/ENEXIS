{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle           # Save and load data\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Setting Pandas options.\n",
    "pd.set_option(\"display.max_rows\", 50) # How to display all rows from data frame using pandas. Setting value to None to show all rows.\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_info_columns\", 100)\n",
    "pd.set_option(\"display.max_info_rows\", 1000000)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "#pd.set_option(\"styler.format.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Key and download directory from config file\n",
    "CONFIG_FILE = \"../config/api-call.json\"\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from a JSON file.\"\"\"\n",
    "    with open(config_path, \"r\") as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config parameters for loading JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "config = load_config(CONFIG_FILE)\n",
    "# print(config)\n",
    "DOWNLOAD_DIR = config[\"ned\"][\"ned_download_dir\"]\n",
    "# Folder path containing files\n",
    "folder_path = config[\"ned\"][\"ned_download_dir\"]\n",
    "# File pattern to match (e.g., all CSV files that start with \"data_\")\n",
    "file_pattern = \"power-gen-type-0\"  # Change this based on your naming convention\n",
    "file = \"power-gen-type-0.json\"\n",
    "# Ensure the download directory exists\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch JSON files in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the processing\n",
      "File name is : <_io.TextIOWrapper name='../data/powergen/power-gen-type-0.json' mode='r' encoding='utf-8'>\n",
      "rows in df are :  34944\n",
      "\n",
      " DataFrame created successfully!\n",
      "\n",
      "['id', 'capacity', 'volume', 'percentage', 'emission', 'emissionfactor']\n",
      "\n",
      "Number of numerical variables: 6\n",
      "\n",
      "Number of categorical variables: 11\n",
      "['@id', '@type', 'point', 'type', 'granularity', 'granularitytimezone', 'activity', 'classification', 'validfrom', 'validto', 'lastupdate']\n",
      "34944\n",
      "                id power-gen-type  capacity                    validto\n",
      "0      23791261744              0   8134680  2021-12-31T23:15:00+00:00\n",
      "1      23791591475              0   8039900  2021-12-31T23:30:00+00:00\n",
      "2      23792244041              0   8128668  2021-12-31T23:45:00+00:00\n",
      "3      23792573621              0   8090804  2022-01-01T00:00:00+00:00\n",
      "4      23794423050              0   8101220  2022-01-01T00:15:00+00:00\n",
      "...            ...            ...       ...                        ...\n",
      "34939  51525834909              0  12094504  2022-12-30T22:00:00+00:00\n",
      "34940  51527700058              0  12053024  2022-12-30T22:15:00+00:00\n",
      "34941  51528040982              0  12010416  2022-12-30T22:30:00+00:00\n",
      "34942  51528716097              0  11933236  2022-12-30T22:45:00+00:00\n",
      "34943  51529057162              0  11862020  2022-12-30T23:00:00+00:00\n",
      "\n",
      "[34944 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Type\t    What is the type of energy carrier?\t0 All, 1 Wind, 2 Solar, 3 Biogas, 4 HeatPump, 8 Cofiring, 9 Geothermal, 10 Other, 11 Waste, 12 BioOil, 13 Biomass\n",
    "# 14 Wood, 17 WindOffshore, 18 FossilGasPower, 19 FossilHardCoal, 20 Nuclear, 21 WastePower, 22 WindOffshoreB, 23 NaturalGas, 24 Biomethane, 25 BiomassPower\n",
    "# 26 OtherPower, 27 ElectricityMix, 28 GasMix, 31 GasDistribution, 35 CHP Total, 50 SolarThermal, 51 WindOffshoreC, 53 IndustrialConsumersGasCombination\n",
    "# 54 IndustrialConsumersPowerGasCombination, 55 LocalDistributionCompaniesCombination, 56 AllConsumingGas\n",
    "\n",
    "\n",
    "# Define an array of n values (Custom values instead of a fixed range)\n",
    "# n_values = [4, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 35, 50, 51, 53, 54, 55, 56]  # Type values\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "# df_list = []\n",
    "\n",
    "# Dictionary to store dynamically named DataFrames\n",
    "# df_dict = {}\n",
    "\n",
    "print(\"starting the processing\")\n",
    "\n",
    "file_path = os.path.join(folder_path, file)\n",
    "df_name = os.path.splitext(file)[0]  # Removes .json extension\n",
    "        \n",
    "try:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f\"File name is : {f}\")\n",
    "        data = json.load(f)  # Load JSON data\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Extract 'hydra:member'\n",
    "# if \"hydra:member\" in data and isinstance(data[\"hydra:member\"], list) and len(data[\"hydra:member\"]) > 0:\n",
    "    # print(df_dict[df_name])\n",
    "    # df_dict[df_name] = pd.DataFrame(data[\"hydra:member\"])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"rows in df are : \", df.shape[0])\n",
    "print(\"\\n DataFrame created successfully!\\n\")\n",
    "# print(df.head())  # Display first few rows\n",
    "\n",
    "df_orig_num    = df.select_dtypes(include='number')\n",
    "l_df_num_names = df_orig_num.columns.tolist()\n",
    "print(l_df_num_names)\n",
    "print(f\"\\nNumber of numerical variables: {len(l_df_num_names)}\")\n",
    "\n",
    "df_orig_cat    = df.select_dtypes(include='object')\n",
    "l_df_cat_names = list(df_orig_cat.columns)\n",
    "\n",
    "print(f\"\\nNumber of categorical variables: {len(l_df_cat_names)}\")\n",
    "print(l_df_cat_names)\n",
    "\n",
    "# Extract the 'hydra:member' array which contains the utilization data\n",
    "# utilization_data = data.get('hydra:member', [])  # Handle missing key\n",
    "\n",
    "# Create a list of dictionaries, where each dictionary represents a row\n",
    "rows = []\n",
    "for item in data:\n",
    "    # Select the fields you want to include in the table\n",
    "    row = {\n",
    "        'id': item.get('id'),\n",
    "        'power-gen-type': item.get('type').split(\"/\")[-1],\n",
    "        'capacity': item.get('capacity'),                    \n",
    "        'validto': item.get('validto')                \n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of dictionaries\n",
    "formatted_df = pd.DataFrame(rows)\n",
    "\n",
    "# Convert 'capacity' to numeric, handling errors by setting non-numeric values to NaN\n",
    "# formatted_df['capacity'] = pd.to_numeric(formatted_df['capacity'], errors='coerce')\n",
    "\n",
    "# Filter, excluding rows where capacity is NaN\n",
    "# filtered_df = formatted_df[formatted_df['capacity'] > 0].dropna(subset=['capacity'])\n",
    "\n",
    "print(formatted_df.shape[0])\n",
    "print(formatted_df)\n",
    "\n",
    "# Loop through all files in the folder\n",
    "# for file in os.listdir(folder_path):\n",
    "    # if file.startswith(file_pattern) and file.endswith(\".json\"):  # Adjust for other formats if needed\n",
    "#    if file.startswith(file_pattern) and file.endswith(\".json\"):  # Adjust for other formats if needed\n",
    "        \n",
    "\n",
    "#        else:\n",
    "#            # print(df)\n",
    "#            print(\"\\nNo valid data found in 'hydra:member'.\")\n",
    "#        print(f\"Data stored in: {df_name}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_response_data(json_dict):\n",
    "\n",
    "    # Convert the list of utilizations into a DataFrame\n",
    "    # json_data = pd.DataFrame(json_dict[\"hydra:member\"])\n",
    "    \n",
    "    # f_describe(df, 10)\n",
    "    #df_orig_num    = json_data.select_dtypes(include='number')\n",
    "    #l_df_num_names = df_orig_num.columns.tolist()\n",
    "\n",
    "    # print(l_df_num_names)\n",
    "    # print(f\"\\nNumber of numerical variables: {len(l_df_num_names)}\")\n",
    "\n",
    "    #df_orig_cat    = json_data.select_dtypes(include='object')\n",
    "    #l_df_cat_names = list(df_orig_cat.columns)\n",
    "\n",
    "    # print(f\"\\nNumber of categorical variables: {len(l_df_cat_names)}\")\n",
    "    # print(l_df_cat_names)\n",
    "\n",
    "    # formatted_df = json_to_table(json_data)\n",
    "\n",
    "    # Convert 'capacity' to numeric, handling errors by setting non-numeric values to NaN\n",
    "    # formatted_df['capacity'] = pd.to_numeric(formatted_df['capacity'], errors='coerce')\n",
    "\n",
    "    # Filter, excluding rows where capacity is NaN\n",
    "    # filtered_df = formatted_df[formatted_df['capacity'] > 0].dropna(subset=['capacity'])\n",
    "\n",
    "    # print(filtered_df.shape[0])\n",
    "    # print(filtered_df)\n",
    "\n",
    "    # Create dictionary 'dc_ned_json_data_1' with objects that will be used in the next exercises.\n",
    "    #dc_ned_json_data_1 = {\n",
    "    #    'df_orig': json_data    \n",
    "    #}\n",
    "\n",
    "    # Save dc_exercise_1_2_3 as 'dc_ned_json_data_1.pkl'\n",
    "    #with open('../data/dc-ned-json-data-1.pkl', 'wb') as pickle_file:\n",
    "    #    pickle.dump(dc_ned_json_data_1, pickle_file)\n",
    "\n",
    "    # Display the DataFrame as a table\n",
    "    # print(\"\\nConverted JSON Payload to Table Format:\\n\")\n",
    "    # print(json_data.to_string(index=False))\n",
    "\n",
    "    #if formatted_df is not None:\n",
    "    #    # Print the DataFrame (table format)\n",
    "    #    print(formatted_df.head(3))\n",
    "    # return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enexis-data-visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
