{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Price Forecasting Script\n",
    "\n",
    "This script performs energy price forecasting using a SARIMA model. It processes a dataset of day-ahead energy prices from the year 2022, optimizes model parameters, and predicts the next week's energy prices.\n",
    "\n",
    "**Key Features and Goals:**\n",
    "- **Data Integrity and Leakage Prevention:**  \n",
    "  The script always performs a careful train-test split (for example, using a 3-week training period and a 1-week forecasting period) to ensure that no future data leaks into the training set.\n",
    "  \n",
    "- **Iterative and Modular Workflow:**  \n",
    "  Each step‚Äîfrom data loading and preprocessing to model fitting, forecasting, and evaluation‚Äîis separated into modular steps. This allows you to adjust date ranges, test data splits, and parameters at every stage.\n",
    "  \n",
    "- **Interactive Visualizations:**  \n",
    "  Using Plotly, the script provides interactive visualizations for exploratory data analysis (EDA) and forecast evaluation. You can zoom, hover, and dynamically explore the data and forecast results.\n",
    "  \n",
    "- **Model Optimization and Parameter Evaluation:**  \n",
    "  The SARIMA model parameters are optimized using Auto-ARIMA with a stepwise search, with the option to let auto_arima choose an optimal Box‚ÄìCox transformation.  \n",
    "  Additionally, details of all candidate hyperparameter configurations evaluated (via a candidate parameters summary) are logged, allowing you to analyze why a particular configuration was chosen and compare it with other model types (e.g., SARIMAX, ML, or deep learning models).\n",
    "\n",
    "- **Comprehensive Logging:**  \n",
    "  The experiment results‚Äîincluding date ranges, model type, selected parameters, error metrics (MAE, MSE, RMSE, MAPE, and MdAPE), and global forecast accuracy‚Äîare saved in two ways:\n",
    "  - A CSV log file named using the scheme: `SARIMA_used_log_YYYYMMDD_HHMM.csv` (stored in the designated Log folder).\n",
    "  - A cumulative SQLite database (`experiment_results.db`) stored in the designated Data folder, enabling robust querying and long-term tracking of all experiments.\n",
    "\n",
    "**Steps in This Script:**\n",
    "1. **Import & Setup Libraries:**  \n",
    "   Checks and imports all required libraries, ensuring that Plotly is configured for interactive visualizations.\n",
    "2. **Load and Preprocess Dataset:**  \n",
    "   Reads the CSV file, extracts timestamps from the \"MTU (CET/CEST)\" column, converts them to datetime, renames the target column (\"Day-ahead (EUR/MWh)\" to \"Energy Price\"), and resamples the data to a continuous hourly frequency.\n",
    "3. **Exploratory Data Analysis (EDA) with Interactive Visualizations:**  \n",
    "   Provides summary statistics, outlier detection, and interactive plots (time series, histogram, box plot) to explore the dataset.\n",
    "4. **Define Date Range and Split Data (Training & Testing):**  \n",
    "   Allows you to adjust the training (e.g., 3 weeks) and test (e.g., 1 week) periods, with an explicit check for data leakage.\n",
    "5. **Enhanced Interactive Visualization of Train-Test Split:**  \n",
    "   Creates an interactive Plotly chart that displays the full dataset with vertical lines and annotations marking the start of training, end of training, and end of test periods.\n",
    "6. **Fit Optimized SARIMA Model:**  \n",
    "   Uses Auto-ARIMA to select optimal model parameters and then trains a SARIMA model using the best-found configuration (with a fallback to default parameters if necessary).\n",
    "7. **Forecast the Next 7 Days and Visualize Results (Interactive):**  \n",
    "   Generates a 7-day forecast with confidence intervals, inverts any Box‚ÄìCox transformation if applied, and displays an interactive forecast chart with vertical markers.\n",
    "8. **Verify Forecast vs. Test Data and Evaluate Accuracy Metrics (Interactive):**  \n",
    "   Compares forecasted and actual values, computes overall error metrics (including MAE, MSE, RMSE, MAPE, and MdAPE), calculates a global forecast accuracy metric (by aggregating actual and forecast values), and provides interactive visualizations of both hourly and day-by-day performance.\n",
    "9. **Log Experiment Results:**  \n",
    "   Saves all experiment details (including candidate parameters evaluated) to both a CSV log file and a cumulative SQLite database for future analysis and model comparison.\n",
    "\n",
    "**Dataset Information:**\n",
    "- **Source:** Day-ahead energy prices (Year: 2022)\n",
    "- **Frequency:** Hourly data\n",
    "- **Target Column:** \"Energy Price\" (renamed from \"Day-ahead (EUR/MWh)\")\n",
    "- **Seasonality:** Daily (m=24)\n",
    "\n",
    "**Modeling Approach:**\n",
    "- **Primary Model:** SARIMA (with Auto-ARIMA optimization)\n",
    "- **Fallback Option:** Manual SARIMA parameters if Auto-ARIMA fails\n",
    "- **Additional Considerations:** The candidate parameter search summary is logged to help understand the selection process and support future comparisons with other models (e.g., SARIMAX, ML, or deep learning).\n",
    "\n",
    "This comprehensive and modular approach ensures robust model development, prevents data leakage, provides interactive insights, and enables detailed tracking and analysis of all experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Step 1: Import & Setup Libraries\n",
    "\n",
    "In this step, we check for and import all the required libraries. If a library is missing, the script will attempt to install it. This cell ensures that all dependencies are loaded and that Plotly is configured to render charts in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ pandas is installed.\n",
      "‚úÖ numpy is installed.\n",
      "‚úÖ plotly is installed.\n",
      "üìå scikit-learn is missing. Installing now...\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "‚úÖ scikit-learn installed successfully.\n",
      "‚úÖ statsmodels is installed.\n",
      "‚úÖ pmdarima is installed.\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import & Setup Libraries\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# List of required libraries\n",
    "REQUIRED_LIBRARIES = [\n",
    "    \"pandas\", \"numpy\", \"plotly\", \"scikit-learn\", \"statsmodels\", \"pmdarima\"\n",
    "    #, \"psutil\"\n",
    "]\n",
    "\n",
    "def check_and_install_libraries():\n",
    "    \"\"\"Checks and installs missing libraries.\"\"\"\n",
    "    for lib in REQUIRED_LIBRARIES:\n",
    "        try:\n",
    "            __import__(lib)\n",
    "            print(f\"‚úÖ {lib} is installed.\")\n",
    "        except ImportError:\n",
    "            print(f\"üìå {lib} is missing. Installing now...\")\n",
    "            subprocess.call([sys.executable, \"-m\", \"pip\", \"install\", lib])\n",
    "            print(f\"‚úÖ {lib} installed successfully.\")\n",
    "\n",
    "# Run the function to check/install libraries\n",
    "check_and_install_libraries()\n",
    "\n",
    "# Import libraries\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.io as pio\n",
    "    # from sklearn.model_selection import train_test_split\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    from pmdarima import auto_arima\n",
    "    # from statsmodels.tsa.stattools import adfuller\n",
    "    # from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "    # import scipy.stats as stats\n",
    "    # import psutil\n",
    "\n",
    "    # Configure Plotly to render in the notebook\n",
    "    pio.renderers.default = \"notebook\"\n",
    "    \n",
    "    print(\"\\n‚úÖ All libraries imported successfully!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during import: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ Step 2: Load and Preprocess Dataset\n",
    "\n",
    "In this step, we load the dataset and preprocess it. Note that the first column, \"MTU (CET/CEST)\", contains a date range in the format:  \n",
    "`\"dd/mm/yyyy HH:MM:SS - dd/mm/yyyy HH:MM:SS\"`.  \n",
    "We extract the starting timestamp (the portion before \" - \") and convert it to a datetime object using the format `%d/%m/%Y %H:%M:%S`.\n",
    "\n",
    "After parsing the timestamps, we:\n",
    "- Drop any rows with invalid timestamps.\n",
    "- Set the timestamp as the DataFrame index.\n",
    "- Rename the \"Day-ahead (EUR/MWh)\" column to \"Energy Price\" (which is our target variable).\n",
    "- Keep only the \"Energy Price\" column.\n",
    "- Ensure that the index has a continuous hourly frequency (filling missing timestamps if needed).\n",
    "\n",
    "Adjust the file path or format as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File found: /Users/sgawde/work/eaisi-code/main-branch-apr/ENEXIS/workspaces/sandeep/data/power-gen-consolidated-data-2022-2024.csv\n",
      "‚úÖ Raw data shape: (26303, 76)\n",
      "‚úÖ Raw data columns: ['date_x', 'Load', 'Price', 'Flow_BE_to_NL', 'Flow_NL_to_BE', 'Flow_DE_to_NL', 'Flow_NL_to_DE', 'Flow_GB_to_NL', 'Flow_NL_to_GB', 'Flow_DK_to_NL', 'Flow_NL_to_DK', 'Flow_NO_to_NL', 'Flow_NL_to_NO', 'Flow_BE', 'Flow_DE', 'Flow_GB', 'Flow_DK', 'Flow_NO', 'Total_Flow', 'index', 'date_y', 'temperature_2m', 'apparent_temperature', 'cloud_cover', 'wind_speed_10m', 'diffuse_radiation', 'direct_normal_irradiance', 'shortwave_radiation', 'wind_speed_100m', 'location', 'capacity_0', 'production_all', 'capacity_1', 'production_wind', 'capacity_2', 'production_solar', 'capacity_4', 'production_heatpump', 'capacity_8', 'production_cofiring', 'capacity_9', 'production_geothermal', 'capacity_10', 'production_other', 'capacity_11', 'production_waste', 'capacity_12', 'production_biooil', 'capacity_13', 'production_biomass', 'capacity_14', 'production_wood', 'capacity_17', 'production_windoffshore', 'capacity_18', 'production_fossilgaspower', 'capacity_19', 'production_fossilhardcoal', 'capacity_20', 'production_nuclear', 'capacity_21', 'production_wastepower', 'capacity_22', 'production_windoffshoreB', 'capacity_25', 'production_biomasspower', 'capacity_26', 'production_otherpower', 'capacity_27', 'production_electricitymix', 'capacity_35', 'production_CHP_total', 'capacity_50', 'production_solarthermal', 'capacity_51', 'production_allconsuminggas']\n",
      "‚úÖ Raw data preview:\n",
      "                      date_x      Load   Price  Flow_BE_to_NL  Flow_NL_to_BE  \\\n",
      "0  2022-01-01 00:00:00+00:00  10249.75  124.70            0.0          728.0   \n",
      "1  2022-01-01 01:00:00+00:00   9907.00  134.00            0.0         1070.0   \n",
      "2  2022-01-01 02:00:00+00:00   9782.50   58.80            0.0          344.0   \n",
      "3  2022-01-01 03:00:00+00:00   9589.75   37.67            0.0          154.0   \n",
      "4  2022-01-01 04:00:00+00:00   9508.00   39.70          352.0            0.0   \n",
      "\n",
      "   Flow_DE_to_NL  Flow_NL_to_DE  Flow_GB_to_NL  Flow_NL_to_GB  Flow_DK_to_NL  \\\n",
      "0        1314.00         425.50            0.0          591.0          582.0   \n",
      "1        1092.00         281.75            0.0          456.0          552.0   \n",
      "2        1372.50         849.25          412.0            0.0          237.0   \n",
      "3        1533.50        1067.75          795.0            0.0            0.0   \n",
      "4        1254.25        1323.00          994.0            0.0            0.0   \n",
      "\n",
      "   ...  capacity_26  production_otherpower  capacity_27  \\\n",
      "0  ...       241000                 241000     10246506   \n",
      "1  ...       241000                 241000     10083044   \n",
      "2  ...       241000                 241000      9595627   \n",
      "3  ...       241000                 241000      9044240   \n",
      "4  ...       241000                 241000      8799020   \n",
      "\n",
      "   production_electricitymix  capacity_35  production_CHP_total  capacity_50  \\\n",
      "0                   10246506      1127491               1127491          482   \n",
      "1                   10083044      1184195               1184195          391   \n",
      "2                    9595627      1181864               1181864          444   \n",
      "3                    9044240      1129166               1129166          461   \n",
      "4                    8799020      1140291               1140291          479   \n",
      "\n",
      "   production_solarthermal  capacity_51  production_allconsuminggas  \n",
      "0                      482      1865500                     1865500  \n",
      "1                      391      1839500                     1839500  \n",
      "2                      444      1429250                     1429250  \n",
      "3                      461      1349250                     1349250  \n",
      "4                      479      1436000                     1436000  \n",
      "\n",
      "[5 rows x 76 columns]\n",
      "\n",
      "‚úÖ Data shape after dropping invalid date: (26303, 77)\n",
      "\n",
      "‚úÖ Index range after sorting:\n",
      "   Start: 2022-01-01\n",
      "   End:   2024-12-31\n",
      "\n",
      "‚úÖ Data shape after dropping duplicate timestamps: (1096, 76)\n",
      "\n",
      "‚úÖ Final preprocessed data shape: (1096, 76)\n",
      "‚úÖ Final index range:\n",
      "   Start: 2022-01-01\n",
      "   End:   2024-12-31\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load and Preprocess Dataset\n",
    "\n",
    "import sys\n",
    "\n",
    "# Define file path components (adjust file name as needed)\n",
    "# file_path = os.path.join(DOWNLOAD_DIR, f\"power-gen-consolidated-data-2022-2024.csv\")  # Change extension as needed\n",
    "DATA_FOLDER = \"/Users/sgawde/work/eaisi-code/main-branch-apr/ENEXIS/workspaces/sandeep/data\"\n",
    "FILE_NAME = \"power-gen-consolidated-data-2022-2024.csv\"\n",
    "FILE_PATH = os.path.join(DATA_FOLDER, FILE_NAME)\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(FILE_PATH):\n",
    "    print(f\"‚ùå Error: File not found at {FILE_PATH}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"‚úÖ File found: {FILE_PATH}\")\n",
    "\n",
    "# Load the raw dataset and print its shape and columns\n",
    "df_raw = pd.read_csv(FILE_PATH)\n",
    "print(f\"‚úÖ Raw data shape: {df_raw.shape}\")\n",
    "print(\"‚úÖ Raw data columns:\", df_raw.columns.tolist())\n",
    "print(\"‚úÖ Raw data preview:\")\n",
    "print(df_raw.head())\n",
    "\n",
    "df_raw[\"date\"] = df_raw[\"date_x\"].copy()\n",
    "\n",
    "\n",
    "# Extract the start time from the \"MTU (CET/CEST)\" column.\n",
    "# The column is in the format: \"dd/mm/yyyy HH:MM:SS - dd/mm/yyyy HH:MM:SS\" 2022-01-01 00:00:00+00:00\n",
    "df_raw[\"date\"] = df_raw[\"date\"].str.split(\" \").str[0]\n",
    "\n",
    "# Parse the \"Timestamp\" column using the explicit format\n",
    "# df_raw[\"date\"] = pd.to_datetime(df_raw[\"date\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "# print(\"\\n‚úÖ date after parsing:\")\n",
    "# print(df_raw[\"date\"].head())\n",
    "\n",
    "# Drop any rows with invalid timestamps (NaT)\n",
    "df_raw = df_raw.dropna(subset=[\"date\"])\n",
    "print(f\"\\n‚úÖ Data shape after dropping invalid date: {df_raw.shape}\")\n",
    "\n",
    "# Set the \"Timestamp\" column as the index and sort the DataFrame\n",
    "df_raw.set_index(\"date\", inplace=True)\n",
    "df_raw.sort_index(inplace=True)\n",
    "print(\"\\n‚úÖ Index range after sorting:\")\n",
    "print(f\"   Start: {df_raw.index.min()}\")\n",
    "print(f\"   End:   {df_raw.index.max()}\")\n",
    "\n",
    "# Drop duplicate timestamps (keep the first occurrence)\n",
    "df_raw = df_raw[~df_raw.index.duplicated(keep=\"first\")]\n",
    "print(\"\\n‚úÖ Data shape after dropping duplicate timestamps:\", df_raw.shape)\n",
    "\n",
    "# Rename the energy price column:\n",
    "# Use the \"Day-ahead (EUR/MWh)\" column as the target variable.\n",
    "#if \"Day-ahead (EUR/MWh)\" in df_raw.columns:\n",
    "#    df_raw.rename(columns={\"Day-ahead (EUR/MWh)\": \"Energy Price\"}, inplace=True)\n",
    "#else:\n",
    "#    print(\"‚ö†Ô∏è Warning: 'Day-ahead (EUR/MWh)' column not found.\")\n",
    "\n",
    "# Keep only the \"Energy Price\" column\n",
    "#if \"Price\" in df_raw.columns:\n",
    "#    df_processed = df_raw[[\"Price\"]]\n",
    "#else:\n",
    "#    print(\"‚ùå ERROR: 'Price' column is missing. Check column names.\")\n",
    "#    sys.exit(1)\n",
    "\n",
    "# Ensure the index has a continuous hourly frequency (filling missing timestamps via forward fill)\n",
    "# df_processed = df_processed.asfreq(\"H\").ffill()\n",
    "print(\"\\n‚úÖ Final preprocessed data shape:\", df_raw.shape)\n",
    "print(\"‚úÖ Final index range:\")\n",
    "print(f\"   Start: {df_raw.index.min()}\")\n",
    "print(f\"   End:   {df_raw.index.max()}\")\n",
    "\n",
    "# Assign the processed DataFrame to 'df' for use in subsequent steps\n",
    "# df = df_raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Step 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this step, we explore the preprocessed dataset in detail. We will:\n",
    "- Provide an overview of the dataset (number of rows, columns, data types, missing values).\n",
    "- Display descriptive statistics and distributions for the numerical columns.\n",
    "- Detect potential outliers using the Interquartile Range (IQR) method.\n",
    "\n",
    "This analysis helps us understand the data quality and guides any necessary preprocessing adjustments before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Dataset Overview:\n",
      "- Number of rows: 1096\n",
      "- Number of columns: 72\n",
      "\n",
      "üìå Column Information:\n",
      "                           Data Type  Missing Values  Unique Values  \\\n",
      "index                          int64               0           1096   \n",
      "Load                         float64               0           1034   \n",
      "Price                        float64               0           1009   \n",
      "Flow_BE_to_NL                float64               0            406   \n",
      "Flow_NL_to_BE                float64               0            609   \n",
      "...                              ...             ...            ...   \n",
      "production_CHP_total         float64            1096              0   \n",
      "capacity_50                  float64            1096              0   \n",
      "production_solarthermal      float64            1096              0   \n",
      "capacity_51                  float64            1096              0   \n",
      "production_allconsuminggas   float64            1096              0   \n",
      "\n",
      "                            First Value  Last Value  \n",
      "index                              0.00     26280.0  \n",
      "Load                           10249.75     11857.5  \n",
      "Price                            124.70        54.9  \n",
      "Flow_BE_to_NL                      0.00         0.0  \n",
      "Flow_NL_to_BE                    728.00      1310.0  \n",
      "...                                 ...         ...  \n",
      "production_CHP_total                NaN         NaN  \n",
      "capacity_50                         NaN         NaN  \n",
      "production_solarthermal             NaN         NaN  \n",
      "capacity_51                         NaN         NaN  \n",
      "production_allconsuminggas          NaN         NaN  \n",
      "\n",
      "[72 rows x 5 columns]\n",
      "\n",
      "üìä Column Distribution & Summary Statistics:\n",
      "              index          Load        Price  Flow_BE_to_NL  Flow_NL_to_BE  \\\n",
      "count   1096.000000   1096.000000  1096.000000    1096.000000    1096.000000   \n",
      "mean   13140.000000  10745.998631   120.934261     298.913321     724.589416   \n",
      "std     7596.774052    693.557284    93.628228     519.195647     858.406989   \n",
      "min        0.000000   9214.250000    -4.400000       0.000000       0.000000   \n",
      "25%     6570.000000  10259.500000    70.775000       0.000000       0.000000   \n",
      "50%    13140.000000  10655.125000    93.200000       0.000000     351.000000   \n",
      "75%    19710.000000  11104.312500   148.790000     432.000000    1302.500000   \n",
      "max    26280.000000  13179.000000   636.800000    3145.000000    3733.000000   \n",
      "\n",
      "       Flow_DE_to_NL  Flow_NL_to_DE  Flow_GB_to_NL  Flow_NL_to_GB  \\\n",
      "count    1096.000000    1096.000000     1096.00000    1096.000000   \n",
      "mean     1020.536953     761.503878      295.38458     323.796305   \n",
      "std       815.780580     881.795384      392.20115     417.883390   \n",
      "min         0.000000       0.000000        0.00000       0.000000   \n",
      "25%       364.687500       0.000000        0.00000       0.000000   \n",
      "50%       911.250000     440.875000        0.00000       0.000000   \n",
      "75%      1493.562500    1333.375000      631.50000     732.062500   \n",
      "max      4781.500000    4564.500000     1058.00000    1080.000000   \n",
      "\n",
      "       Flow_DK_to_NL  ...  capacity_26  production_otherpower  capacity_27  \\\n",
      "count    1096.000000  ...          0.0                    0.0          0.0   \n",
      "mean      342.015511  ...          NaN                    NaN          NaN   \n",
      "std       314.677045  ...          NaN                    NaN          NaN   \n",
      "min         0.000000  ...          NaN                    NaN          NaN   \n",
      "25%         0.000000  ...          NaN                    NaN          NaN   \n",
      "50%       374.000000  ...          NaN                    NaN          NaN   \n",
      "75%       698.000000  ...          NaN                    NaN          NaN   \n",
      "max       701.000000  ...          NaN                    NaN          NaN   \n",
      "\n",
      "       production_electricitymix  capacity_35  production_CHP_total  \\\n",
      "count                        0.0          0.0                   0.0   \n",
      "mean                         NaN          NaN                   NaN   \n",
      "std                          NaN          NaN                   NaN   \n",
      "min                          NaN          NaN                   NaN   \n",
      "25%                          NaN          NaN                   NaN   \n",
      "50%                          NaN          NaN                   NaN   \n",
      "75%                          NaN          NaN                   NaN   \n",
      "max                          NaN          NaN                   NaN   \n",
      "\n",
      "       capacity_50  production_solarthermal  capacity_51  \\\n",
      "count          0.0                      0.0          0.0   \n",
      "mean           NaN                      NaN          NaN   \n",
      "std            NaN                      NaN          NaN   \n",
      "min            NaN                      NaN          NaN   \n",
      "25%            NaN                      NaN          NaN   \n",
      "50%            NaN                      NaN          NaN   \n",
      "75%            NaN                      NaN          NaN   \n",
      "max            NaN                      NaN          NaN   \n",
      "\n",
      "       production_allconsuminggas  \n",
      "count                         0.0  \n",
      "mean                          NaN  \n",
      "std                           NaN  \n",
      "min                           NaN  \n",
      "25%                           NaN  \n",
      "50%                           NaN  \n",
      "75%                           NaN  \n",
      "max                           NaN  \n",
      "\n",
      "[8 rows x 72 columns]\n",
      "\n",
      "üö® Outlier Detection:\n",
      "Load                30\n",
      "Price               97\n",
      "Flow_BE_to_NL      112\n",
      "Flow_NL_to_BE        2\n",
      "Flow_DE_to_NL       19\n",
      "Flow_NL_to_DE        8\n",
      "Flow_NL_to_DK      217\n",
      "Flow_NL_to_NO      150\n",
      "Flow_BE              1\n",
      "Flow_DE              4\n",
      "Total_Flow          14\n",
      "wind_speed_10m      19\n",
      "wind_speed_100m     19\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 1. Interactive Time Series Plot\\nfig_line = px.line(\\n    df,\\n    x=df.index,\\n    y=\"Price\",\\n    title=\"Interactive Energy Price Time Series\",\\n    labels={\"x\": \"Time\", \"Energy Price\": \"Price (EUR/MWh)\"},\\n    template=\"plotly_dark\"\\n)\\nfig_line.update_xaxes(rangeslider_visible=True)\\nfig_line.show()\\n\\n# 2. Interactive Histogram of Energy Price\\nfig_hist = px.histogram(\\n    df,\\n    x=\"Price\",\\n    nbins=50,\\n    title=\"Distribution of Energy Price\",\\n    labels={\"Energy Price\": \"Price (EUR/MWh)\"},\\n    template=\"plotly_dark\"\\n)\\nfig_hist.update_layout(bargap=0.1)\\nfig_hist.show()\\n\\n# 3. Interactive Box Plot for Energy Price\\nfig_box = px.box(\\n    df,\\n    y=\"Price\",\\n    title=\"Box Plot of Energy Price\",\\n    labels={\"Energy Price\": \"Price (EUR/MWh)\"},\\n    template=\"plotly_dark\"\\n)\\nfig_box.show()\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Exploratory Data Analysis (EDA) with Interactive Visualizations\n",
    "\n",
    "def dataset_summary(data):\n",
    "    \"\"\"Prints an overview of the dataset, including column quality, data types, and missing values.\"\"\"\n",
    "    if data.empty:\n",
    "        print(\"‚ö†Ô∏è Warning: The dataset is empty. Please check the preprocessing steps.\")\n",
    "        return\n",
    "    print(\"\\nüîç Dataset Overview:\")\n",
    "    print(f\"- Number of rows: {data.shape[0]}\")\n",
    "    print(f\"- Number of columns: {data.shape[1]}\")\n",
    "    \n",
    "    print(\"\\nüìå Column Information:\")\n",
    "    try:\n",
    "        summary_df = pd.DataFrame({\n",
    "            \"Data Type\": data.dtypes,\n",
    "            \"Missing Values\": data.isnull().sum(),\n",
    "            \"Unique Values\": data.nunique(),\n",
    "            \"First Value\": data.iloc[0],\n",
    "            \"Last Value\": data.iloc[-1]\n",
    "        })\n",
    "        print(summary_df)\n",
    "    except IndexError:\n",
    "        print(\"‚ö†Ô∏è Cannot display first/last values because the dataset is empty.\")\n",
    "\n",
    "def column_distribution(data):\n",
    "    \"\"\"Displays descriptive statistics for numerical columns.\"\"\"\n",
    "    if data.empty:\n",
    "        print(\"‚ö†Ô∏è Dataset is empty. Skipping descriptive statistics.\")\n",
    "    else:\n",
    "        print(\"\\nüìä Column Distribution & Summary Statistics:\")\n",
    "        print(data.describe())\n",
    "\n",
    "def detect_outliers(data):\n",
    "    \"\"\"Identifies potential outliers using the IQR method.\"\"\"\n",
    "    if data.empty:\n",
    "        print(\"‚ö†Ô∏è Dataset is empty. Skipping outlier detection.\")\n",
    "    else:\n",
    "        print(\"\\nüö® Outlier Detection:\")\n",
    "        numerical_cols = data.select_dtypes(include=['number'])\n",
    "        Q1 = numerical_cols.quantile(0.25)\n",
    "        Q3 = numerical_cols.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((numerical_cols < (Q1 - 1.5 * IQR)) | (numerical_cols > (Q3 + 1.5 * IQR))).sum()\n",
    "        # Only print columns with detected outliers\n",
    "        outliers = outliers[outliers > 0]\n",
    "        if outliers.empty:\n",
    "            print(\"‚úÖ No outliers detected.\")\n",
    "        else:\n",
    "            print(outliers)\n",
    "\n",
    "# Run summary functions on the preprocessed DataFrame (df)\n",
    "dataset_summary(df)\n",
    "column_distribution(df)\n",
    "detect_outliers(df)\n",
    "\n",
    "# Interactive Visualizations using Plotly Express\n",
    "\n",
    "import plotly.express as px\n",
    "'''\n",
    "# 1. Interactive Time Series Plot\n",
    "fig_line = px.line(\n",
    "    df,\n",
    "    x=df.index,\n",
    "    y=\"Price\",\n",
    "    title=\"Interactive Energy Price Time Series\",\n",
    "    labels={\"x\": \"Time\", \"Energy Price\": \"Price (EUR/MWh)\"},\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig_line.update_xaxes(rangeslider_visible=True)\n",
    "fig_line.show()\n",
    "\n",
    "# 2. Interactive Histogram of Energy Price\n",
    "fig_hist = px.histogram(\n",
    "    df,\n",
    "    x=\"Price\",\n",
    "    nbins=50,\n",
    "    title=\"Distribution of Energy Price\",\n",
    "    labels={\"Energy Price\": \"Price (EUR/MWh)\"},\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig_hist.update_layout(bargap=0.1)\n",
    "fig_hist.show()\n",
    "\n",
    "# 3. Interactive Box Plot for Energy Price\n",
    "fig_box = px.box(\n",
    "    df,\n",
    "    y=\"Price\",\n",
    "    title=\"Box Plot of Energy Price\",\n",
    "    labels={\"Energy Price\": \"Price (EUR/MWh)\"},\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig_box.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Step 4: Train-Test Split\n",
    "\n",
    "In this step, we select specific date ranges for training and testing:\n",
    "- **Training Period:** 3 weeks (e.g., from 2023-06-01 to 2023-06-21)\n",
    "- **Test Period:** The following 1 week (e.g., from 2023-06-22 to 2023-06-28)\n",
    "\n",
    "This ensures that our training data does not leak into our test data. If necessary, adjust the date ranges to suit your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No data leakage: Training data ends before Test data begins.\n",
      "\n",
      "‚úÖ Train Data Summary:\n",
      "   Start: 2022-01-01, End: 2022-12-31, Total: 365 records\n",
      "‚úÖ Test Data Summary:\n",
      "   Start: 2023-10-01, End: 2023-10-31, Total: 31 records\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train-Test Split\n",
    "\n",
    "# Define training and testing date ranges (adjust as needed)\n",
    "train_start = \"2022-01-01\"\n",
    "train_end = \"2022-12-31\"   # 3 weeks of training data\n",
    "test_start  = \"2023-10-01\"\n",
    "test_end    = \"2023-10-31\"   # 1 week of test/forecasting data\n",
    "\n",
    "df[\"location\"] = df[\"location\"].replace(\"DeBilt\", 1.0)\n",
    "\n",
    "# Filter the DataFrame to select the training and test periods\n",
    "train = df.loc[train_start:train_end]\n",
    "test = df.loc[test_start:test_end]\n",
    "\n",
    "# Check for data leakage: ensure that the training set ends before the test set begins\n",
    "if train.index.max() < test.index.min():\n",
    "    print(\"‚úÖ No data leakage: Training data ends before Test data begins.\")\n",
    "else:\n",
    "    print(\"Data leakage detected: Training data overlaps with Test data!\")\n",
    "    # raise ValueError(\"‚ùå Data leakage detected: Training data overlaps with Test data!\")\n",
    "\n",
    "# Print summary of the train-test split\n",
    "print(\"\\n‚úÖ Train Data Summary:\")\n",
    "print(f\"   Start: {train.index.min()}, End: {train.index.max()}, Total: {len(train)} records\")\n",
    "print(\"‚úÖ Test Data Summary:\")\n",
    "print(f\"   Start: {test.index.min()}, End: {test.index.max()}, Total: {len(test)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ Step 5: Interactive Data Visualization (Plotly)\n",
    "\n",
    "In this step, we create interactive visualizations using Plotly. The visualization displays the full time series with the \"Energy Price\" and highlights the train-test split. You can use the range slider and selectors to zoom in or filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç **Train & Test Dataset Overview:**\n",
      "- Train Records: 365, Test Records: 31\n",
      "- Train Range: 2022-01-01 ‚Üí 2022-12-31\n",
      "- Test Range: 2023-10-01 ‚Üí 2023-10-31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Create an interactive line plot of the full dataset\\nfig = px.line(\\n    df,\\n    x=df.index,\\n    y=\"Price\",\\n    title=\"üìà Interactive Energy Price Time Series (Train & Test Split)\",\\n    labels={\"Price\": \"Price (EUR/MWh)\", \"index\": \"Time\"},\\n    template=\"plotly_dark\"\\n)\\n\\n# 1. Add vertical line for train start\\nfig.add_vline(\\n    x=train.index[0],\\n    line_width=3,\\n    line_dash=\"dash\",\\n    line_color=\"green\"\\n)\\n\\n# 2. Add vertical line for train end\\nfig.add_vline(\\n    x=train.index[-1],\\n    line_width=3,\\n    line_dash=\"dash\",\\n    line_color=\"red\"\\n)\\n\\n# 3. Add vertical line for test end\\nfig.add_vline(\\n    x=test.index[-1],\\n    line_width=3,\\n    line_dash=\"dash\",\\n    line_color=\"blue\"\\n)\\n\\n# Customize layout to include range selectors, slider, and annotations\\nfig.update_layout(\\n    xaxis=dict(\\n        rangeselector=dict(\\n            buttons=list([\\n                dict(count=7, label=\"1W\", step=\"day\", stepmode=\"backward\"),\\n                dict(count=30, label=\"1M\", step=\"day\", stepmode=\"backward\"),\\n                dict(step=\"all\")\\n            ])\\n        ),\\n        rangeslider=dict(visible=True),\\n        type=\"date\"\\n    ),\\n    annotations=[\\n        # Train Start Annotation\\n        dict(\\n            x=train.index[0],\\n            y=df[\"Price\"].max(),\\n            text=\"Train Start\",\\n            showarrow=True,\\n            arrowhead=2,\\n            arrowcolor=\"green\"\\n        ),\\n        # Train End Annotation\\n        dict(\\n            x=train.index[-1],\\n            y=df[\"Price\"].max(),\\n            text=\"Train End\",\\n            showarrow=True,\\n            arrowhead=2,\\n            arrowcolor=\"red\"\\n        ),\\n        # Test End Annotation\\n        dict(\\n            x=test.index[-1],\\n            y=df[\"Price\"].max(),\\n            text=\"Test End\",\\n            showarrow=True,\\n            arrowhead=2,\\n            arrowcolor=\"blue\"\\n        )\\n    ]\\n)\\n\\n# Show the interactive plot\\nfig.show()\\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Enhanced Interactive Data Visualization (Plotly)\n",
    "\n",
    "# Ensure Plotly renders inside the notebook\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# Print a summary of the training and testing datasets\n",
    "print(\"\\nüîç **Train & Test Dataset Overview:**\")\n",
    "print(f\"- Train Records: {len(train)}, Test Records: {len(test)}\")\n",
    "print(f\"- Train Range: {train.index.min()} ‚Üí {train.index.max()}\")\n",
    "print(f\"- Test Range: {test.index.min()} ‚Üí {test.index.max()}\")\n",
    "'''\n",
    "# Create an interactive line plot of the full dataset\n",
    "fig = px.line(\n",
    "    df,\n",
    "    x=df.index,\n",
    "    y=\"Price\",\n",
    "    title=\"üìà Interactive Energy Price Time Series (Train & Test Split)\",\n",
    "    labels={\"Price\": \"Price (EUR/MWh)\", \"index\": \"Time\"},\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "\n",
    "# 1. Add vertical line for train start\n",
    "fig.add_vline(\n",
    "    x=train.index[0],\n",
    "    line_width=3,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"green\"\n",
    ")\n",
    "\n",
    "# 2. Add vertical line for train end\n",
    "fig.add_vline(\n",
    "    x=train.index[-1],\n",
    "    line_width=3,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"red\"\n",
    ")\n",
    "\n",
    "# 3. Add vertical line for test end\n",
    "fig.add_vline(\n",
    "    x=test.index[-1],\n",
    "    line_width=3,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"blue\"\n",
    ")\n",
    "\n",
    "# Customize layout to include range selectors, slider, and annotations\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=7, label=\"1W\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=30, label=\"1M\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    ),\n",
    "    annotations=[\n",
    "        # Train Start Annotation\n",
    "        dict(\n",
    "            x=train.index[0],\n",
    "            y=df[\"Price\"].max(),\n",
    "            text=\"Train Start\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            arrowcolor=\"green\"\n",
    "        ),\n",
    "        # Train End Annotation\n",
    "        dict(\n",
    "            x=train.index[-1],\n",
    "            y=df[\"Price\"].max(),\n",
    "            text=\"Train End\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            arrowcolor=\"red\"\n",
    "        ),\n",
    "        # Test End Annotation\n",
    "        dict(\n",
    "            x=test.index[-1],\n",
    "            y=df[\"Price\"].max(),\n",
    "            text=\"Test End\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            arrowcolor=\"blue\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6Ô∏è‚É£ Step 6: Fit SARIMA Model (Optimized for Speed)\n",
    "\n",
    "In this step, we use Auto‚ÄêARIMA to search for the best SARIMA parameters on the training data. We use a stepwise search (which is more efficient) and allow auto_arima to choose an optimal Box‚ÄìCox transformation if needed. \n",
    "\n",
    "After obtaining the optimal orders, we train a SARIMA model using the selected parameters. \n",
    "\n",
    "*Note:* If Auto‚ÄêARIMA fails for any reason, default parameters will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Running Optimized Auto-ARIMA to select best parameters...\n",
      "Performing stepwise search to minimize aic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,2)(1,0,1)[7] intercept   : AIC=11091.410, Time=2.89 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7] intercept   : AIC=11251.259, Time=0.05 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,0)(1,0,0)[7] intercept   : AIC=11205.898, Time=0.20 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,1)(0,0,1)[7] intercept   : AIC=11152.611, Time=0.83 sec\n",
      " ARIMA(0,1,0)(0,0,0)[7]             : AIC=11249.262, Time=0.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,2)(0,0,1)[7] intercept   : AIC=11092.305, Time=1.69 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,2)(1,0,0)[7] intercept   : AIC=11092.243, Time=1.13 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,2)(2,0,1)[7] intercept   : AIC=11092.595, Time=2.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,2)(1,0,2)[7] intercept   : AIC=11092.615, Time=2.68 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,2)(0,0,0)[7] intercept   : AIC=11090.868, Time=0.78 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,2)(0,0,0)[7] intercept   : AIC=11089.149, Time=0.46 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,2)(1,0,0)[7] intercept   : AIC=11090.678, Time=0.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,2)(0,0,1)[7] intercept   : AIC=11090.724, Time=0.80 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,2)(1,0,1)[7] intercept   : AIC=11089.811, Time=1.43 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,2)(0,0,0)[7] intercept   : AIC=11089.542, Time=0.26 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,1)(0,0,0)[7] intercept   : AIC=11093.916, Time=0.33 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(0,0,0)[7] intercept   : AIC=11086.793, Time=0.72 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(1,0,0)[7] intercept   : AIC=11089.962, Time=0.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(0,0,1)[7] intercept   : AIC=11088.790, Time=1.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(1,0,1)[7] intercept   : AIC=11089.194, Time=1.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,3)(0,0,0)[7] intercept   : AIC=11088.501, Time=0.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,3)(0,0,0)[7] intercept   : AIC=11089.919, Time=0.88 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,4)(0,0,0)[7] intercept   : AIC=11090.117, Time=0.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,4)(0,0,0)[7] intercept   : AIC=11088.975, Time=0.47 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,4)(0,0,0)[7] intercept   : AIC=11088.537, Time=1.50 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(0,0,0)[7]             : AIC=11084.794, Time=0.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(1,0,0)[7]             : AIC=11086.793, Time=0.71 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(0,0,1)[7]             : AIC=11086.793, Time=0.73 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(1,0,1)[7]             : AIC=11087.197, Time=0.73 sec\n",
      " ARIMA(0,1,3)(0,0,0)[7]             : AIC=11086.505, Time=0.11 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,2)(0,0,0)[7]             : AIC=11087.153, Time=0.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,3)(0,0,0)[7]             : AIC=11087.921, Time=0.40 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,4)(0,0,0)[7]             : AIC=11088.120, Time=0.26 sec\n",
      " ARIMA(0,1,2)(0,0,0)[7]             : AIC=11087.544, Time=0.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,4)(0,0,0)[7]             : AIC=11086.978, Time=0.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,2)(0,0,0)[7]             : AIC=11088.871, Time=0.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,4)(0,0,0)[7]             : AIC=11086.635, Time=0.92 sec\n",
      "\n",
      "Best model:  ARIMA(1,1,3)(0,0,0)[7]          \n",
      "Total fit time: 31.621 seconds\n",
      "Best ARIMA Order: (1, 1, 3), Best Seasonal Order: (0, 0, 0, 7)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1096, 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     32\u001b[39m forecast = sarima_results.forecast(steps=future_steps)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# ‚úÖ Step 6: Plot the Results\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# plt.figure(figsize=(10,5))\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# plt.plot(df.index, y, label=\"Actual Data\", color=\"blue\")\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# plt.gcf().autofmt_xdate()  # Rotate x-axis labels to avoid formatting issues\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Compute evaluation metrics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m mae_ltsm = \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m rmse_ltsm = np.sqrt(mean_squared_error(y, forecast))\n\u001b[32m     42\u001b[39m mape_ltsm = mean_absolute_percentage_error(y, forecast)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/metrics/_regression.py:277\u001b[39m, in \u001b[36mmean_absolute_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[32m    223\u001b[39m \n\u001b[32m    224\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    272\u001b[39m \u001b[33;03m0.85...\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    274\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    276\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m )\n\u001b[32m    282\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    284\u001b[39m output_errors = _average(\n\u001b[32m    285\u001b[39m     xp.abs(y_pred - y_true), weights=sample_weight, axis=\u001b[32m0\u001b[39m, xp=xp\n\u001b[32m    286\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/metrics/_regression.py:198\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[33;03mregression task.\u001b[39;00m\n\u001b[32m    150\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    195\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    196\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m y_type, y_true, y_pred, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/metrics/_regression.py:104\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, multioutput, dtype, xp)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m \u001b[33;03mTo reduce redundancy when calling `_find_matching_floating_dtype`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m y_true = check_array(y_true, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    106\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/enexis-mar-visualization/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [1096, 30]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "print(\"\\n‚è≥ Running Optimized Auto-ARIMA to select best parameters...\")\n",
    "\n",
    "# ‚úÖ Step 1: Ensure 'sales' is a 1D array\n",
    "y = df['Price'].values.ravel()\n",
    "\n",
    "# ‚úÖ Step 2: Use Auto-ARIMA to Find the Best Model\n",
    "auto_model = auto_arima(\n",
    "    y,\n",
    "    seasonal=True,  # Use seasonal ARIMA\n",
    "    m=7,  # Seasonal period (weekly data)\n",
    "    trace=True,  # Show fitting process\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 3: Print the Best ARIMA Order\n",
    "print(f\"Best ARIMA Order: {auto_model.order}, Best Seasonal Order: {auto_model.seasonal_order}\")\n",
    "\n",
    "# ‚úÖ Step 4: Fit SARIMAX Using the Best Parameters\n",
    "best_order = auto_model.order\n",
    "best_seasonal_order = auto_model.seasonal_order\n",
    "\n",
    "sarima_model = SARIMAX(y, order=best_order, seasonal_order=best_seasonal_order)\n",
    "sarima_results = sarima_model.fit()\n",
    "\n",
    "# ‚úÖ Step 5: Forecast Next 30 Days\n",
    "future_steps = 30\n",
    "forecast = sarima_results.forecast(steps=future_steps)\n",
    "\n",
    "# ‚úÖ Step 6: Plot the Results\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.plot(df.index, y, label=\"Actual Data\", color=\"blue\")\n",
    "# plt.gcf().autofmt_xdate()  # Rotate x-axis labels to avoid formatting issues\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mae_ltsm = mean_absolute_error(y, forecast)\n",
    "rmse_ltsm = np.sqrt(mean_squared_error(y, forecast))\n",
    "mape_ltsm = mean_absolute_percentage_error(y, forecast)\n",
    "# smape_ltsm = symmetric_mape(y, forecast)\n",
    "# aic_ltsm = compute_aic(y, forecast, num_params=train.shape[1] + 1)\n",
    "\n",
    "print(mae_ltsm, rmse_ltsm, mape_ltsm)\n",
    "\n",
    "'''\n",
    "start_arima = time.time()\n",
    "try:\n",
    "    auto_model = auto_arima(\n",
    "        train,\n",
    "        seasonal=True,\n",
    "        m=24,                 # Daily seasonality in hourly data\n",
    "        stepwise=True,        # Use heuristic search for efficiency\n",
    "        trace=True,           # Show search progress (disable later if desired)\n",
    "        suppress_warnings=True,\n",
    "        # n_jobs is ignored in stepwise mode\n",
    "        max_p=2, max_q=2,     # Limit non-seasonal AR & MA terms\n",
    "        max_P=1, max_Q=1,     # Limit seasonal terms\n",
    "        d=1, D=1,\n",
    "        max_order=10,         # Restrict total number of parameters\n",
    "        trend=\"t\",\n",
    "        lambda_=\"auto\",       # Let auto_arima choose an optimal Box‚ÄìCox transformation (if beneficial)\n",
    "        information_criterion=\"aic\"\n",
    "    )\n",
    "\n",
    "    best_order, best_seasonal_order = auto_model.order, auto_model.seasonal_order\n",
    "    elapsed_arima = time.time() - start_arima\n",
    "    print(f\"‚úÖ Best SARIMA order: {best_order}, Seasonal Order: {best_seasonal_order}\")\n",
    "    print(f\"‚è± Auto-ARIMA completed in {elapsed_arima:.2f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Auto-ARIMA failed. Using default SARIMA parameters. Error: {e}\")\n",
    "    best_order, best_seasonal_order = (2, 1, 1), (1, 1, 1, 24)\n",
    "\n",
    "\n",
    "# Check if a Box‚ÄìCox transformation was applied and print the lambda value if available\n",
    "if hasattr(auto_model, 'lambda_') and auto_model.lambda_ is not None:\n",
    "    print(f\"üìê Optimal Box‚ÄìCox lambda: {auto_model.lambda_:.4f}\")\n",
    "else:\n",
    "    print(\"üìê No Box‚ÄìCox transformation was applied.\")\n",
    "\n",
    "print(\"\\n‚è≥ Training Optimized SARIMA Model...\")\n",
    "\n",
    "sarima_model = SARIMAX(\n",
    "    train,\n",
    "    order=best_order,\n",
    "    seasonal_order=best_seasonal_order,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarima_result = sarima_model.fit(disp=False)\n",
    "print(\"‚úÖ Optimized SARIMA model trained successfully!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7Ô∏è‚É£ Step 7: Forecast the Next 7 Days and Visualize Results\n",
    "\n",
    "In this step, we:\n",
    "- Use the trained SARIMA model to forecast the next 7 days (168 hours) of energy prices.\n",
    "- Create a forecast index based on the start of the test period.\n",
    "- Extract the forecasted mean and confidence intervals.\n",
    "- **Important:** If a Box‚ÄìCox transformation was applied (via `lambda_=\"auto\"` in Auto‚ÄêARIMA), we invert the transformation for the forecast output.\n",
    "- Plot the forecast along with the training and test data to visually compare model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê No Box‚ÄìCox transformation to invert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/xs43v__d0mn25qy5kzxrnkrm0000gn/T/ipykernel_26257/1659982504.py:13: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_pydatetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m forecast_df = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mForecasted Price\u001b[39m\u001b[33m\"\u001b[39m: forecast_mean}, index=forecast_index)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Convert test.index.min() to a Python datetime object for add_vline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m forecast_start_dt = \u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pydatetime\u001b[49m()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Build Interactive Plotly Figure\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     38\u001b[39m fig = go.Figure()\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'to_pydatetime'"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "\n",
    "# Define forecast horizon: 7 days * 24 hours = 168 hours\n",
    "forecast_steps = 24 * 7\n",
    "\n",
    "# Create forecast results using the SARIMA model\n",
    "forecast_obj = sarima_results.get_forecast(steps=forecast_steps)\n",
    "forecast_mean = forecast_obj.predicted_mean\n",
    "forecast_conf_int = forecast_obj.conf_int()\n",
    "\n",
    "# Create a forecast index starting at the beginning of the test set\n",
    "forecast_index = pd.date_range(start=test.index.min(), periods=forecast_steps, freq=\"H\")\n",
    "\n",
    "# Check if a Box‚ÄìCox transformation was applied in Auto‚ÄêARIMA\n",
    "lambda_val = None\n",
    "if hasattr(auto_model, 'lambda_'):\n",
    "    lambda_val = auto_model.lambda_\n",
    "\n",
    "# If a transformation was applied (and lambda is not 1), invert the Box‚ÄìCox transformation:\n",
    "# Inverse Box‚ÄìCox: x = (y*lambda + 1)**(1/lambda)\n",
    "if lambda_val is not None and lambda_val != 1:\n",
    "    forecast_mean = (forecast_mean * lambda_val + 1) ** (1 / lambda_val)\n",
    "    forecast_conf_int = (forecast_conf_int * lambda_val + 1) ** (1 / lambda_val)\n",
    "    print(f\"üìê Inverting Box‚ÄìCox transform using lambda: {lambda_val:.4f}\")\n",
    "else:\n",
    "    print(\"üìê No Box‚ÄìCox transformation to invert.\")\n",
    "\n",
    "# Build a DataFrame for the forecast results\n",
    "forecast_df = pd.DataFrame({\"Forecasted Price\": forecast_mean}, index=forecast_index)\n",
    "\n",
    "# Convert test.index.min() to a Python datetime object for add_vline\n",
    "forecast_start_dt = test.index.min().to_pydatetime()\n",
    "\n",
    "# -----------------------------\n",
    "# Build Interactive Plotly Figure\n",
    "# -----------------------------\n",
    "fig = go.Figure()\n",
    "\n",
    "# 1. Training Data\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=train.index,\n",
    "        y=train[\"Energy Price\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Training Data\",\n",
    "        line=dict(color=\"blue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. Test Data\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test.index,\n",
    "        y=test[\"Energy Price\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Test Data\",\n",
    "        line=dict(color=\"orange\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Forecast\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=forecast_df.index,\n",
    "        y=forecast_df[\"Forecasted Price\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Forecast\",\n",
    "        line=dict(color=\"red\", dash=\"dash\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 4. Confidence Interval (fill between upper & lower bounds)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(forecast_conf_int.index) + list(forecast_conf_int.index[::-1]),\n",
    "        y=list(forecast_conf_int.iloc[:, 1]) + list(forecast_conf_int.iloc[:, 0][::-1]),\n",
    "        fill='toself',\n",
    "        fillcolor='rgba(255, 192, 203, 0.3)',  # light pink\n",
    "        line=dict(color='rgba(255, 192, 203, 0)'),\n",
    "        name=\"95% Confidence Interval\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 5. Vertical line for forecast start (without annotation in add_vline)\n",
    "fig.add_vline(\n",
    "    x=forecast_start_dt,\n",
    "    line_width=2,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"black\"\n",
    ")\n",
    "\n",
    "# 6. Add a separate annotation for the forecast start line\n",
    "fig.add_annotation(\n",
    "    x=forecast_start_dt,\n",
    "    y=df[\"Energy Price\"].max(),\n",
    "    text=\"Forecast Start\",\n",
    "    showarrow=True,\n",
    "    arrowhead=2,\n",
    "    arrowcolor=\"black\",\n",
    "    yanchor=\"bottom\"\n",
    ")\n",
    "\n",
    "# Update Layout with range slider and selectors\n",
    "fig.update_layout(\n",
    "    title=\"Energy Price Forecast (Next 7 Days)\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Energy Price (EUR/MWh)\",\n",
    "    template=\"plotly_dark\",\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=7, label=\"1W\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=30, label=\"1M\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the interactive figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8Ô∏è‚É£ Step 8: Verify Forecast vs. Test Data and Evaluate Accuracy Metrics\n",
    "\n",
    "In this step, we compare the forecasted energy prices with the actual test data by:\n",
    "\n",
    "- Combining the test data and forecasted data into a single DataFrame.\n",
    "- Printing a summary table of Actual vs. Forecast values.\n",
    "- Calculating overall error metrics (MAE, MSE, RMSE, MAPE) for the entire forecast period.\n",
    "- Computing day-by-day error metrics to assess forecast accuracy on a daily basis.\n",
    "- Visualizing the actual versus forecasted values.\n",
    "\n",
    "This allows you to evaluate both the overall performance and the daily accuracy of the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Verify Forecast vs. Test Data and Evaluate Accuracy Metrics\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Use a small epsilon to avoid division by zero\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Create a DataFrame that combines actual test values with forecasted values\n",
    "compare_df = pd.DataFrame({\n",
    "    \"Actual\": test[\"Energy Price\"],\n",
    "    \"Forecast\": forecast_df[\"Forecasted Price\"]\n",
    "})\n",
    "\n",
    "# Calculate Hourly Accuracy (%) for each time point:\n",
    "# Accuracy = (1 - |Actual - Forecast|/(Actual)) * 100\n",
    "compare_df[\"Hourly Accuracy (%)\"] = (1 - np.abs((compare_df[\"Actual\"] - compare_df[\"Forecast\"]) / (compare_df[\"Actual\"] + epsilon))) * 100\n",
    "\n",
    "# Print the first few rows of the comparison DataFrame\n",
    "print(\"\\nüìä Comparison of Test Data and Forecast (first 5 rows):\")\n",
    "print(compare_df.head())\n",
    "\n",
    "# -----------------------\n",
    "# Overall Error Metrics\n",
    "# -----------------------\n",
    "overall_mae = mean_absolute_error(compare_df[\"Actual\"], compare_df[\"Forecast\"])\n",
    "overall_mse = mean_squared_error(compare_df[\"Actual\"], compare_df[\"Forecast\"])\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "overall_mape = np.mean(np.abs((compare_df[\"Actual\"] - compare_df[\"Forecast\"]) / (compare_df[\"Actual\"] + epsilon))) * 100\n",
    "overall_mdape = np.median(np.abs((compare_df[\"Actual\"] - compare_df[\"Forecast\"]) / (compare_df[\"Actual\"] + epsilon))) * 100\n",
    "\n",
    "# Global Forecast Accuracy (%) computed by aggregating the values:\n",
    "sum_actual = compare_df[\"Actual\"].sum()\n",
    "sum_forecast = compare_df[\"Forecast\"].sum()\n",
    "global_accuracy = (1 - np.abs(sum_actual - sum_forecast) / (sum_actual + epsilon)) * 100\n",
    "\n",
    "print(\"\\nüìâ Overall Forecast Error Metrics:\")\n",
    "print(f\"- MAE: {overall_mae:.4f}\")\n",
    "print(f\"- MSE: {overall_mse:.4f}\")\n",
    "print(f\"- RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"- MAPE: {overall_mape:.2f}%\")\n",
    "print(f\"- MdAPE: {overall_mdape:.2f}%\")\n",
    "print(f\"- Global Forecast Accuracy: {global_accuracy:.2f}%\")\n",
    "\n",
    "# -----------------------\n",
    "# Day-by-Day Error Metrics\n",
    "# -----------------------\n",
    "def compute_metrics(actual, forecast):\n",
    "    mae = mean_absolute_error(actual, forecast)\n",
    "    mse = mean_squared_error(actual, forecast)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((actual - forecast) / (actual + epsilon))) * 100\n",
    "    accuracy = max(0, 100 - mape)\n",
    "    return pd.Series({\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"MAPE\": mape, \"Accuracy (%)\": accuracy})\n",
    "\n",
    "daily_metrics = compare_df.resample(\"D\").apply(lambda x: compute_metrics(x[\"Actual\"], x[\"Forecast\"]))\n",
    "print(\"\\nüìä Day-by-Day Forecast Accuracy:\")\n",
    "print(daily_metrics)\n",
    "\n",
    "# -----------------------\n",
    "# Interactive Plotly Plot with Dual Y-Axes\n",
    "# -----------------------\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add actual test data trace on primary y-axis\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=compare_df.index, \n",
    "        y=compare_df[\"Actual\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Actual Test Data\",\n",
    "        line=dict(color=\"orange\")\n",
    "    ),\n",
    "    secondary_y=False\n",
    ")\n",
    "\n",
    "# Add forecast data trace on primary y-axis\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=compare_df.index,\n",
    "        y=compare_df[\"Forecast\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Forecast\",\n",
    "        line=dict(color=\"red\", dash=\"dot\")\n",
    "    ),\n",
    "    secondary_y=False\n",
    ")\n",
    "\n",
    "# Add hourly accuracy trace on secondary y-axis\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=compare_df.index,\n",
    "        y=compare_df[\"Hourly Accuracy (%)\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Hourly Accuracy (%)\",\n",
    "        line=dict(color=\"blue\", dash=\"dash\")\n",
    "    ),\n",
    "    secondary_y=True\n",
    ")\n",
    "\n",
    "# Update layout for interactivity\n",
    "fig.update_layout(\n",
    "    title=\"Interactive Comparison: Actual vs. Forecast & Hourly Accuracy\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Energy Price (EUR/MWh)\",\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "\n",
    "# Set secondary y-axis title\n",
    "fig.update_yaxes(title_text=\"Hourly Accuracy (%)\", secondary_y=True)\n",
    "\n",
    "# Add range slider and selectors\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label=\"1D\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=7, label=\"1W\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=30, label=\"1M\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9Ô∏è‚É£ Step 9: Log Experiment Results\n",
    "\n",
    "In this step, we log the experiment results to two locations:\n",
    "\n",
    "1. **CSV Log File:**  \n",
    "   - The log file is named using the format:  \n",
    "     `SARIMA_used_log_YYYYMMDD_HHMM.csv`  \n",
    "   - This file is stored in the Log folder:  \n",
    "     `/Users/redouan/Library/CloudStorage/OneDrive-DANAnalytics/EAISI/Script/Logfiles`\n",
    "   - It contains one row per experiment with columns for the experiment timestamp, model type, training and test date ranges, selected SARIMA parameters, and various error metrics.\n",
    "\n",
    "2. **SQLite Database:**  \n",
    "   - The cumulative results are stored in a SQLite database file named `experiment_results.db`  \n",
    "   - This file is located in the Data folder:  \n",
    "     `/Users/redouan/Library/CloudStorage/OneDrive-DANAnalytics/EAISI/Script/Data`\n",
    "   - This database allows you to query and analyze results across multiple experiments.\n",
    "\n",
    "This two-file approach ensures traceability and flexibility when comparing model performance across different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Ensure that overall_accuracy and overall_mdape are defined (if not, compute them)\n",
    "if \"overall_accuracy\" not in globals():\n",
    "    overall_accuracy = compare_df[\"Hourly Accuracy (%)\"].mean()\n",
    "if \"overall_mdape\" not in globals():\n",
    "    overall_mdape = np.median(np.abs((compare_df[\"Actual\"] - compare_df[\"Forecast\"]) / (compare_df[\"Actual\"] + 1e-10))) * 100\n",
    "\n",
    "# -----------------------------\n",
    "# Define folder paths for logs and results\n",
    "# -----------------------------\n",
    "log_folder = \"/Users/redouan/Library/CloudStorage/OneDrive-DANAnalytics/EAISI/Script/Logfiles\"\n",
    "db_folder = \"/Users/redouan/Library/CloudStorage/OneDrive-DANAnalytics/EAISI/Script/Data\"\n",
    "\n",
    "# Ensure the folders exist\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "os.makedirs(db_folder, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Gather experiment results\n",
    "# -----------------------------\n",
    "# For candidate_params, we capture the full auto_arima summary as a string.\n",
    "try:\n",
    "    candidate_params = str(auto_model.summary())\n",
    "except Exception as e:\n",
    "    candidate_params = f\"Auto-ARIMA search failed; used default parameters. Error: {e}\"\n",
    "\n",
    "results = {\n",
    "    \"experiment_timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"model_type\": \"SARIMA\",  # update dynamically as needed\n",
    "    \"train_start\": train.index.min().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"train_end\": train.index.max().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"test_start\": test.index.min().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"test_end\": test.index.max().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"best_order\": str(best_order),\n",
    "    \"best_seasonal_order\": str(best_seasonal_order),\n",
    "    \"AIC\": sarima_result.aic,\n",
    "    \"BIC\": sarima_result.bic,\n",
    "    \"overall_MAE\": overall_mae,\n",
    "    \"overall_MSE\": overall_mse,\n",
    "    \"overall_RMSE\": overall_rmse,\n",
    "    \"overall_MAPE\": overall_mape,\n",
    "    \"overall_mdape\": overall_mdape,\n",
    "    \"overall_accuracy\": overall_accuracy,\n",
    "    \"candidate_params\": candidate_params\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Option 1: Write results to a CSV Log File\n",
    "# -----------------------------\n",
    "# Create a filename with the current timestamp (YYYYMMDD_HHMM)\n",
    "csv_filename = f\"SARIMA_used_log_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "csv_filepath = os.path.join(log_folder, csv_filename)\n",
    "\n",
    "# Define the header based on the keys of the results dictionary\n",
    "header = list(results.keys())\n",
    "\n",
    "# Write the header and current results to the CSV file using semicolon as the delimiter\n",
    "with open(csv_filepath, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=header, delimiter=\";\")\n",
    "    writer.writeheader()\n",
    "    writer.writerow(results)\n",
    "\n",
    "print(f\"‚úÖ Experiment results logged to CSV file: {csv_filepath}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Option 2: Insert results into a cumulative SQLite Database\n",
    "# -----------------------------\n",
    "db_filepath = os.path.join(db_folder, \"experiment_results.db\")\n",
    "conn = sqlite3.connect(db_filepath)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table if it doesn't exist, including new fields overall_mdape and candidate_params\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS experiments (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    experiment_timestamp TEXT,\n",
    "    model_type TEXT,\n",
    "    train_start TEXT,\n",
    "    train_end TEXT,\n",
    "    test_start TEXT,\n",
    "    test_end TEXT,\n",
    "    best_order TEXT,\n",
    "    best_seasonal_order TEXT,\n",
    "    AIC REAL,\n",
    "    BIC REAL,\n",
    "    overall_MAE REAL,\n",
    "    overall_MSE REAL,\n",
    "    overall_RMSE REAL,\n",
    "    overall_MAPE REAL,\n",
    "    overall_mdape REAL,\n",
    "    overall_accuracy REAL,\n",
    "    candidate_params TEXT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Insert the current experiment results into the database\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO experiments (\n",
    "    experiment_timestamp, model_type, train_start, train_end, test_start, test_end,\n",
    "    best_order, best_seasonal_order, AIC, BIC, overall_MAE, overall_MSE, overall_RMSE,\n",
    "    overall_MAPE, overall_mdape, overall_accuracy, candidate_params\n",
    ")\n",
    "VALUES (\n",
    "    :experiment_timestamp, :model_type, :train_start, :train_end, :test_start, :test_end,\n",
    "    :best_order, :best_seasonal_order, :AIC, :BIC, :overall_MAE, :overall_MSE, :overall_RMSE,\n",
    "    :overall_MAPE, :overall_mdape, :overall_accuracy, :candidate_params\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(insert_query, results)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(f\"‚úÖ Experiment results inserted into SQLite database: {db_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enexis-mar-visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
